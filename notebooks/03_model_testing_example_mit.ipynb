{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Testing\n",
        "\n",
        "Questions to be answered:\n",
        "\n",
        "- Remove outliers?\n",
        "- Which Sampling method to use?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "scoring = {'f1_macro': 'f1_macro', 'bal_acc': 'balanced_accuracy', 'f1_weighted': 'f1_weighted'}\n",
        "random_state = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from src.utils.preprocessing import (\n",
        "    prepare_mitbih, \n",
        "    prepare_ptbdb,\n",
        "    resample_training\n",
        ")\n",
        "from src.utils.evaluation import eval_model\n",
        "from src.visualization import plot_confusion_matrix\n",
        "from src.utils.model_saver import create_model_saver\n",
        "\n",
        "# external \n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import loguniform, randint, uniform\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Samplers\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Init model saver\n",
        "model_saver = create_model_saver(\"../src/models/exploration_phase\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MITBIH dataset prepared:\n",
            "  Training size: (87554, 187)\n",
            "  Test size: (21892, 187)\n",
            "Note: No validation set - using train/test split only. Cross-validation handles train/val splitting.\n"
          ]
        }
      ],
      "source": [
        "# Prepare datasets\n",
        "mitbih = prepare_mitbih(remove_outliers=False)\n",
        "\n",
        "print(\"MITBIH dataset prepared:\")\n",
        "print(f\"  Training size: {mitbih.X_train.shape}\")\n",
        "print(f\"  Test size: {mitbih.X_test.shape if mitbih.X_test is not None else 'None'}\")\n",
        "print(\"Note: No validation set - using train/test split only. Cross-validation handles train/val splitting.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test = mitbih.X_train.values, mitbih.X_test.values\n",
        "y_train = mitbih.y_train.astype(int).values\n",
        "y_test = mitbih.y_test.astype(int).values\n",
        "\n",
        "# Scale features using train fit only\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Param Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_spaces = {\n",
        "    \"LogisticRegression\": {\n",
        "        \"estimator\": LogisticRegression(max_iter=10000, multi_class='multinomial', solver='lbfgs'),\n",
        "        \"params\": {\n",
        "            \"C\": loguniform(1e-3, 1e3),      # Big C = less penalty on large weights (more freedom, risk of overfitting). \n",
        "                                             # Small C = more penalty (more discipline, less overfitting).\n",
        "                                             # loguniform = means we try values spread across tiny to big scales (e.g., 0.001 up to 100), not just small steps.\n",
        "            \"penalty\": [\"l2\"], # gently pushes weights toward zero, which keeps the model simpler and more stable.\n",
        "            \"solver\": [\"lbfgs\"],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 5,\n",
        "        \"create_new_model\": False,\n",
        "    },\n",
        "    \"KNN\": {\n",
        "        \"estimator\": KNeighborsClassifier(),\n",
        "        \"params\": {\n",
        "            \"n_neighbors\": randint(1, 51),\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"metric\": [\"minkowski\", \"manhattan\", \"euclidean\"],\n",
        "            \"p\": [1, 2],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 5,\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"estimator\": RandomForestClassifier(random_state=random_state, n_jobs=-1),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200, 300],\n",
        "            \"max_depth\": [10, 15, 20],\n",
        "            \"min_samples_split\": [2, 5, 10, 20, 50],\n",
        "            \"min_samples_leaf\": [1, 2, 4, 8],\n",
        "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "            \"bootstrap\": [True],\n",
        "            \"class_weight\": [\"balanced\", None],\n",
        "            \"criterion\": [\"gini\", \"entropy\"],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 5,\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"estimator\": SVC(),\n",
        "        \"params\": {\n",
        "            \"kernel\": [\"rbf\", \"poly\"],\n",
        "            \"C\": [0.1, 1, 10],\n",
        "            \"gamma\": [0.001, 0.01, 0.1, 0.5, 0.9],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 5,\n",
        "    },\n",
        "    \"DecisionTree\": {\n",
        "        \"estimator\": DecisionTreeClassifier(random_state=random_state),\n",
        "        \"params\": {\n",
        "            \"max_depth\": [None, 5, 10, 15, 20, 25, 30],\n",
        "            \"min_samples_split\": [2, 5, 10, 20, 50],\n",
        "            \"min_samples_leaf\": [1, 2, 4, 8, 16],\n",
        "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "            \"criterion\": [\"gini\", \"entropy\"],\n",
        "            \"class_weight\": [\"balanced\", None],\n",
        "            \"splitter\": [\"best\", \"random\"],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 100,\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"estimator\": xgb.XGBClassifier(\n",
        "            objective=\"multi:softmax\",\n",
        "            num_class=5,\n",
        "            random_state=random_state,\n",
        "            n_jobs=-1,\n",
        "            eval_metric=\"mlogloss\",\n",
        "        ),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200, 300, 500],\n",
        "            \"max_depth\": [3, 4, 5, 6, 7, 8],\n",
        "            \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
        "            \"subsample\": [0.8, 0.9, 1.0],\n",
        "            \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
        "            \"reg_alpha\": [0, 0.1, 0.5, 1.0],\n",
        "            \"reg_lambda\": [0, 0.1, 0.5, 1.0],\n",
        "            \"min_child_weight\": [1, 3, 5, 7],\n",
        "            \"gamma\": [0, 0.1, 0.2, 0.3],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 40,\n",
        "    },\n",
        "    \"LDA\": {\n",
        "        \"estimator\": LinearDiscriminantAnalysis(),\n",
        "        \"params\": [\n",
        "            {\"solver\": [\"svd\"], \"store_covariance\": [False, True], \"tol\": [1e-4, 1e-3, 1e-2]},\n",
        "            {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [None, \"auto\", 0.0, 0.05, 0.1, 0.15, 0.25, 0.35, 0.5, 0.65, 0.75, 0.85, 0.9], \"tol\": [1e-4, 1e-3, 1e-2]},\n",
        "        ],\n",
        "        \"cv\": StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 50,\n",
        "    },\n",
        "    \"ANN\": {\n",
        "        \"estimator\": MLPClassifier(\n",
        "            max_iter=300,\n",
        "            early_stopping=True,\n",
        "            random_state=random_state,\n",
        "            n_iter_no_change=10,\n",
        "            solver=\"adam\",\n",
        "        ),\n",
        "        \"params\": {\n",
        "            \"hidden_layer_sizes\": [(64,), (128,), (128, 64)],\n",
        "            \"activation\": [\"relu\"],\n",
        "            \"alpha\": loguniform(1e-4, 1e-2),\n",
        "            \"learning_rate_init\": loguniform(1e-3, 1e-2),\n",
        "            \"batch_size\": randint(64, 129),\n",
        "            \"beta_1\": uniform(0.9, 0.09),\n",
        "            \"beta_2\": uniform(0.95, 0.049),\n",
        "            \"validation_fraction\": [0.1, 0.15],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state),\n",
        "        \"n_iter\": 100,\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test models with Randomized Search CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Without outlier removal or sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/LogisticRegression_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model LogisticRegression already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check if model already exists\n",
        "classifier_name = \"LogisticRegression\"\n",
        "experiment_name = \"no_sampling\"\n",
        "create_new = param_spaces[classifier_name].get('create_new_model', False)\n",
        "\n",
        "if not create_new and model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_logreg = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    logreg = param_spaces[classifier_name]['estimator']\n",
        "\n",
        "    param_dist_logreg = param_spaces[classifier_name]['params']\n",
        "\n",
        "    rs_logreg = RandomizedSearchCV(\n",
        "        estimator=logreg,\n",
        "        param_distributions=param_dist_logreg,\n",
        "        n_iter=param_spaces[classifier_name]['n_iter'],\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=param_spaces[classifier_name]['cv'],\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    rs_logreg.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_logreg.best_params_,\n",
        "        'best_score': rs_logreg.best_score_,\n",
        "        'cv_results': rs_logreg.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_logreg, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_logreg = rs_logreg.best_estimator_\n",
        "results['LogisticRegression'] = eval_model(\n",
        "    best_logreg,\n",
        "    X_train_s, y_train,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=4.0428727350273315, max_iter=10000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.0428727350273315, max_iter=10000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=4.0428727350273315, max_iter=10000,\n",
              "                   multi_class='multinomial')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9176564641388762,\n",
              "  'precision_macro': 0.800141874074688,\n",
              "  'recall_macro': 0.6105422563887755,\n",
              "  'f1_macro': 0.6765546028672075,\n",
              "  'precision_per_class': array([0.92888831, 0.81679389, 0.65064103, 0.65625   , 0.94813614]),\n",
              "  'recall_per_class': array([0.98220199, 0.48198198, 0.35060449, 0.328125  , 0.90979782]),\n",
              "  'f1_per_class': array([0.9548015 , 0.60623229, 0.45566779, 0.4375    , 0.92857143]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7119,   18,   91,    1,   19],\n",
              "         [ 106,  107,    7,    1,    1],\n",
              "         [ 350,    5,  203,    9,   12],\n",
              "         [  38,    0,    5,   21,    0],\n",
              "         [  51,    1,    6,    0,  585]])},\n",
              " 'test': {'accuracy': 0.9151288141786954,\n",
              "  'precision_macro': 0.7885019903691001,\n",
              "  'recall_macro': 0.5967700974401475,\n",
              "  'f1_macro': 0.6633702561560696,\n",
              "  'precision_per_class': array([0.92469552, 0.82105263, 0.66344828, 0.57843137, 0.95488215]),\n",
              "  'recall_per_class': array([0.98476653, 0.42086331, 0.33218232, 0.36419753, 0.8818408 ]),\n",
              "  'f1_per_class': array([0.95378612, 0.55648038, 0.44270594, 0.4469697 , 0.91690915]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17842,    36,   192,     9,    39],\n",
              "         [  293,   234,    26,     2,     1],\n",
              "         [  894,    14,   481,    32,    27],\n",
              "         [   95,     0,     8,    59,     0],\n",
              "         [  171,     1,    18,     0,  1418]])}}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_logreg)\n",
        "results['LogisticRegression']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.2 KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/KNN_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model KNN already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check if model already exists\n",
        "classifier_name = \"KNN\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_knn = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    knn = KNeighborsClassifier()\n",
        "    param_dist_knn = {\n",
        "        'n_neighbors': randint(1, 51),\n",
        "        'weights': ['uniform', 'distance'],           # helps with imbalance; 'distance' often better\n",
        "        'metric': ['minkowski', 'manhattan', 'euclidean'],\n",
        "        'p': [1,2],                           # used only for minkowski, if left out it defaults to euclidean\n",
        "    }\n",
        "\n",
        "    rs_knn = RandomizedSearchCV(\n",
        "        estimator=knn,\n",
        "        param_distributions=param_dist_knn,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    rs_knn.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_knn.best_params_,\n",
        "        'best_score': rs_knn.best_score_,\n",
        "        'cv_results': rs_knn.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_knn, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_knn = rs_knn.best_estimator_\n",
        "results['KNN'] = eval_model(\n",
        "    best_knn,\n",
        "    X_train_s, y_train,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=4, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=4, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric='manhattan', n_neighbors=4, p=1, weights='distance')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9798994974874372,\n",
              "  'precision_macro': 0.9391433113355262,\n",
              "  'recall_macro': 0.8599185488349104,\n",
              "  'f1_macro': 0.8949289961165755,\n",
              "  'precision_per_class': array([0.98375205, 0.88826816, 0.95087719, 0.87755102, 0.99526814]),\n",
              "  'recall_per_class': array([0.99406733, 0.71621622, 0.93609672, 0.671875  , 0.98133748]),\n",
              "  'f1_per_class': array([0.98888279, 0.79301746, 0.94342907, 0.76106195, 0.98825372]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7205,   18,   20,    3,    2],\n",
              "         [  61,  159,    2,    0,    0],\n",
              "         [  33,    0,  542,    3,    1],\n",
              "         [  16,    0,    5,   43,    0],\n",
              "         [   9,    2,    1,    0,  631]])},\n",
              " 'test': {'accuracy': 0.9775260369084597,\n",
              "  'precision_macro': 0.920137365015206,\n",
              "  'recall_macro': 0.8528821323680518,\n",
              "  'f1_macro': 0.8832154533279242,\n",
              "  'precision_per_class': array([0.98254894, 0.88167053, 0.94080338, 0.80141844, 0.99424552]),\n",
              "  'recall_per_class': array([0.99442543, 0.68345324, 0.92196133, 0.69753086, 0.9670398 ]),\n",
              "  'f1_per_class': array([0.98845152, 0.77001013, 0.93128706, 0.74587459, 0.98045397]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[18017,    46,    42,     8,     5],\n",
              "         [  158,   380,    17,     0,     1],\n",
              "         [   85,     5,  1335,    20,     3],\n",
              "         [   32,     0,    17,   113,     0],\n",
              "         [   45,     0,     8,     0,  1555]])}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_knn)\n",
        "results['KNN']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.3 Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/RandomForest_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model RandomForest already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check if model already exists\n",
        "classifier_name = \"RandomForest\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_rf = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    rf = RandomForestClassifier(random_state=random_state, n_jobs=-1)\n",
        "    param_dist_rf = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [10, 15, 20], # prevent overfitting majority class\n",
        "        \n",
        "        'min_samples_split': [2, 5, 10, 20, 50],\n",
        "        'min_samples_leaf': [1, 2, 4, 8], # higher = better regularization\n",
        "        \n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'bootstrap': [True], # better generalization\n",
        "        \n",
        "        'class_weight': ['balanced', None], # for imbalanced data\n",
        "        \n",
        "        # Split criterion: entropy can help with imbalanced classes\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "    }\n",
        "\n",
        "    rs_rf = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_dist_rf,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_rf.fit(X_train, y_train) # using unscaled data - RF is not sensitive to feature scaling\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_rf.best_params_,\n",
        "        'best_score': rs_rf.best_score_,\n",
        "        'cv_results': rs_rf.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_rf, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_rf = rs_rf.best_estimator_\n",
        "results['RandomForest'] = eval_model( \n",
        "    best_rf, \n",
        "    X_train, y_train,\n",
        "    X_test, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
              "                       max_depth=20, min_samples_leaf=8, min_samples_split=20,\n",
              "                       n_estimators=200, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
              "                       max_depth=20, min_samples_leaf=8, min_samples_split=20,\n",
              "                       n_estimators=200, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
              "                       max_depth=20, min_samples_leaf=8, min_samples_split=20,\n",
              "                       n_estimators=200, n_jobs=-1, random_state=42)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9785290086797624,\n",
              "  'precision_macro': 0.9160207060087867,\n",
              "  'recall_macro': 0.8648953216324944,\n",
              "  'f1_macro': 0.8885240457117929,\n",
              "  'precision_per_class': array([0.98467013, 0.88172043, 0.94210526, 0.78571429, 0.98589342]),\n",
              "  'recall_per_class': array([0.99254967, 0.73873874, 0.92746114, 0.6875    , 0.97822706]),\n",
              "  'f1_per_class': array([0.9885942 , 0.80392157, 0.93472585, 0.73333333, 0.98204528]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7194,   20,   20,    8,    6],\n",
              "         [  54,  164,    3,    0,    1],\n",
              "         [  34,    2,  537,    4,    2],\n",
              "         [  14,    0,    6,   44,    0],\n",
              "         [  10,    0,    4,    0,  629]])},\n",
              " 'test': {'accuracy': 0.9748309884889458,\n",
              "  'precision_macro': 0.901553466600747,\n",
              "  'recall_macro': 0.8709987482601733,\n",
              "  'f1_macro': 0.8848821016625263,\n",
              "  'precision_per_class': array([0.98157362, 0.8516129 , 0.94247159, 0.74556213, 0.98654709]),\n",
              "  'recall_per_class': array([0.99083784, 0.71223022, 0.91643646, 0.77777778, 0.95771144]),\n",
              "  'f1_per_class': array([0.98618398, 0.77571009, 0.92927171, 0.76132931, 0.97191543]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17952,    66,    64,    21,    15],\n",
              "         [  158,   396,     1,     0,     1],\n",
              "         [   92,     2,  1327,    22,     5],\n",
              "         [   27,     0,     9,   126,     0],\n",
              "         [   60,     1,     7,     0,  1540]])}}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_rf)\n",
        "results['RandomForest']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.4 SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/SVM_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model SVM already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check if model already exists\n",
        "classifier_name = \"SVM\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_svm = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    svm = SVC()\n",
        "    param_dist_svm = {\n",
        "        'kernel': ['rbf', 'poly'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'gamma': [0.001, 0.01, 0.1, 0.5, 1],\n",
        "    }\n",
        "    rs_svm = RandomizedSearchCV(\n",
        "        estimator=svm,\n",
        "        param_distributions=param_dist_svm,\n",
        "        n_iter=15,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state),\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "    rs_svm.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_svm.best_params_,\n",
        "        'best_score': rs_svm.best_score_,\n",
        "        'cv_results': rs_svm.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_svm, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_svm = rs_svm.best_estimator_\n",
        "results['SVM'] = eval_model(\n",
        "    best_svm,\n",
        "    X_train_s, y_train,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.01, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.01, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=10, gamma=0.01, kernel='poly')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9745317496573778,\n",
              "  'precision_macro': 0.9163739251346034,\n",
              "  'recall_macro': 0.8540245675024011,\n",
              "  'f1_macro': 0.8822902628187215,\n",
              "  'precision_per_class': array([0.98194995, 0.84615385, 0.91872792, 0.8490566 , 0.98598131]),\n",
              "  'recall_per_class': array([0.99075607, 0.69369369, 0.89810017, 0.703125  , 0.9844479 ]),\n",
              "  'f1_per_class': array([0.98633336, 0.76237624, 0.90829694, 0.76923077, 0.98521401]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7181,   23,   35,    3,    6],\n",
              "         [  65,  154,    3,    0,    0],\n",
              "         [  46,    5,  520,    5,    3],\n",
              "         [  12,    0,    7,   45,    0],\n",
              "         [   9,    0,    1,    0,  633]])},\n",
              " 'test': {'accuracy': 0.9740544491138315,\n",
              "  'precision_macro': 0.9049136882358036,\n",
              "  'recall_macro': 0.8394617444559591,\n",
              "  'f1_macro': 0.8684037795992783,\n",
              "  'precision_per_class': array([0.98054602, 0.87347932, 0.92642857, 0.75675676, 0.98735777]),\n",
              "  'recall_per_class': array([0.99315598, 0.64568345, 0.89571823, 0.69135802, 0.97139303]),\n",
              "  'f1_per_class': array([0.98681072, 0.74250259, 0.91081461, 0.72258065, 0.97931034]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17994,    32,    67,    12,    13],\n",
              "         [  182,   359,    14,     1,     0],\n",
              "         [  102,    19,  1297,    23,     7],\n",
              "         [   34,     0,    16,   112,     0],\n",
              "         [   39,     1,     6,     0,  1562]])}}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_svm)\n",
        "results['SVM']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.5 Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/DecisionTree_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model DecisionTree already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check if model already exists\n",
        "classifier_name = \"DecisionTree\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_dt = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    dt = DecisionTreeClassifier(random_state=random_state)\n",
        "\n",
        "    param_dist_dt = {\n",
        "        'max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
        "        'min_samples_split': [2, 5, 10, 20, 50],\n",
        "        'min_samples_leaf': [1, 2, 4, 8, 16],\n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'criterion': ['gini', 'entropy'],  \n",
        "        'class_weight': ['balanced', None],\n",
        "        'splitter': ['best', 'random'],  # Split strategy\n",
        "    }\n",
        "\n",
        "    rs_dt = RandomizedSearchCV(\n",
        "        estimator=dt,\n",
        "        param_distributions=param_dist_dt,\n",
        "        n_iter=100,  \n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_dt.fit(X_train, y_train)  # Using unscaled data - DT doesn't need scaling\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_dt.best_params_,\n",
        "        'best_score': rs_dt.best_score_,\n",
        "        'cv_results': rs_dt.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_dt, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_dt = rs_dt.best_estimator_\n",
        "results['DecisionTree'] = eval_model(\n",
        "    best_dt,\n",
        "    X_train, y_train,\n",
        "    X_test, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=25, min_samples_leaf=2,\n",
              "                       min_samples_split=20, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=25, min_samples_leaf=2,\n",
              "                       min_samples_split=20, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=25, min_samples_leaf=2,\n",
              "                       min_samples_split=20, random_state=42)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9611694837825491,\n",
              "  'precision_macro': 0.8286714991952492,\n",
              "  'recall_macro': 0.8113420712229086,\n",
              "  'f1_macro': 0.8192777361500603,\n",
              "  'precision_per_class': array([0.97892852, 0.7357513 , 0.86677909, 0.61290323, 0.94899536]),\n",
              "  'recall_per_class': array([0.98068433, 0.63963964, 0.88773748, 0.59375   , 0.95489891]),\n",
              "  'f1_per_class': array([0.97980564, 0.68433735, 0.87713311, 0.6031746 , 0.95193798]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7108,   41,   58,   15,   26],\n",
              "         [  71,  142,    7,    0,    2],\n",
              "         [  47,    5,  514,    9,    4],\n",
              "         [  16,    1,    8,   38,    1],\n",
              "         [  19,    4,    6,    0,  614]])},\n",
              " 'test': {'accuracy': 0.9594372373469761,\n",
              "  'precision_macro': 0.8282860612296581,\n",
              "  'recall_macro': 0.7983514845333289,\n",
              "  'f1_macro': 0.8124014481179902,\n",
              "  'precision_per_class': array([0.97427195, 0.72995781, 0.8837535 , 0.59119497, 0.96225208]),\n",
              "  'recall_per_class': array([0.98233801, 0.62230216, 0.87154696, 0.58024691, 0.93532338]),\n",
              "  'f1_per_class': array([0.97828835, 0.67184466, 0.87760779, 0.58566978, 0.94859666]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17798,   114,   116,    45,    45],\n",
              "         [  192,   346,    12,     0,     6],\n",
              "         [  148,    11,  1262,    19,     8],\n",
              "         [   49,     0,    19,    94,     0],\n",
              "         [   81,     3,    19,     1,  1504]])}}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_dt)\n",
        "results['DecisionTree']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.6 XGBoost / Gradien Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/XGBoost_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model XGBoost already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check if model already exists\n",
        "classifier_name = \"XGBoost\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_xgb = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        objective='multi:softmax',\n",
        "        num_class=5,  # no of classes\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    param_dist_xgb = {\n",
        "        'n_estimators': [100, 200, 300, 500],\n",
        "        'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
        "        'subsample': [0.8, 0.9, 1.0],\n",
        "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "        'reg_alpha': [0, 0.1, 0.5, 1.0],  # L1 regularization\n",
        "        'reg_lambda': [0, 0.1, 0.5, 1.0],  # L2 regularization\n",
        "        'min_child_weight': [1, 3, 5, 7],\n",
        "        'gamma': [0, 0.1, 0.2, 0.3],  # Minimum loss reduction\n",
        "    }\n",
        "\n",
        "    rs_xgb = RandomizedSearchCV(\n",
        "        estimator=xgb_model,\n",
        "        param_distributions=param_dist_xgb,\n",
        "        n_iter=30,  \n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state),\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_xgb.fit(X_train, y_train)  # XGBoost handles scaling internally\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_xgb.best_params_,\n",
        "        'best_score': rs_xgb.best_score_,\n",
        "        'cv_results': rs_xgb.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_xgb, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_xgb = rs_xgb.best_estimator_\n",
        "results['XGBoost'] = eval_model(\n",
        "    best_xgb,\n",
        "    X_train, y_train,\n",
        "    X_test, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=0, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
              "              max_leaves=None, min_child_weight=5, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
              "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=0, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
              "              max_leaves=None, min_child_weight=5, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
              "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='mlogloss',\n",
              "              feature_types=None, gamma=0, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
              "              max_leaves=None, min_child_weight=5, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
              "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9816126084970306,\n",
              "  'precision_macro': 0.9503427741288547,\n",
              "  'recall_macro': 0.8653017509227453,\n",
              "  'f1_macro': 0.9026234500019875,\n",
              "  'precision_per_class': array([0.98499318, 0.92397661, 0.94903339, 0.9       , 0.99371069]),\n",
              "  'recall_per_class': array([0.99613687, 0.71171171, 0.93264249, 0.703125  , 0.98289269]),\n",
              "  'f1_per_class': array([0.99053368, 0.80407125, 0.94076655, 0.78947368, 0.98827209]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7220,   11,   13,    2,    2],\n",
              "         [  62,  158,    1,    0,    1],\n",
              "         [  34,    1,  540,    3,    1],\n",
              "         [   7,    0,   12,   45,    0],\n",
              "         [   7,    1,    3,    0,  632]])},\n",
              " 'test': {'accuracy': 0.9818198428649735,\n",
              "  'precision_macro': 0.9545382548756202,\n",
              "  'recall_macro': 0.8654063021130722,\n",
              "  'f1_macro': 0.9046987238778078,\n",
              "  'precision_per_class': array([0.98292922, 0.95588235, 0.97383721, 0.86764706, 0.99239544]),\n",
              "  'recall_per_class': array([0.99790264, 0.70143885, 0.92541436, 0.72839506, 0.9738806 ]),\n",
              "  'f1_per_class': array([0.99035933, 0.80912863, 0.9490085 , 0.79194631, 0.98305085]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[18080,    17,    13,     2,     6],\n",
              "         [  160,   390,     5,     0,     1],\n",
              "         [   86,     1,  1340,    16,     5],\n",
              "         [   31,     0,    13,   118,     0],\n",
              "         [   37,     0,     5,     0,  1566]])}}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_xgb)\n",
        "results['XGBoost']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.7 Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model LDA not found. Training new model...\n",
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END .............shrinkage=0.85, solver=lsqr, tol=0.001; total time=   1.7s\n",
            "[CV] END .............shrinkage=0.0, solver=lsqr, tol=0.0001; total time=   1.8s\n",
            "[CV] END .............shrinkage=0.85, solver=lsqr, tol=0.001; total time=   2.1s\n",
            "[CV] END .............shrinkage=0.0, solver=lsqr, tol=0.0001; total time=   2.2s\n",
            "[CV] END ............shrinkage=0.75, solver=eigen, tol=0.001; total time=   2.3s\n",
            "[CV] END .............shrinkage=0.0, solver=eigen, tol=0.001; total time=   2.4s\n",
            "[CV] END .............shrinkage=0.0, solver=lsqr, tol=0.0001; total time=   2.2s\n",
            "[CV] END .............shrinkage=0.5, solver=eigen, tol=0.001; total time=   2.4s\n",
            "[CV] END .............shrinkage=0.85, solver=lsqr, tol=0.001; total time=   2.5s\n",
            "[CV] END ............shrinkage=0.75, solver=eigen, tol=0.001; total time=   2.5s\n",
            "[CV] END ............shrinkage=None, solver=eigen, tol=0.001; total time=   2.7s\n",
            "[CV] END ............shrinkage=None, solver=eigen, tol=0.001; total time=   2.7s\n",
            "[CV] END .............shrinkage=0.0, solver=eigen, tol=0.001; total time=   2.8s\n",
            "[CV] END ............shrinkage=None, solver=eigen, tol=0.001; total time=   2.8s\n",
            "[CV] END ............shrinkage=0.75, solver=eigen, tol=0.001; total time=   2.9s\n",
            "[CV] END .............shrinkage=0.0, solver=eigen, tol=0.001; total time=   3.0s\n",
            "[CV] END .............shrinkage=0.5, solver=eigen, tol=0.001; total time=   3.1s\n",
            "[CV] END .............shrinkage=0.5, solver=eigen, tol=0.001; total time=   3.2s\n",
            "[CV] END ............shrinkage=auto, solver=lsqr, tol=0.0001; total time=   3.3s\n",
            "[CV] END ............shrinkage=auto, solver=lsqr, tol=0.0001; total time=   3.3s\n",
            "[CV] END ............shrinkage=auto, solver=lsqr, tol=0.0001; total time=   3.7s\n",
            "[CV] END .............shrinkage=0.65, solver=eigen, tol=0.01; total time=   1.9s\n",
            "[CV] END .............shrinkage=0.65, solver=eigen, tol=0.01; total time=   2.0s\n",
            "[CV] END ............shrinkage=0.15, solver=eigen, tol=0.001; total time=   2.4s\n",
            "[CV] END .............shrinkage=0.25, solver=eigen, tol=0.01; total time=   2.4s\n",
            "[CV] END ..............shrinkage=0.1, solver=eigen, tol=0.01; total time=   2.3s\n",
            "[CV] END .............shrinkage=0.25, solver=eigen, tol=0.01; total time=   2.9s\n",
            "[CV] END ............shrinkage=0.15, solver=eigen, tol=0.001; total time=   3.2s\n",
            "[CV] END .............shrinkage=0.65, solver=eigen, tol=0.01; total time=   3.5s\n",
            "[CV] END ............shrinkage=0.15, solver=eigen, tol=0.001; total time=   3.4s\n",
            "[CV] END ............shrinkage=0.9, solver=eigen, tol=0.0001; total time=   2.9s\n",
            "[CV] END ............shrinkage=0.9, solver=eigen, tol=0.0001; total time=   2.9s\n",
            "[CV] END ..............shrinkage=0.1, solver=eigen, tol=0.01; total time=   3.4s\n",
            "[CV] END .............shrinkage=0.25, solver=eigen, tol=0.01; total time=   3.5s\n",
            "[CV] END ..............shrinkage=0.5, solver=lsqr, tol=0.001; total time=   3.0s\n",
            "[CV] END ..............shrinkage=0.5, solver=lsqr, tol=0.001; total time=   3.1s\n",
            "[CV] END .....solver=svd, store_covariance=False, tol=0.0001; total time=   6.5s\n",
            "[CV] END ..............shrinkage=0.5, solver=lsqr, tol=0.001; total time=   2.7s\n",
            "[CV] END ..............shrinkage=0.1, solver=eigen, tol=0.01; total time=   3.6s\n",
            "[CV] END .............shrinkage=0.5, solver=lsqr, tol=0.0001; total time=   2.2s\n",
            "[CV] END .............shrinkage=0.5, solver=lsqr, tol=0.0001; total time=   2.4s\n",
            "[CV] END ............shrinkage=0.9, solver=eigen, tol=0.0001; total time=   3.7s\n",
            "[CV] END ............shrinkage=0.1, solver=eigen, tol=0.0001; total time=   2.4s\n",
            "[CV] END .....solver=svd, store_covariance=False, tol=0.0001; total time=   8.1s\n",
            "[CV] END ............shrinkage=0.1, solver=eigen, tol=0.0001; total time=   3.1s\n",
            "[CV] END ............shrinkage=0.1, solver=eigen, tol=0.0001; total time=   3.1s\n",
            "[CV] END .............shrinkage=0.5, solver=lsqr, tol=0.0001; total time=   3.5s\n",
            "[CV] END ............shrinkage=0.85, solver=eigen, tol=0.001; total time=   2.7s\n",
            "[CV] END .............shrinkage=0.1, solver=lsqr, tol=0.0001; total time=   2.2s\n",
            "[CV] END .............shrinkage=0.1, solver=lsqr, tol=0.0001; total time=   2.3s\n",
            "[CV] END ............shrinkage=0.25, solver=lsqr, tol=0.0001; total time=   3.1s\n",
            "[CV] END .............shrinkage=0.35, solver=lsqr, tol=0.001; total time=   2.8s\n",
            "[CV] END .............shrinkage=0.35, solver=lsqr, tol=0.001; total time=   2.7s\n",
            "[CV] END ............shrinkage=0.25, solver=lsqr, tol=0.0001; total time=   3.1s\n",
            "[CV] END .............shrinkage=0.35, solver=lsqr, tol=0.001; total time=   2.8s\n",
            "[CV] END ............shrinkage=0.25, solver=lsqr, tol=0.0001; total time=   3.0s\n",
            "[CV] END .............shrinkage=None, solver=eigen, tol=0.01; total time=   2.7s\n",
            "[CV] END ............shrinkage=0.85, solver=eigen, tol=0.001; total time=   3.6s\n",
            "[CV] END ............shrinkage=0.85, solver=eigen, tol=0.001; total time=   3.6s\n",
            "[CV] END .......solver=svd, store_covariance=True, tol=0.001; total time=   7.8s\n",
            "[CV] END .............shrinkage=None, solver=eigen, tol=0.01; total time=   3.0s\n",
            "[CV] END .............shrinkage=0.1, solver=lsqr, tol=0.0001; total time=   2.7s\n",
            "[CV] END .....solver=svd, store_covariance=False, tol=0.0001; total time=   9.6s\n",
            "[CV] END .............shrinkage=None, solver=eigen, tol=0.01; total time=   3.1s\n",
            "[CV] END ...........shrinkage=0.15, solver=eigen, tol=0.0001; total time=   2.3s\n",
            "[CV] END ...........shrinkage=0.15, solver=eigen, tol=0.0001; total time=   2.2s\n",
            "[CV] END ............shrinkage=0.05, solver=eigen, tol=0.001; total time=   2.0s\n",
            "[CV] END .......solver=svd, store_covariance=True, tol=0.001; total time=   8.7s\n",
            "[CV] END ..............shrinkage=0.75, solver=lsqr, tol=0.01; total time=   1.6s\n",
            "[CV] END ..............shrinkage=0.75, solver=lsqr, tol=0.01; total time=   1.6s\n",
            "[CV] END ..............shrinkage=0.75, solver=lsqr, tol=0.01; total time=   1.8s\n",
            "[CV] END .......solver=svd, store_covariance=True, tol=0.001; total time=   8.9s\n",
            "[CV] END ............shrinkage=0.05, solver=eigen, tol=0.001; total time=   2.6s\n",
            "[CV] END ............shrinkage=0.05, solver=eigen, tol=0.001; total time=   2.6s\n",
            "[CV] END ...........shrinkage=None, solver=eigen, tol=0.0001; total time=   2.3s\n",
            "[CV] END ...........shrinkage=0.15, solver=eigen, tol=0.0001; total time=   2.9s\n",
            "[CV] END ..............shrinkage=0.1, solver=lsqr, tol=0.001; total time=   1.8s\n",
            "[CV] END ..............shrinkage=0.1, solver=lsqr, tol=0.001; total time=   1.8s\n",
            "[CV] END ..............shrinkage=0.1, solver=lsqr, tol=0.001; total time=   1.8s\n",
            "[CV] END ...........shrinkage=0.25, solver=eigen, tol=0.0001; total time=   2.0s\n",
            "[CV] END ...........shrinkage=0.25, solver=eigen, tol=0.0001; total time=   1.9s\n",
            "[CV] END ...........shrinkage=None, solver=eigen, tol=0.0001; total time=   2.4s\n",
            "[CV] END .............shrinkage=0.1, solver=eigen, tol=0.001; total time=   2.1s\n",
            "[CV] END ...........shrinkage=None, solver=eigen, tol=0.0001; total time=   2.8s\n",
            "[CV] END ...........shrinkage=0.25, solver=eigen, tol=0.0001; total time=   2.6s\n",
            "[CV] END .............shrinkage=0.1, solver=eigen, tol=0.001; total time=   1.8s\n",
            "[CV] END .............shrinkage=0.1, solver=eigen, tol=0.001; total time=   1.7s\n",
            "[CV] END ..............shrinkage=0.25, solver=lsqr, tol=0.01; total time=   1.7s\n",
            "[CV] END ..............shrinkage=0.25, solver=lsqr, tol=0.01; total time=   1.9s\n",
            "[CV] END ..............shrinkage=0.25, solver=lsqr, tol=0.01; total time=   2.1s\n",
            "[CV] END .............shrinkage=None, solver=lsqr, tol=0.001; total time=   1.9s\n",
            "[CV] END .............shrinkage=None, solver=lsqr, tol=0.001; total time=   2.0s\n",
            "[CV] END ..............shrinkage=0.9, solver=eigen, tol=0.01; total time=   2.5s\n",
            "[CV] END ..............shrinkage=0.9, solver=eigen, tol=0.01; total time=   2.7s\n",
            "[CV] END ..............shrinkage=0.9, solver=eigen, tol=0.01; total time=   2.7s\n",
            "[CV] END ............shrinkage=0.65, solver=eigen, tol=0.001; total time=   2.4s\n",
            "[CV] END .............shrinkage=None, solver=lsqr, tol=0.001; total time=   2.3s\n",
            "[CV] END .............shrinkage=0.75, solver=lsqr, tol=0.001; total time=   2.4s\n",
            "[CV] END .............shrinkage=0.75, solver=lsqr, tol=0.001; total time=   2.3s\n",
            "[CV] END ............shrinkage=0.65, solver=eigen, tol=0.001; total time=   2.8s\n",
            "[CV] END ...............shrinkage=0.5, solver=lsqr, tol=0.01; total time=   2.3s\n",
            "[CV] END ...............shrinkage=0.5, solver=lsqr, tol=0.01; total time=   2.3s\n",
            "[CV] END ..............shrinkage=0.0, solver=lsqr, tol=0.001; total time=   2.0s\n",
            "[CV] END ............shrinkage=0.65, solver=eigen, tol=0.001; total time=   3.3s\n",
            "[CV] END ...............shrinkage=0.5, solver=lsqr, tol=0.01; total time=   2.4s\n",
            "[CV] END ..............shrinkage=0.0, solver=lsqr, tol=0.001; total time=   2.1s\n",
            "[CV] END .............shrinkage=0.75, solver=lsqr, tol=0.001; total time=   2.8s\n",
            "[CV] END ........solver=svd, store_covariance=True, tol=0.01; total time=   5.5s\n",
            "[CV] END ..............shrinkage=0.0, solver=lsqr, tol=0.001; total time=   2.3s\n",
            "[CV] END ............shrinkage=auto, solver=eigen, tol=0.001; total time=   4.4s\n",
            "[CV] END ............shrinkage=auto, solver=eigen, tol=0.001; total time=   4.5s\n",
            "[CV] END ...........shrinkage=0.75, solver=eigen, tol=0.0001; total time=   2.2s\n",
            "[CV] END .............shrinkage=0.05, solver=lsqr, tol=0.001; total time=   1.9s\n",
            "[CV] END ............shrinkage=auto, solver=eigen, tol=0.001; total time=   4.5s\n",
            "[CV] END ...........shrinkage=0.75, solver=eigen, tol=0.0001; total time=   2.3s\n",
            "[CV] END .............shrinkage=0.05, solver=lsqr, tol=0.001; total time=   2.2s\n",
            "[CV] END .............shrinkage=0.05, solver=lsqr, tol=0.001; total time=   2.2s\n",
            "[CV] END ...........shrinkage=0.75, solver=eigen, tol=0.0001; total time=   2.5s\n",
            "[CV] END .............shrinkage=0.35, solver=eigen, tol=0.01; total time=   2.2s\n",
            "[CV] END ........solver=svd, store_covariance=True, tol=0.01; total time=   7.0s\n",
            "[CV] END .............shrinkage=0.35, solver=eigen, tol=0.01; total time=   2.6s\n",
            "[CV] END ..............shrinkage=0.65, solver=lsqr, tol=0.01; total time=   1.8s\n",
            "[CV] END .............shrinkage=0.35, solver=eigen, tol=0.01; total time=   2.3s\n",
            "[CV] END ..............shrinkage=0.65, solver=lsqr, tol=0.01; total time=   2.0s\n",
            "[CV] END ..............shrinkage=0.65, solver=lsqr, tol=0.01; total time=   1.9s\n",
            "[CV] END ........solver=svd, store_covariance=True, tol=0.01; total time=   7.3s\n",
            "[CV] END .............shrinkage=auto, solver=lsqr, tol=0.001; total time=   2.6s\n",
            "[CV] END .............shrinkage=auto, solver=lsqr, tol=0.001; total time=   2.4s\n",
            "[CV] END .............shrinkage=auto, solver=lsqr, tol=0.001; total time=   2.5s\n",
            "[CV] END ..............shrinkage=None, solver=lsqr, tol=0.01; total time=   1.4s\n",
            "[CV] END ..............shrinkage=0.15, solver=lsqr, tol=0.01; total time=   1.6s\n",
            "[CV] END ..............shrinkage=0.15, solver=lsqr, tol=0.01; total time=   1.7s\n",
            "[CV] END ..............shrinkage=0.15, solver=lsqr, tol=0.01; total time=   1.9s\n",
            "[CV] END ..............shrinkage=None, solver=lsqr, tol=0.01; total time=   2.0s\n",
            "[CV] END ..............shrinkage=None, solver=lsqr, tol=0.01; total time=   1.7s\n",
            "[CV] END ............shrinkage=None, solver=lsqr, tol=0.0001; total time=   1.5s\n",
            "[CV] END ............shrinkage=0.75, solver=lsqr, tol=0.0001; total time=   1.8s\n",
            "[CV] END ............shrinkage=0.75, solver=lsqr, tol=0.0001; total time=   2.1s\n",
            "[CV] END ............shrinkage=0.15, solver=lsqr, tol=0.0001; total time=   1.6s\n",
            "[CV] END ............shrinkage=None, solver=lsqr, tol=0.0001; total time=   1.7s\n",
            "[CV] END ............shrinkage=0.75, solver=lsqr, tol=0.0001; total time=   1.9s\n",
            "[CV] END ............shrinkage=0.15, solver=lsqr, tol=0.0001; total time=   1.6s\n",
            "[CV] END ............shrinkage=0.15, solver=lsqr, tol=0.0001; total time=   1.7s\n",
            "[CV] END ............shrinkage=None, solver=lsqr, tol=0.0001; total time=   1.9s\n",
            "[CV] END .............shrinkage=auto, solver=eigen, tol=0.01; total time=   3.1s\n",
            "[CV] END .............shrinkage=auto, solver=eigen, tol=0.01; total time=   2.9s\n",
            "[CV] END .............shrinkage=auto, solver=eigen, tol=0.01; total time=   3.2s\n",
            "[CV] END ......solver=svd, store_covariance=True, tol=0.0001; total time=   4.8s\n",
            "[CV] END ......solver=svd, store_covariance=True, tol=0.0001; total time=   4.8s\n",
            "[CV] END ......solver=svd, store_covariance=True, tol=0.0001; total time=   4.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model saved: ../src/models/exploration_phase/LDA_no_sampling.joblib\n",
            "INFO:src.models.exploration_phase.model_saver:Metadata saved: ../src/models/exploration_phase/LDA_no_sampling_metadata.pkl\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model LDA saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check if model already exists\n",
        "classifier_name = \"LDA\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_lda = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    param_distributions = [\n",
        "        {\n",
        "            \"solver\": [\"svd\"],\n",
        "            \"store_covariance\": [False, True],\n",
        "            \"tol\": [1e-4, 1e-3, 1e-2],\n",
        "            # n_components kept implicit (None) to avoid invalid values vs. n_classes-1\n",
        "        },\n",
        "        {\n",
        "            \"solver\": [\"lsqr\", \"eigen\"],\n",
        "            \"shrinkage\": [None, \"auto\", 0.0, 0.05, 0.1, 0.15, 0.25, 0.35, 0.5, 0.65, 0.75, 0.85, 0.9],\n",
        "            \"tol\": [1e-4, 1e-3, 1e-2],\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
        "\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "    rs_lda = RandomizedSearchCV(\n",
        "        estimator=lda,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=50,\n",
        "        scoring=scoring,\n",
        "        refit=\"f1_macro\",\n",
        "        cv=cv,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "\n",
        "    rs_lda.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        \"best_params\": rs_lda.best_params_,\n",
        "        \"best_score\": rs_lda.best_score_,\n",
        "        \"cv_results\": rs_lda.cv_results_,\n",
        "        \"experiment\": experiment_name,\n",
        "        \"classifier\": classifier_name,\n",
        "    }\n",
        "\n",
        "    model_saver.save_model(classifier_name, rs_lda, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_lda = rs_lda.best_estimator_\n",
        "results['LDA'] = eval_model(\n",
        "    best_lda,\n",
        "    X_train_s, y_train,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(shrinkage=&#x27;auto&#x27;, solver=&#x27;lsqr&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis(shrinkage=&#x27;auto&#x27;, solver=&#x27;lsqr&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'tol': 0.0001, 'solver': 'lsqr', 'shrinkage': 'auto'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.8941297396071265,\n",
              "  'precision_macro': 0.6346495795067106,\n",
              "  'recall_macro': 0.6599108158462592,\n",
              "  'f1_macro': 0.6339529523776317,\n",
              "  'precision_per_class': array([0.94157365, 0.56157635, 0.5323475 , 0.18181818, 0.9559322 ]),\n",
              "  'recall_per_class': array([0.94274283, 0.51351351, 0.49740933, 0.46875   , 0.87713841]),\n",
              "  'f1_per_class': array([0.94215788, 0.53647059, 0.51428571, 0.26200873, 0.91484185]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[6833,   69,  227,  106,   13],\n",
              "         [  94,  114,   10,    4,    0],\n",
              "         [ 234,   19,  288,   25,   13],\n",
              "         [  29,    0,    5,   30,    0],\n",
              "         [  67,    1,   11,    0,  564]])},\n",
              " 'test': {'accuracy': 0.8933857116754979,\n",
              "  'precision_macro': 0.6406346941002119,\n",
              "  'recall_macro': 0.6505553927969936,\n",
              "  'f1_macro': 0.6284933290106093,\n",
              "  'precision_per_class': array([0.93934237, 0.58119658, 0.56112377, 0.15560166, 0.96590909]),\n",
              "  'recall_per_class': array([0.94447511, 0.48920863, 0.51035912, 0.46296296, 0.84577114]),\n",
              "  'f1_per_class': array([0.94190175, 0.53125   , 0.53453888, 0.23291925, 0.90185676]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17112,   141,   509,   332,    24],\n",
              "         [  246,   272,    32,     6,     0],\n",
              "         [  565,    53,   739,    67,    24],\n",
              "         [   81,     0,     6,    75,     0],\n",
              "         [  213,     2,    31,     2,  1360]])}}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_lda)\n",
        "display(rs_lda.best_params_)\n",
        "results['LDA']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.8 Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ANN not found. Training new model...\n",
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV] END activation=relu, alpha=0.0096476850757201, batch_size=96, beta_1=0.9273818018663584, beta_2=0.9757130651499796, hidden_layer_sizes=(64,), learning_rate_init=0.001955370866274525, validation_fraction=0.1; total time=  14.7s\n",
            "[CV] END activation=relu, alpha=0.0096476850757201, batch_size=96, beta_1=0.9273818018663584, beta_2=0.9757130651499796, hidden_layer_sizes=(64,), learning_rate_init=0.001955370866274525, validation_fraction=0.1; total time=  21.4s\n",
            "[CV] END activation=relu, alpha=0.00032927591344236165, batch_size=67, beta_1=0.928053996848047, beta_2=0.9754833330377127, hidden_layer_sizes=(128,), learning_rate_init=0.003695730787054511, validation_fraction=0.1; total time=  24.5s\n",
            "[CV] END activation=relu, alpha=0.00013066739238053285, batch_size=87, beta_1=0.9585799625653968, beta_2=0.9527641673723278, hidden_layer_sizes=(128,), learning_rate_init=0.0016305687346221474, validation_fraction=0.15; total time=  25.4s\n",
            "[CV] END activation=relu, alpha=0.00010629918194937652, batch_size=123, beta_1=0.9506959396060986, beta_2=0.9688854086244558, hidden_layer_sizes=(128,), learning_rate_init=0.0012521954287060388, validation_fraction=0.15; total time=  25.4s\n",
            "[CV] END activation=relu, alpha=0.0096476850757201, batch_size=96, beta_1=0.9273818018663584, beta_2=0.9757130651499796, hidden_layer_sizes=(64,), learning_rate_init=0.001955370866274525, validation_fraction=0.1; total time=  25.6s\n",
            "[CV] END activation=relu, alpha=0.0010677482709481358, batch_size=127, beta_1=0.9420086603923182, beta_2=0.9921370799300797, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014808945119975188, validation_fraction=0.1; total time=  30.8s\n",
            "[CV] END activation=relu, alpha=0.00010629918194937652, batch_size=123, beta_1=0.9506959396060986, beta_2=0.9688854086244558, hidden_layer_sizes=(128,), learning_rate_init=0.0012521954287060388, validation_fraction=0.15; total time=  31.0s\n",
            "[CV] END activation=relu, alpha=0.0005611516415334506, batch_size=78, beta_1=0.9658794547630265, beta_2=0.9793342657256547, hidden_layer_sizes=(128, 64), learning_rate_init=0.0027914686374528727, validation_fraction=0.1; total time=  33.2s\n",
            "[CV] END activation=relu, alpha=0.0010677482709481358, batch_size=127, beta_1=0.9420086603923182, beta_2=0.9921370799300797, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014808945119975188, validation_fraction=0.1; total time=  33.5s\n",
            "[CV] END activation=relu, alpha=0.00010629918194937652, batch_size=123, beta_1=0.9506959396060986, beta_2=0.9688854086244558, hidden_layer_sizes=(128,), learning_rate_init=0.0012521954287060388, validation_fraction=0.15; total time=  34.2s\n",
            "[CV] END activation=relu, alpha=0.0006305535040199287, batch_size=123, beta_1=0.9329725658964323, beta_2=0.9723474292266348, hidden_layer_sizes=(128, 64), learning_rate_init=0.004153230257664391, validation_fraction=0.15; total time=  35.2s\n",
            "[CV] END activation=relu, alpha=0.00032927591344236165, batch_size=67, beta_1=0.928053996848047, beta_2=0.9754833330377127, hidden_layer_sizes=(128,), learning_rate_init=0.003695730787054511, validation_fraction=0.1; total time=  35.4s\n",
            "[CV] END activation=relu, alpha=0.00869299151113955, batch_size=107, beta_1=0.984554904740777, beta_2=0.9938465401709548, hidden_layer_sizes=(128,), learning_rate_init=0.005336690243421028, validation_fraction=0.1; total time=  22.1s\n",
            "[CV] END activation=relu, alpha=0.00013066739238053285, batch_size=87, beta_1=0.9585799625653968, beta_2=0.9527641673723278, hidden_layer_sizes=(128,), learning_rate_init=0.0016305687346221474, validation_fraction=0.15; total time=  37.0s\n",
            "[CV] END activation=relu, alpha=0.0003034247005811288, batch_size=123, beta_1=0.9109834411360301, beta_2=0.9742636685954522, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014906121385323263, validation_fraction=0.1; total time=  37.2s\n",
            "[CV] END activation=relu, alpha=0.00013066739238053285, batch_size=87, beta_1=0.9585799625653968, beta_2=0.9527641673723278, hidden_layer_sizes=(128,), learning_rate_init=0.0016305687346221474, validation_fraction=0.15; total time=  39.0s\n",
            "[CV] END activation=relu, alpha=0.0006305535040199287, batch_size=123, beta_1=0.9329725658964323, beta_2=0.9723474292266348, hidden_layer_sizes=(128, 64), learning_rate_init=0.004153230257664391, validation_fraction=0.15; total time=  41.8s\n",
            "[CV] END activation=relu, alpha=0.00032927591344236165, batch_size=67, beta_1=0.928053996848047, beta_2=0.9754833330377127, hidden_layer_sizes=(128,), learning_rate_init=0.003695730787054511, validation_fraction=0.1; total time=  42.1s\n",
            "[CV] END activation=relu, alpha=0.0005611516415334506, batch_size=78, beta_1=0.9658794547630265, beta_2=0.9793342657256547, hidden_layer_sizes=(128, 64), learning_rate_init=0.0027914686374528727, validation_fraction=0.1; total time=  44.6s\n",
            "[CV] END activation=relu, alpha=0.0003034247005811288, batch_size=123, beta_1=0.9109834411360301, beta_2=0.9742636685954522, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014906121385323263, validation_fraction=0.1; total time=  47.5s\n",
            "[CV] END activation=relu, alpha=0.0003034247005811288, batch_size=123, beta_1=0.9109834411360301, beta_2=0.9742636685954522, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014906121385323263, validation_fraction=0.1; total time=  49.6s\n",
            "[CV] END activation=relu, alpha=0.0005611516415334506, batch_size=78, beta_1=0.9658794547630265, beta_2=0.9793342657256547, hidden_layer_sizes=(128, 64), learning_rate_init=0.0027914686374528727, validation_fraction=0.1; total time=  56.5s\n",
            "[CV] END activation=relu, alpha=0.00869299151113955, batch_size=107, beta_1=0.984554904740777, beta_2=0.9938465401709548, hidden_layer_sizes=(128,), learning_rate_init=0.005336690243421028, validation_fraction=0.1; total time=  33.1s\n",
            "[CV] END activation=relu, alpha=0.0006305535040199287, batch_size=123, beta_1=0.9329725658964323, beta_2=0.9723474292266348, hidden_layer_sizes=(128, 64), learning_rate_init=0.004153230257664391, validation_fraction=0.15; total time= 1.0min\n",
            "[CV] END activation=relu, alpha=0.009413993046829943, batch_size=64, beta_1=0.9178844113380755, beta_2=0.9502705837390565, hidden_layer_sizes=(128, 64), learning_rate_init=0.0015806743432481031, validation_fraction=0.15; total time=  29.9s\n",
            "[CV] END activation=relu, alpha=0.00015030900645056822, batch_size=125, beta_1=0.9292797297686938, beta_2=0.9690451871947846, hidden_layer_sizes=(128,), learning_rate_init=0.003464911387927851, validation_fraction=0.15; total time=  39.3s\n",
            "[CV] END activation=relu, alpha=0.00869299151113955, batch_size=107, beta_1=0.984554904740777, beta_2=0.9938465401709548, hidden_layer_sizes=(128,), learning_rate_init=0.005336690243421028, validation_fraction=0.1; total time=  43.7s\n",
            "[CV] END activation=relu, alpha=0.0028708753481954683, batch_size=96, beta_1=0.9545363977302911, beta_2=0.9953887430471541, hidden_layer_sizes=(128,), learning_rate_init=0.0013057771348997226, validation_fraction=0.1; total time=  30.2s\n",
            "[CV] END activation=relu, alpha=0.0010677482709481358, batch_size=127, beta_1=0.9420086603923182, beta_2=0.9921370799300797, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014808945119975188, validation_fraction=0.1; total time= 1.1min\n",
            "[CV] END activation=relu, alpha=0.002878805718308925, batch_size=98, beta_1=0.9424993432645754, beta_2=0.9558601180509767, hidden_layer_sizes=(128,), learning_rate_init=0.007061774157217603, validation_fraction=0.1; total time=  24.4s\n",
            "[CV] END activation=relu, alpha=0.0028708753481954683, batch_size=96, beta_1=0.9545363977302911, beta_2=0.9953887430471541, hidden_layer_sizes=(128,), learning_rate_init=0.0013057771348997226, validation_fraction=0.1; total time=  32.6s\n",
            "[CV] END activation=relu, alpha=0.005012762811014231, batch_size=75, beta_1=0.9297808222367384, beta_2=0.9531143591640151, hidden_layer_sizes=(128, 64), learning_rate_init=0.004664888338326056, validation_fraction=0.1; total time=  29.1s\n",
            "[CV] END activation=relu, alpha=0.0028708753481954683, batch_size=96, beta_1=0.9545363977302911, beta_2=0.9953887430471541, hidden_layer_sizes=(128,), learning_rate_init=0.0013057771348997226, validation_fraction=0.1; total time=  36.5s\n",
            "[CV] END activation=relu, alpha=0.00015030900645056822, batch_size=125, beta_1=0.9292797297686938, beta_2=0.9690451871947846, hidden_layer_sizes=(128,), learning_rate_init=0.003464911387927851, validation_fraction=0.15; total time=  52.6s\n",
            "[CV] END activation=relu, alpha=0.00016435497475111326, batch_size=126, beta_1=0.9806187236106167, beta_2=0.9732931409359235, hidden_layer_sizes=(64,), learning_rate_init=0.0032253042671791196, validation_fraction=0.15; total time=  18.2s\n",
            "[CV] END activation=relu, alpha=0.0005170191786366995, batch_size=123, beta_1=0.9488426474842424, beta_2=0.9569052870237633, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014630761777791696, validation_fraction=0.1; total time=  49.6s\n",
            "[CV] END activation=relu, alpha=0.00016435497475111326, batch_size=126, beta_1=0.9806187236106167, beta_2=0.9732931409359235, hidden_layer_sizes=(64,), learning_rate_init=0.0032253042671791196, validation_fraction=0.15; total time=  18.3s\n",
            "[CV] END activation=relu, alpha=0.002878805718308925, batch_size=98, beta_1=0.9424993432645754, beta_2=0.9558601180509767, hidden_layer_sizes=(128,), learning_rate_init=0.007061774157217603, validation_fraction=0.1; total time=  35.2s\n",
            "[CV] END activation=relu, alpha=0.002878805718308925, batch_size=98, beta_1=0.9424993432645754, beta_2=0.9558601180509767, hidden_layer_sizes=(128,), learning_rate_init=0.007061774157217603, validation_fraction=0.1; total time=  41.4s\n",
            "[CV] END activation=relu, alpha=0.00016435497475111326, batch_size=126, beta_1=0.9806187236106167, beta_2=0.9732931409359235, hidden_layer_sizes=(64,), learning_rate_init=0.0032253042671791196, validation_fraction=0.15; total time=  18.9s\n",
            "[CV] END activation=relu, alpha=0.0005170191786366995, batch_size=123, beta_1=0.9488426474842424, beta_2=0.9569052870237633, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014630761777791696, validation_fraction=0.1; total time=  51.5s\n",
            "[CV] END activation=relu, alpha=0.005012762811014231, batch_size=75, beta_1=0.9297808222367384, beta_2=0.9531143591640151, hidden_layer_sizes=(128, 64), learning_rate_init=0.004664888338326056, validation_fraction=0.1; total time=  47.0s\n",
            "[CV] END activation=relu, alpha=0.0005170191786366995, batch_size=123, beta_1=0.9488426474842424, beta_2=0.9569052870237633, hidden_layer_sizes=(128, 64), learning_rate_init=0.0014630761777791696, validation_fraction=0.1; total time=  55.9s\n",
            "[CV] END activation=relu, alpha=0.005766810466779011, batch_size=105, beta_1=0.9727308341607975, beta_2=0.9810367840690107, hidden_layer_sizes=(128,), learning_rate_init=0.0028611101001573156, validation_fraction=0.15; total time=  18.3s\n",
            "[CV] END activation=relu, alpha=0.00015030900645056822, batch_size=125, beta_1=0.9292797297686938, beta_2=0.9690451871947846, hidden_layer_sizes=(128,), learning_rate_init=0.003464911387927851, validation_fraction=0.15; total time= 1.0min\n",
            "[CV] END activation=relu, alpha=0.005766810466779011, batch_size=105, beta_1=0.9727308341607975, beta_2=0.9810367840690107, hidden_layer_sizes=(128,), learning_rate_init=0.0028611101001573156, validation_fraction=0.15; total time=  20.5s\n",
            "[CV] END activation=relu, alpha=0.005012762811014231, batch_size=75, beta_1=0.9297808222367384, beta_2=0.9531143591640151, hidden_layer_sizes=(128, 64), learning_rate_init=0.004664888338326056, validation_fraction=0.1; total time=  52.8s\n",
            "[CV] END activation=relu, alpha=0.00018996032713181662, batch_size=78, beta_1=0.9679996024688744, beta_2=0.9612111101090894, hidden_layer_sizes=(128, 64), learning_rate_init=0.0019487290213568475, validation_fraction=0.15; total time=  24.7s\n",
            "[CV] END activation=relu, alpha=0.005766810466779011, batch_size=105, beta_1=0.9727308341607975, beta_2=0.9810367840690107, hidden_layer_sizes=(128,), learning_rate_init=0.0028611101001573156, validation_fraction=0.15; total time=  19.7s\n",
            "[CV] END activation=relu, alpha=0.009413993046829943, batch_size=64, beta_1=0.9178844113380755, beta_2=0.9502705837390565, hidden_layer_sizes=(128, 64), learning_rate_init=0.0015806743432481031, validation_fraction=0.15; total time=  58.5s\n",
            "[CV] END activation=relu, alpha=0.00018996032713181662, batch_size=78, beta_1=0.9679996024688744, beta_2=0.9612111101090894, hidden_layer_sizes=(128, 64), learning_rate_init=0.0019487290213568475, validation_fraction=0.15; total time=  28.8s\n",
            "[CV] END activation=relu, alpha=0.0013260331922696556, batch_size=77, beta_1=0.9444416036727952, beta_2=0.9756139086397176, hidden_layer_sizes=(128, 64), learning_rate_init=0.0012908947091547854, validation_fraction=0.15; total time=  45.3s\n",
            "[CV] END activation=relu, alpha=0.00023612399244412623, batch_size=93, beta_1=0.9794952233026981, beta_2=0.9658929060292584, hidden_layer_sizes=(128, 64), learning_rate_init=0.00787211264452507, validation_fraction=0.1; total time=  17.2s\n",
            "[CV] END activation=relu, alpha=0.009413993046829943, batch_size=64, beta_1=0.9178844113380755, beta_2=0.9502705837390565, hidden_layer_sizes=(128, 64), learning_rate_init=0.0015806743432481031, validation_fraction=0.15; total time= 1.0min\n",
            "[CV] END activation=relu, alpha=0.00023612399244412623, batch_size=93, beta_1=0.9794952233026981, beta_2=0.9658929060292584, hidden_layer_sizes=(128, 64), learning_rate_init=0.00787211264452507, validation_fraction=0.1; total time=  16.3s\n",
            "[CV] END activation=relu, alpha=0.0013260331922696556, batch_size=77, beta_1=0.9444416036727952, beta_2=0.9756139086397176, hidden_layer_sizes=(128, 64), learning_rate_init=0.0012908947091547854, validation_fraction=0.15; total time=  41.9s\n",
            "[CV] END activation=relu, alpha=0.0013260331922696556, batch_size=77, beta_1=0.9444416036727952, beta_2=0.9756139086397176, hidden_layer_sizes=(128, 64), learning_rate_init=0.0012908947091547854, validation_fraction=0.15; total time=  44.4s\n",
            "[CV] END activation=relu, alpha=0.00023612399244412623, batch_size=93, beta_1=0.9794952233026981, beta_2=0.9658929060292584, hidden_layer_sizes=(128, 64), learning_rate_init=0.00787211264452507, validation_fraction=0.1; total time=  29.4s\n",
            "[CV] END activation=relu, alpha=0.00018996032713181662, batch_size=78, beta_1=0.9679996024688744, beta_2=0.9612111101090894, hidden_layer_sizes=(128, 64), learning_rate_init=0.0019487290213568475, validation_fraction=0.15; total time=  36.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model saved: ../src/models/exploration_phase/ANN_no_sampling.joblib\n",
            "INFO:src.models.exploration_phase.model_saver:Metadata saved: ../src/models/exploration_phase/ANN_no_sampling_metadata.pkl\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model ANN saved successfully!\n"
          ]
        }
      ],
      "source": [
        "classifier_name = \"ANN\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_lda = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    ann = MLPClassifier(\n",
        "        max_iter=300,\n",
        "        early_stopping=True,\n",
        "        random_state=random_state,\n",
        "        n_iter_no_change=10,\n",
        "        solver=\"adam\",\n",
        "    )\n",
        "\n",
        "\n",
        "    param_distributions = {\n",
        "        \"hidden_layer_sizes\": [\n",
        "            (64,),\n",
        "            (128,),\n",
        "            (128, 64),\n",
        "        ],\n",
        "        \"activation\": [\"relu\"],  # focused, fast\n",
        "        \"alpha\": loguniform(1e-4, 1e-2),  # L2\n",
        "        \"learning_rate_init\": loguniform(1e-3, 1e-2),\n",
        "        \"batch_size\": randint(64, 129),\n",
        "        \"beta_1\": uniform(0.9, 0.09),   # ~0.90-0.99\n",
        "        \"beta_2\": uniform(0.95, 0.049), # ~0.95-0.999\n",
        "        \"validation_fraction\": [0.1, 0.15],\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
        "\n",
        "    rs_ann = RandomizedSearchCV(\n",
        "        estimator=ann,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit=\"f1_macro\",\n",
        "        cv=cv,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_ann.fit(X_train_s, y_train)\n",
        "    \n",
        "    metadata = {\n",
        "        \"best_params\": rs_ann.best_params_,\n",
        "        \"best_score\": rs_ann.best_score_,\n",
        "        \"cv_results\": rs_ann.cv_results_,\n",
        "        \"experiment\": experiment_name,\n",
        "        \"classifier\": classifier_name,\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_ann, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_ann = rs_ann.best_estimator_\n",
        "results['ANN'] = eval_model(\n",
        "    best_ann,\n",
        "    X_train_s, y_train,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.0005170191786366995, batch_size=123,\n",
              "              beta_1=0.9488426474842424, beta_2=0.9569052870237633,\n",
              "              early_stopping=True, hidden_layer_sizes=(128, 64),\n",
              "              learning_rate_init=0.0014630761777791696, max_iter=300,\n",
              "              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.0005170191786366995, batch_size=123,\n",
              "              beta_1=0.9488426474842424, beta_2=0.9569052870237633,\n",
              "              early_stopping=True, hidden_layer_sizes=(128, 64),\n",
              "              learning_rate_init=0.0014630761777791696, max_iter=300,\n",
              "              random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(alpha=0.0005170191786366995, batch_size=123,\n",
              "              beta_1=0.9488426474842424, beta_2=0.9569052870237633,\n",
              "              early_stopping=True, hidden_layer_sizes=(128, 64),\n",
              "              learning_rate_init=0.0014630761777791696, max_iter=300,\n",
              "              random_state=42)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.8895580263203478"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9809273640931933,\n",
              "  'precision_macro': 0.9202085425774307,\n",
              "  'recall_macro': 0.8750374326674202,\n",
              "  'f1_macro': 0.8959547701775328,\n",
              "  'precision_per_class': array([0.98765432, 0.88421053, 0.94415358, 0.80357143, 0.98145286]),\n",
              "  'recall_per_class': array([0.99337748, 0.75675676, 0.9343696 , 0.703125  , 0.98755832]),\n",
              "  'f1_per_class': array([0.99050764, 0.81553398, 0.93923611, 0.75      , 0.98449612]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7200,   18,   17,    6,    7],\n",
              "         [  50,  168,    2,    0,    2],\n",
              "         [  26,    4,  541,    5,    3],\n",
              "         [   8,    0,   11,   45,    0],\n",
              "         [   6,    0,    2,    0,  635]])},\n",
              " 'test': {'accuracy': 0.9778457884158597,\n",
              "  'precision_macro': 0.9155768607194622,\n",
              "  'recall_macro': 0.8594817664280281,\n",
              "  'f1_macro': 0.8849524970380223,\n",
              "  'precision_per_class': array([0.98451521, 0.86067416, 0.93907563, 0.80985915, 0.98376015]),\n",
              "  'recall_per_class': array([0.99310078, 0.68884892, 0.92610497, 0.70987654, 0.97947761]),\n",
              "  'f1_per_class': array([0.98878936, 0.76523477, 0.9325452 , 0.75657895, 0.98161421]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17993,    50,    48,    10,    17],\n",
              "         [  156,   383,    12,     0,     5],\n",
              "         [   77,     9,  1341,    17,     4],\n",
              "         [   26,     0,    21,   115,     0],\n",
              "         [   24,     3,     6,     0,  1575]])}}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_ann)\n",
        "display(rs_ann.best_score_)\n",
        "results['ANN']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.9 Results Summary and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "MODEL COMPARISON WITH BEST PARAMETERS FROM RANDOMIZEDSEARCHCV\n",
            "====================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_f1_macro</th>\n",
              "      <th>best_cv_score</th>\n",
              "      <th>best_parameters</th>\n",
              "      <th>val_f1_cls_0</th>\n",
              "      <th>val_f1_cls_1</th>\n",
              "      <th>val_f1_cls_2</th>\n",
              "      <th>val_f1_cls_3</th>\n",
              "      <th>val_f1_cls_4</th>\n",
              "      <th>test_f1_cls_0</th>\n",
              "      <th>test_f1_cls_1</th>\n",
              "      <th>test_f1_cls_2</th>\n",
              "      <th>test_f1_cls_3</th>\n",
              "      <th>test_f1_cls_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "      <td>{'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha...</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.88</td>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 4, 'p':...</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.88</td>\n",
              "      <td>{'n_estimators': 200, 'min_samples_split': 20,...</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.87</td>\n",
              "      <td>{'kernel': 'poly', 'gamma': 0.01, 'C': 10}</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.83</td>\n",
              "      <td>{'splitter': 'best', 'min_samples_split': 20, ...</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>{'C': 4.0428727350273315, 'penalty': 'l2', 'so...</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model  val_accuracy  val_f1_macro  test_accuracy  \\\n",
              "0             XGBoost          0.98          0.90           0.98   \n",
              "1                 KNN          0.98          0.89           0.98   \n",
              "2        RandomForest          0.98          0.89           0.97   \n",
              "3                 SVM          0.97          0.88           0.97   \n",
              "4        DecisionTree          0.96          0.82           0.96   \n",
              "5  LogisticRegression          0.92          0.68           0.92   \n",
              "\n",
              "   test_f1_macro  best_cv_score  \\\n",
              "0           0.90           0.90   \n",
              "1           0.88           0.88   \n",
              "2           0.88           0.88   \n",
              "3           0.87           0.87   \n",
              "4           0.81           0.83   \n",
              "5           0.66           0.66   \n",
              "\n",
              "                                     best_parameters  val_f1_cls_0  \\\n",
              "0  {'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha...          0.99   \n",
              "1  {'metric': 'manhattan', 'n_neighbors': 4, 'p':...          0.99   \n",
              "2  {'n_estimators': 200, 'min_samples_split': 20,...          0.99   \n",
              "3         {'kernel': 'poly', 'gamma': 0.01, 'C': 10}          0.99   \n",
              "4  {'splitter': 'best', 'min_samples_split': 20, ...          0.98   \n",
              "5  {'C': 4.0428727350273315, 'penalty': 'l2', 'so...          0.95   \n",
              "\n",
              "   val_f1_cls_1  val_f1_cls_2  val_f1_cls_3  val_f1_cls_4  test_f1_cls_0  \\\n",
              "0          0.80          0.94          0.79          0.99           0.99   \n",
              "1          0.79          0.94          0.76          0.99           0.99   \n",
              "2          0.80          0.93          0.73          0.98           0.99   \n",
              "3          0.76          0.91          0.77          0.99           0.99   \n",
              "4          0.68          0.88          0.60          0.95           0.98   \n",
              "5          0.61          0.46          0.44          0.93           0.95   \n",
              "\n",
              "   test_f1_cls_1  test_f1_cls_2  test_f1_cls_3  test_f1_cls_4  \n",
              "0           0.81           0.95           0.79           0.98  \n",
              "1           0.77           0.93           0.75           0.98  \n",
              "2           0.78           0.93           0.76           0.97  \n",
              "3           0.74           0.91           0.72           0.98  \n",
              "4           0.67           0.88           0.59           0.95  \n",
              "5           0.56           0.44           0.45           0.92  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def _safe_col(label):\n",
        "    # Make safe column names like \"val_f1_cls_0\" or \"val_f1_cls_N\"\n",
        "    return re.sub(r'[^0-9a-zA-Z_]+', '_', str(label)).strip('_')\n",
        "\n",
        "# Mapping of model names to their RandomizedSearchCV objects\n",
        "models_and_searchers = {\n",
        "    \"LogisticRegression\": rs_logreg,\n",
        "    \"KNN\": rs_knn, \n",
        "    \"RandomForest\": rs_rf,\n",
        "    \"SVM\": rs_svm,\n",
        "    \"DecisionTree\": rs_dt,\n",
        "    \"XGBoost\": rs_xgb,\n",
        "    \"LDA\": rs_lda,\n",
        "    \"ANN\": rs_ann,\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, res in results.items():\n",
        "    row = {\n",
        "        'model': name,\n",
        "        'test_accuracy': round(res['test']['accuracy'], 2),\n",
        "        'test_f1_macro': round(res['test']['f1_macro'], 2),\n",
        "    }\n",
        "\n",
        "    # Add best parameters from RandomizedSearchCV\n",
        "    if name in models_and_searchers:\n",
        "        searcher = models_and_searchers[name]\n",
        "        best_params = searcher.best_params_\n",
        "        best_cv_score = searcher.best_score_\n",
        "        row['best_cv_score'] = round(best_cv_score, 2)\n",
        "        row['best_parameters'] = str(best_params)\n",
        "    else:\n",
        "        row['best_cv_score'] = None\n",
        "        row['best_parameters'] = None\n",
        "\n",
        "    labels = res['labels']\n",
        "    f1_t = res['test']['f1_per_class']\n",
        "\n",
        "    # Add per-class F1 columns for test set only\n",
        "    for lbl, f1 in zip(labels, f1_t):\n",
        "        row[f'test_f1_cls_{_safe_col(lbl)}'] = round(f1, 2)\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "comparison_df = (\n",
        "    pd.DataFrame(rows)\n",
        "      .sort_values(by=['test_f1_macro'], ascending=False)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "best_model_name = comparison_df.iloc[0]['model']\n",
        "best_model_results = results[best_model_name]\n",
        "\n",
        "comparison_df_display = comparison_df.copy()\n",
        "comparison_df_display['best_parameters'] = comparison_df_display['best_parameters'].apply(\n",
        "    lambda x: json.dumps(x, indent=2) if isinstance(x, dict) else x\n",
        ")\n",
        "import os \n",
        "\n",
        "comparison_df_display.to_csv(\"../src/data/03_model_testing_results/model_comparison_without_resampling.csv\", index=False)\n",
        "\n",
        "# Display the comparison table with best parameters\n",
        "print(\"=\" * 100)\n",
        "print(\"MODEL COMPARISON WITH BEST PARAMETERS FROM RANDOMIZEDSEARCHCV\")\n",
        "print(\"=\" * 100)\n",
        "display(comparison_df_display)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SAVED MODELS INFORMATION\n",
            "================================================================================\n",
            "\n",
            "Model: DecisionTree_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/DecisionTree_no_sampling.joblib\n",
            "  Size: 232415 bytes\n",
            "  Modified: 1760415820.9521165\n",
            "\n",
            "Model: SVM_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/SVM_no_sampling.joblib\n",
            "  Size: 12504219 bytes\n",
            "  Modified: 1760415063.7689745\n",
            "\n",
            "Model: KNN_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/KNN_no_sampling.joblib\n",
            "  Size: 118528799 bytes\n",
            "  Modified: 1760396388.739042\n",
            "\n",
            "Model: RandomForest_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/RandomForest_no_sampling.joblib\n",
            "  Size: 48327727 bytes\n",
            "  Modified: 1760399598.0772789\n",
            "\n",
            "Model: LogisticRegression_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/LogisticRegression_no_sampling.joblib\n",
            "  Size: 26175 bytes\n",
            "  Modified: 1760395829.1684663\n",
            "\n",
            "Model: XGBoost_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/XGBoost_no_sampling.joblib\n",
            "  Size: 2872222 bytes\n",
            "  Modified: 1760417090.5740137\n"
          ]
        }
      ],
      "source": [
        "# Check saved models\n",
        "print(\"=\" * 80)\n",
        "print(\"SAVED MODELS INFORMATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "saved_models = model_saver.list_saved_models()\n",
        "if saved_models:\n",
        "    for model_key, info in saved_models.items():\n",
        "        print(f\"\\nModel: {model_key}\")\n",
        "        print(f\"  Exists: {info['exists']}\")\n",
        "        print(f\"  Path: {info['model_path']}\")\n",
        "        if info['exists']:\n",
        "            print(f\"  Size: {info['size_bytes']} bytes\")\n",
        "            print(f\"  Modified: {info['modified_time']}\")\n",
        "        \n",
        "        # Load and display metadata if available\n",
        "        if info['metadata_exists']:\n",
        "            try:\n",
        "                metadata = model_saver.load_metadata(model_key.split('_')[0], model_key.split('_')[1] if '_' in model_key else 'default')\n",
        "                if metadata:\n",
        "                    print(f\"  Best Score: {metadata.get('best_score', 'N/A')}\")\n",
        "                    print(f\"  Best Params: {metadata.get('best_params', 'N/A')}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error loading metadata: {e}\")\n",
        "else:\n",
        "    print(\"No saved models found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. With Sampling Methods\n",
        "\n",
        "but without\n",
        "- Feature Engineering ( RR-Interval! )\n",
        "- baseline wandering removal\n",
        "- denoising\n",
        "- Leak-Free Scaling\n",
        "- RepeatedStratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### 3.2.1 Quick run - Using the best models from above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing sampling methods on best models...\n",
            "================================================================================\n",
            "\n",
            "Testing No_Sampling...\n",
            "  - KNN\n",
            "  - RandomForest\n",
            "  - XGBoost\n",
            "\n",
            "Testing RandomOverSampler...\n",
            "  - KNN\n",
            "    Class distribution after RandomOverSampler:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - RandomForest\n",
            "    Class distribution after RandomOverSampler:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - XGBoost\n",
            "    Class distribution after RandomOverSampler:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "\n",
            "Testing SMOTE...\n",
            "  - KNN\n",
            "    Class distribution after SMOTE:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - RandomForest\n",
            "    Class distribution after SMOTE:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - XGBoost\n",
            "    Class distribution after SMOTE:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "\n",
            "Testing ADASYN...\n",
            "  - KNN\n",
            "    Class distribution after ADASYN:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,311 samples\n",
            "      Class 2: 65,243 samples\n",
            "      Class 3: 65,181 samples\n",
            "      Class 4: 65,200 samples\n",
            "  - RandomForest\n",
            "    Class distribution after ADASYN:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,311 samples\n",
            "      Class 2: 65,243 samples\n",
            "      Class 3: 65,181 samples\n",
            "      Class 4: 65,200 samples\n",
            "  - XGBoost\n",
            "    Class distribution after ADASYN:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,311 samples\n",
            "      Class 2: 65,243 samples\n",
            "      Class 3: 65,181 samples\n",
            "      Class 4: 65,200 samples\n",
            "\n",
            "Testing SMOTETomek...\n",
            "  - KNN\n",
            "    Class distribution after SMOTETomek:\n",
            "      Class 0: 65,220 samples\n",
            "      Class 1: 65,222 samples\n",
            "      Class 2: 65,221 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - RandomForest\n",
            "    Class distribution after SMOTETomek:\n",
            "      Class 0: 65,220 samples\n",
            "      Class 1: 65,222 samples\n",
            "      Class 2: 65,221 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - XGBoost\n",
            "    Class distribution after SMOTETomek:\n",
            "      Class 0: 65,220 samples\n",
            "      Class 1: 65,222 samples\n",
            "      Class 2: 65,221 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "\n",
            "Testing SMOTEENN...\n",
            "  - KNN\n",
            "    Class distribution after SMOTEENN:\n",
            "      Class 0: 61,969 samples\n",
            "      Class 1: 65,191 samples\n",
            "      Class 2: 65,186 samples\n",
            "      Class 3: 65,222 samples\n",
            "      Class 4: 65,211 samples\n",
            "  - RandomForest\n",
            "    Class distribution after SMOTEENN:\n",
            "      Class 0: 61,969 samples\n",
            "      Class 1: 65,191 samples\n",
            "      Class 2: 65,186 samples\n",
            "      Class 3: 65,222 samples\n",
            "      Class 4: 65,211 samples\n",
            "  - XGBoost\n",
            "    Class distribution after SMOTEENN:\n",
            "      Class 0: 61,969 samples\n",
            "      Class 1: 65,191 samples\n",
            "      Class 2: 65,186 samples\n",
            "      Class 3: 65,222 samples\n",
            "      Class 4: 65,211 samples\n"
          ]
        }
      ],
      "source": [
        "sampling_methods = {\n",
        "    'No_Sampling': None,\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=random_state),\n",
        "    'SMOTE': SMOTE(random_state=random_state, k_neighbors=5),\n",
        "    'ADASYN': ADASYN(random_state=random_state, n_neighbors=5),\n",
        "    'SMOTETomek': SMOTETomek(random_state=random_state, smote=SMOTE(random_state=random_state, k_neighbors=5)),\n",
        "    'SMOTEENN': SMOTEENN(random_state=random_state, smote=SMOTE(random_state=random_state, k_neighbors=5)),\n",
        "}\n",
        "\n",
        "sampling_results = {}\n",
        "\n",
        "best_models = {\n",
        "    'KNN': best_knn,\n",
        "    'RandomForest': best_rf,\n",
        "    'XGBoost': best_xgb,\n",
        "}\n",
        "\n",
        "scale_sensitive = ['LogisticRegression', 'SVM', 'KNN']\n",
        "\n",
        "print(\"Testing sampling methods on best models...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for sampling_name, sampler in sampling_methods.items():\n",
        "    print(f\"\\nTesting {sampling_name}...\")\n",
        "    sampling_results[sampling_name] = {}\n",
        "    \n",
        "    for model_name, model in best_models.items():\n",
        "        print(f\"  - {model_name}\")\n",
        "        \n",
        "        try:\n",
        "            if sampler is None:\n",
        "                # No sampling - use original, only scaled data\n",
        "                result = eval_model(model,\n",
        "                                    X_train_s if model_name in scale_sensitive else X_train , y_train,\n",
        "                                    X_test_s if model_name in scale_sensitive else X_test, y_test)\n",
        "            else:\n",
        "                # Apply sampling on unscaled data\n",
        "                X_train_sampled, y_train_sampled = sampler.fit_resample(X_train, y_train)\n",
        "                \n",
        "                # Re-scale if needed for models that require scaling\n",
        "                if model_name in scale_sensitive:\n",
        "                    scaler_sampling = StandardScaler()\n",
        "                    X_train_sampled = scaler_sampling.fit_transform(X_train_sampled)\n",
        "                    X_test_sampled = scaler_sampling.transform(X_test)\n",
        "                else: # e.g. RF, XGBoost\n",
        "                    X_test_sampled = X_test\n",
        "            \n",
        "                result = eval_model(\n",
        "                    model,\n",
        "                    X_train_sampled, y_train_sampled,\n",
        "                    X_test_sampled, y_test,\n",
        "                )\n",
        "            \n",
        "            sampling_results[sampling_name][model_name] = result\n",
        "            \n",
        "            # Printing statistics\n",
        "            if sampler is not None:\n",
        "                unique, counts = np.unique(y_train_sampled, return_counts=True)\n",
        "                print(f\"    Class distribution after {sampling_name}:\")\n",
        "                for cls, count in zip(unique, counts):\n",
        "                    print(f\"      Class {cls}: {count:,} samples\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"    ERROR with {sampling_name} + {model_name}: {str(e)}\")\n",
        "            sampling_results[sampling_name][model_name] = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create comprehensive comparison table\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"SAMPLING METHODS COMPARISON\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Prepare comparison data\n",
        "comparison_rows = []\n",
        "\n",
        "for sampling_name, models_results in sampling_results.items():\n",
        "    for model_name, result in models_results.items():\n",
        "        if result is not None:\n",
        "            row = {\n",
        "                'sampling_method': sampling_name,\n",
        "                'model': model_name,\n",
        "                'test_accuracy': round(result['test']['accuracy'],2),\n",
        "                'test_f1_macro': round(result['test']['f1_macro'],2)\n",
        "            }\n",
        "            \n",
        "            # Add per-class F1 scores for test set only\n",
        "            labels = result['labels']\n",
        "            f1_t = result['test']['f1_per_class']\n",
        "            \n",
        "            for lbl, f1 in zip(labels, f1_t):\n",
        "                row[f'test_f1_cls_{_safe_col(lbl)}'] = round(f1,2)\n",
        "            \n",
        "            comparison_rows.append(row)\n",
        "\n",
        "# Create and display comparison DataFrame\n",
        "sampling_comparison_df = (\n",
        "    pd.DataFrame(comparison_rows)\n",
        "    .sort_values(by=['test_f1_macro'], ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BEST COMBINATION:\n",
            "Sampling Method: RandomOverSampler\n",
            "Model: XGBoost\n",
            "Test F1-Macro: 0.9200\n",
            "Validation F1-Macro: 0.9200\n",
            "\n",
            "SUMMARY STATISTICS:\n",
            "Total combinations tested: 18\n",
            "Best test F1-macro: 0.9200\n",
            "Best validation F1-macro: 0.9200\n",
            "\n",
            "TOP 5 COMBINATIONS:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sampling_method</th>\n",
              "      <th>model</th>\n",
              "      <th>test_f1_macro</th>\n",
              "      <th>val_f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomOverSampler</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SMOTE</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SMOTETomek</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No_Sampling</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomOverSampler</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sampling_method         model  test_f1_macro  val_f1_macro\n",
              "0  RandomOverSampler       XGBoost           0.92          0.92\n",
              "1              SMOTE       XGBoost           0.91          0.91\n",
              "2         SMOTETomek       XGBoost           0.91          0.91\n",
              "3        No_Sampling       XGBoost           0.90          0.90\n",
              "4  RandomOverSampler  RandomForest           0.90          0.90"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sampling_comparison_df.to_csv(\"../reports/03_model_testing_results/model_comparison_with_sampling_on_best_models.csv\", index=False)\n",
        "\n",
        "# Find best combination\n",
        "best_sampling_model = sampling_comparison_df.iloc[0]\n",
        "print(f\"\\nBEST COMBINATION:\")\n",
        "print(f\"Sampling Method: {best_sampling_model['sampling_method']}\")\n",
        "print(f\"Model: {best_sampling_model['model']}\")\n",
        "print(f\"Test F1-Macro: {best_sampling_model['test_f1_macro']:.4f}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nSUMMARY STATISTICS:\")\n",
        "print(f\"Total combinations tested: {len(comparison_rows)}\")\n",
        "print(f\"Best test F1-macro: {sampling_comparison_df['test_f1_macro'].max():.4f}\")\n",
        "\n",
        "# Show top 5 combinations\n",
        "print(f\"\\nTOP 5 COMBINATIONS:\")\n",
        "top_5 = sampling_comparison_df.head(5)[['sampling_method', 'model', 'test_f1_macro']]\n",
        "display(top_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2.2 Extended Run: Sampling + RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Model Training Phase\n",
        "# This cell focuses only on training models with RandomizedSearchCV\n",
        "# Evaluation is separated to prevent interruption of cross-validation runs\n",
        "\n",
        "sampling_methods = {\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=random_state),\n",
        "    'SMOTE': SMOTE(random_state=random_state, k_neighbors=5),\n",
        "    'ADASYN': ADASYN(random_state=random_state, n_neighbors=5),\n",
        "    'SMOTETomek': SMOTETomek(random_state=random_state, smote=SMOTE(random_state=random_state, k_neighbors=5)),\n",
        "    'SMOTEENN': SMOTEENN(random_state=random_state, smote=SMOTE(random_state=random_state, k_neighbors=5)),\n",
        "}\n",
        "\n",
        "# Which models need scaling (no pipeline used; fit scaler once on the resampled training set)\n",
        "scale_sensitive = [\"LogisticRegression\", \"KNN\", \"SVM\", \"LDA\", \"ANN\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "print(\"Starting 3.2.2 TRAINING PHASE: Full RandomizedSearchCV for each model, per sampling method\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for sampling_name, sampler in sampling_methods.items():\n",
        "    print(f\"\\n=== Training with Sampling: {sampling_name} ===\")\n",
        "\n",
        "    # Apply sampling on original training set (before CV)\n",
        "    try:\n",
        "        if sampler is None:\n",
        "            X_train_res, y_train_res = X_train, y_train\n",
        "        else:\n",
        "            X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
        "    except Exception as e:\n",
        "        print(f\"  Skipping sampling '{sampling_name}' due to error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Show distribution if sampling applied\n",
        "    if sampler is not None:\n",
        "        unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "        print(\"  Class distribution after sampling:\")\n",
        "        for cls, cnt in zip(unique, counts):\n",
        "            print(f\"    Class {cls}: {cnt:,} samples\")\n",
        "\n",
        "    # For each model, run RS-CV on the resampled dataset (TRAINING ONLY)\n",
        "    for model_name, spec in param_spaces.items():\n",
        "        experiment_name = f\"with_sampling_{sampling_name}\"\n",
        "        classifier_name = model_name\n",
        "\n",
        "        # Prepare data (leak-prone scaling by design here; no pipelines)\n",
        "        if model_name in scale_sensitive:\n",
        "            scaler = StandardScaler()\n",
        "            X_tr_fit = scaler.fit_transform(X_train_res)\n",
        "        else:\n",
        "            X_tr_fit = X_train_res\n",
        "\n",
        "        # Train or load if already saved\n",
        "        try:\n",
        "            # Check if an RS-CV object already exists for this sampler+model\n",
        "            if model_saver.model_exists(classifier_name, experiment_name):\n",
        "                print(f\"  [{model_name}] Exists for {experiment_name}. LoaLoading next one...\")\n",
        "            else:\n",
        "                print(f\"  [{model_name}] Training RS-CV for {experiment_name}...\")\n",
        "                rs = RandomizedSearchCV(\n",
        "                    estimator=spec[\"estimator\"],\n",
        "                    param_distributions=spec[\"params\"],\n",
        "                    n_iter=spec[\"n_iter\"],\n",
        "                    scoring=scoring,\n",
        "                    refit=\"f1_macro\",\n",
        "                    cv=spec[\"cv\"],\n",
        "                    random_state=random_state,\n",
        "                    n_jobs=-1,\n",
        "                    verbose=2,\n",
        "                )\n",
        "                rs.fit(X_tr_fit, y_train_res)\n",
        "\n",
        "                metadata = {\n",
        "                    \"best_params\": rs.best_params_,\n",
        "                    \"best_score\": rs.best_score_,\n",
        "                    \"cv_results\": rs.cv_results_,\n",
        "                    \"experiment\": experiment_name,\n",
        "                    \"classifier\": classifier_name,\n",
        "                    \"sampling_method\": sampling_name,\n",
        "                }\n",
        "                model_saver.save_model(classifier_name, rs, experiment_name, metadata)\n",
        "                print(f\"  [{model_name}] Saved for {experiment_name}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  [{model_name}] ERROR for {experiment_name}: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TRAINING PHASE COMPLETED\")\n",
        "print(\"=\" * 80)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Model Evaluation Phase\n",
        "# This cell focuses only on evaluating the trained models\n",
        "# This separation prevents interruption of cross-validation runs from affecting evaluation\n",
        "\n",
        "print(\"Starting 3.2.2 EVALUATION PHASE: Evaluating trained models\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Result collectors\n",
        "all_results = []\n",
        "sampling_results = {}\n",
        "\n",
        "for sampling_name, sampler in sampling_methods.items():\n",
        "    print(f\"\\n=== Evaluating with Sampling: {sampling_name} ===\")\n",
        "    sampling_results[sampling_name] = {}\n",
        "\n",
        "    # Apply sampling on original training set (before CV)\n",
        "    try:\n",
        "        if sampler is None:\n",
        "            X_train_res, y_train_res = X_train, y_train\n",
        "        else:\n",
        "            X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
        "    except Exception as e:\n",
        "        print(f\"  Skipping sampling '{sampling_name}' due to error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # For each model, evaluate the trained model\n",
        "    for model_name, spec in param_spaces.items():\n",
        "        experiment_name = f\"with_sampling_{sampling_name}\"\n",
        "        classifier_name = model_name\n",
        "\n",
        "        # Prepare data (leak-prone scaling by design here; no pipelines)\n",
        "        if model_name in scale_sensitive:\n",
        "            scaler = StandardScaler()\n",
        "            X_tr_fit = scaler.fit_transform(X_train_res)\n",
        "            X_te_fit = scaler.transform(X_test)\n",
        "        else:\n",
        "            X_tr_fit, X_te_fit = X_train_res, X_test\n",
        "\n",
        "        # Load and evaluate the trained model\n",
        "        try:\n",
        "            # Load the trained RS-CV object\n",
        "            if model_saver.model_exists(classifier_name, experiment_name):\n",
        "                print(f\"  [{model_name}] Loading trained model for evaluation...\")\n",
        "                rs = model_saver.load_model(classifier_name, experiment_name)\n",
        "                \n",
        "                # Evaluate best estimator on test set\n",
        "                best_est = rs.best_estimator_\n",
        "                print(f\"  Evaluating model [{model_name}]\")\n",
        "                res = eval_model(\n",
        "                    best_est,\n",
        "                    X_tr_fit, y_train_res,\n",
        "                    X_te_fit, y_test,\n",
        "                )\n",
        "                sampling_results[sampling_name][model_name] = {\"rs\": rs, \"eval\": res}\n",
        "\n",
        "                # Build row for comparison table\n",
        "                row = {\n",
        "                    \"sampling_method\": sampling_name,\n",
        "                    \"model\": model_name,\n",
        "                    \"test_accuracy\": round(res[\"test\"][\"accuracy\"], 2),\n",
        "                    \"test_f1_macro\": round(res[\"test\"][\"f1_macro\"], 2),\n",
        "                    \"best_cv_score\": round(rs.best_score_, 2),\n",
        "                    \"best_parameters\": json.dumps(rs.best_params_),\n",
        "                }\n",
        "                print(row)\n",
        "\n",
        "                # Add per-class F1s for test set only\n",
        "                labels = res[\"labels\"]\n",
        "                for lbl, f1 in zip(labels, res[\"test\"][\"f1_per_class\"]):\n",
        "                    row[f\"test_f1_cls_{lbl}\"] = round(float(f1), 2)\n",
        "\n",
        "                all_results.append(row)\n",
        "            else:\n",
        "                print(f\"  [{model_name}] No trained model found for {experiment_name}\")\n",
        "                sampling_results[sampling_name][model_name] = None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  [{model_name}] ERROR for {experiment_name}: {e}\")\n",
        "            sampling_results[sampling_name][model_name] = None\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EVALUATION PHASE COMPLETED\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Results Comparison and Export\n",
        "if all_results:\n",
        "    comparison_df = (\n",
        "        pd.DataFrame(all_results)\n",
        "        .sort_values(by=[\"test_f1_macro\"], ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"FULL SAMPLING + RANDOMIZEDSEARCHCV COMPARISON\")\n",
        "    print(\"=\" * 100)\n",
        "    display(comparison_df[[\"sampling_method\", \"model\", \"test_f1_macro\"]].head(10))\n",
        "\n",
        "    # Save to CSV\n",
        "    out_path = \"../reports/03_model_testing_results/model_comparison_with_sampling_full_search.csv\"\n",
        "    comparison_df.to_csv(out_path, index=False)\n",
        "    print(f\"\\nSaved detailed results to: {out_path}\")\n",
        "else:\n",
        "    print(\"No results to display.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Possible improvements - Not Tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Run Sampler Tests with RandomizedSearchCV for better comparison + parameter tuning (3.2.2 )\n",
        "\n",
        "- Try to optimize the signal - run best models with the optimized signal and new features\n",
        "    - add RR-Interval as feature\n",
        "    - add new Target \"not_normal\" in MIT to compare to PTB\n",
        "    - baseline wandering removal\n",
        "    - denoising\n",
        "\n",
        "- Implement Leak-free scaling\n",
        "    - current: without pipeline: scale once on the full training set, then do CV on the already sclaed data --> scaler \"saw\" all CV folds, including each folds validation part --> data leakage\n",
        "    - makes CV too optimisic?\n",
        "    - pipeline fits the scaler only on each training fold, then applieos it to that folds validation split. \n",
        "    - solution: Pipeline(StandardScaler(), model) so scaling is fit per CV fold\n",
        "- RepeatedStratifiedKFold:\n",
        "    - single CV split can be \"lucky\" or \"unlucky\" --> dependency how data is shuffled\n",
        "    - repeating stratified k-fold with different shuffles averages out randomness\n",
        "    - more stable, less noisy estimates of performance\n",
        "\n",
        "- Apply best models to PTB Dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score, balanced_accuracy_score\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=10000, multi_class='multinomial'))\n",
        "])\n",
        "\n",
        "param_dist_logreg = {\n",
        "    'C': loguniform(1e-3, 1e3), # Big C = less penalty on large weights (more freedom, risk of overfitting). \n",
        "                                # Small C = more penalty (more discipline, less overfitting).\n",
        "                                # loguniform = means we try values spread across tiny to big scales (e.g., 0.001 up to 100), not just small steps.\n",
        "    'penalty': ['l2'], # gently pushes weights toward zero, which keeps the model simpler and more stable.\n",
        "    'solver': ['lbfgs'],\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=random_state)\n",
        "scoring = {'f1_macro': 'f1_macro', 'bal_acc': 'balanced_accuracy', 'f1_weighted': 'f1_weighted'}\n",
        "\n",
        "rs_logreg = RandomizedSearchCV(\n",
        "    pipe,\n",
        "    param_distributions=param_dist_logreg,\n",
        "    n_iter=20,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    random_state=random_state,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        ")\n",
        "rs_logreg.fit(X_train, y_train) # not fitting on X_train_s because Pipeline will do it for us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
