{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Testing\n",
        "\n",
        "Questions to be answered:\n",
        "\n",
        "- Remove outliers?\n",
        "- Which Sampling method to use?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from src.utils.preprocessing import (\n",
        "    prepare_mitbih, \n",
        "    prepare_ptbdb,\n",
        "    resample_training\n",
        ")\n",
        "from src.visualization import plot_confusion_matrix\n",
        "from src.utils import create_model_saver\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import loguniform, randint, uniform\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Init model saver\n",
        "model_saver = create_model_saver(\"../src/models/exploration_phase\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_model(model, X_tr, y_tr, X_va, y_va, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    yv = model.predict(X_va)\n",
        "    yt = model.predict(X_te)\n",
        "\n",
        "    # Choose a consistent label order (dynamic)\n",
        "    labels = np.unique(np.concatenate([y_tr, y_va, y_te]))\n",
        "\n",
        "    # Validation\n",
        "    acc_v = accuracy_score(y_va, yv)\n",
        "    p_v_m, r_v_m, f1_v_m, _ = precision_recall_fscore_support(\n",
        "        y_va, yv, average='macro', zero_division=0\n",
        "    )\n",
        "    p_v_c, r_v_c, f1_v_c, sup_v = precision_recall_fscore_support(\n",
        "        y_va, yv, average=None, labels=labels, zero_division=0\n",
        "    )\n",
        "    cm_v = confusion_matrix(y_va, yv, labels=labels)\n",
        "\n",
        "    # Test\n",
        "    acc_t = accuracy_score(y_te, yt)\n",
        "    p_t_m, r_t_m, f1_t_m, _ = precision_recall_fscore_support(\n",
        "        y_te, yt, average='macro', zero_division=0\n",
        "    )\n",
        "    p_t_c, r_t_c, f1_t_c, sup_t = precision_recall_fscore_support(\n",
        "        y_te, yt, average=None, labels=labels, zero_division=0\n",
        "    )\n",
        "    cm_t = confusion_matrix(y_te, yt, labels=labels)\n",
        "\n",
        "    return {\n",
        "        'labels': labels,  # order for per-class arrays below\n",
        "        'val': {\n",
        "            'accuracy': acc_v,\n",
        "            'precision_macro': p_v_m,\n",
        "            'recall_macro': r_v_m,\n",
        "            'f1_macro': f1_v_m,\n",
        "            'precision_per_class': p_v_c,\n",
        "            'recall_per_class': r_v_c,\n",
        "            'f1_per_class': f1_v_c,\n",
        "            'support_per_class': sup_v,\n",
        "            'confusion_matrix': cm_v,\n",
        "        },\n",
        "        'test': {\n",
        "            'accuracy': acc_t,\n",
        "            'precision_macro': p_t_m,\n",
        "            'recall_macro': r_t_m,\n",
        "            'f1_macro': f1_t_m,\n",
        "            'precision_per_class': p_t_c,\n",
        "            'recall_per_class': r_t_c,\n",
        "            'f1_per_class': f1_t_c,\n",
        "            'support_per_class': sup_t,\n",
        "            'confusion_matrix': cm_t,\n",
        "        },\n",
        "    }\n",
        "\n",
        "results = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MITBIH dataset prepared:\n",
            "  Training size: (78798, 187)\n",
            "  Validation size: (8756, 187)\n",
            "  Test size: (21892, 187)\n",
            "\n",
            "PTBDB dataset prepared:\n",
            "  Training size: (10472, 187)\n",
            "  Validation size: (1164, 187)\n",
            "  Test size: (2909, 187)\n"
          ]
        }
      ],
      "source": [
        "# Prepare datasets\n",
        "mitbih = prepare_mitbih(remove_outliers=False)\n",
        "\n",
        "print(\"MITBIH dataset prepared:\")\n",
        "print(f\"  Training size: {mitbih.X_train.shape}\")\n",
        "print(f\"  Validation size: {mitbih.X_val.shape if mitbih.X_val is not None else 'None'}\")\n",
        "print(f\"  Test size: {mitbih.X_test.shape if mitbih.X_test is not None else 'None'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, X_test = mitbih.X_train.values, mitbih.X_val.values, mitbih.X_test.values\n",
        "y_train = mitbih.y_train.astype(int).values\n",
        "y_val = mitbih.y_val.astype(int).values\n",
        "y_test = mitbih.y_test.astype(int).values\n",
        "\n",
        "# Scale features using train fit only\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "X_test_s = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test models with Randomized Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "scoring = {'f1_macro': 'f1_macro', 'bal_acc': 'balanced_accuracy', 'f1_weighted': 'f1_weighted'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Without outlier removal or sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/LogisticRegression_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model LogisticRegression already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"LogisticRegression\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_logreg = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    logreg = LogisticRegression(max_iter=10000, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "    param_dist_logreg = {\n",
        "        'C': loguniform(1e-3, 1e3), # Big C = less penalty on large weights (more freedom, risk of overfitting). \n",
        "                                    # Small C = more penalty (more discipline, less overfitting).\n",
        "                                    # loguniform = means we try values spread across tiny to big scales (e.g., 0.001 up to 100), not just small steps.\n",
        "        'penalty': ['l2'], # gently pushes weights toward zero, which keeps the model simpler and more stable.\n",
        "        'solver': ['lbfgs'],\n",
        "    }\n",
        "\n",
        "    rs_logreg = RandomizedSearchCV(\n",
        "        estimator=logreg,\n",
        "        param_distributions=param_dist_logreg,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    rs_logreg.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_logreg.best_params_,\n",
        "        'best_score': rs_logreg.best_score_,\n",
        "        'cv_results': rs_logreg.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_logreg, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_logreg = rs_logreg.best_estimator_\n",
        "results['LogisticRegression'] = eval_model(\n",
        "    best_logreg,\n",
        "    X_train_s, y_train,\n",
        "    X_val_s, y_val,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=4.0428727350273315, max_iter=10000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.0428727350273315, max_iter=10000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=4.0428727350273315, max_iter=10000,\n",
              "                   multi_class='multinomial')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9176564641388762,\n",
              "  'precision_macro': 0.800141874074688,\n",
              "  'recall_macro': 0.6105422563887755,\n",
              "  'f1_macro': 0.6765546028672075,\n",
              "  'precision_per_class': array([0.92888831, 0.81679389, 0.65064103, 0.65625   , 0.94813614]),\n",
              "  'recall_per_class': array([0.98220199, 0.48198198, 0.35060449, 0.328125  , 0.90979782]),\n",
              "  'f1_per_class': array([0.9548015 , 0.60623229, 0.45566779, 0.4375    , 0.92857143]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7119,   18,   91,    1,   19],\n",
              "         [ 106,  107,    7,    1,    1],\n",
              "         [ 350,    5,  203,    9,   12],\n",
              "         [  38,    0,    5,   21,    0],\n",
              "         [  51,    1,    6,    0,  585]])},\n",
              " 'test': {'accuracy': 0.9151288141786954,\n",
              "  'precision_macro': 0.7885019903691001,\n",
              "  'recall_macro': 0.5967700974401475,\n",
              "  'f1_macro': 0.6633702561560696,\n",
              "  'precision_per_class': array([0.92469552, 0.82105263, 0.66344828, 0.57843137, 0.95488215]),\n",
              "  'recall_per_class': array([0.98476653, 0.42086331, 0.33218232, 0.36419753, 0.8818408 ]),\n",
              "  'f1_per_class': array([0.95378612, 0.55648038, 0.44270594, 0.4469697 , 0.91690915]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17842,    36,   192,     9,    39],\n",
              "         [  293,   234,    26,     2,     1],\n",
              "         [  894,    14,   481,    32,    27],\n",
              "         [   95,     0,     8,    59,     0],\n",
              "         [  171,     1,    18,     0,  1418]])}}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_logreg)\n",
        "results['LogisticRegression']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.2 KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/KNN_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model KNN already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"KNN\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_knn = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    knn = KNeighborsClassifier()\n",
        "    param_dist_knn = {\n",
        "        'n_neighbors': randint(1, 51),\n",
        "        'weights': ['uniform', 'distance'],           # helps with imbalance; 'distance' often better\n",
        "        'metric': ['minkowski', 'manhattan', 'euclidean'],\n",
        "        'p': [1,2],                           # used only for minkowski, if left out it defaults to euclidean\n",
        "    }\n",
        "\n",
        "    rs_knn = RandomizedSearchCV(\n",
        "        estimator=knn,\n",
        "        param_distributions=param_dist_knn,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    rs_knn.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_knn.best_params_,\n",
        "        'best_score': rs_knn.best_score_,\n",
        "        'cv_results': rs_knn.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_knn, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_knn = rs_knn.best_estimator_\n",
        "results['KNN'] = eval_model(\n",
        "    best_knn,\n",
        "    X_train_s, y_train,\n",
        "    X_val_s, y_val,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=4, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=4, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric='manhattan', n_neighbors=4, p=1, weights='distance')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9798994974874372,\n",
              "  'precision_macro': 0.9391433113355262,\n",
              "  'recall_macro': 0.8599185488349104,\n",
              "  'f1_macro': 0.8949289961165755,\n",
              "  'precision_per_class': array([0.98375205, 0.88826816, 0.95087719, 0.87755102, 0.99526814]),\n",
              "  'recall_per_class': array([0.99406733, 0.71621622, 0.93609672, 0.671875  , 0.98133748]),\n",
              "  'f1_per_class': array([0.98888279, 0.79301746, 0.94342907, 0.76106195, 0.98825372]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7205,   18,   20,    3,    2],\n",
              "         [  61,  159,    2,    0,    0],\n",
              "         [  33,    0,  542,    3,    1],\n",
              "         [  16,    0,    5,   43,    0],\n",
              "         [   9,    2,    1,    0,  631]])},\n",
              " 'test': {'accuracy': 0.9775260369084597,\n",
              "  'precision_macro': 0.920137365015206,\n",
              "  'recall_macro': 0.8528821323680518,\n",
              "  'f1_macro': 0.8832154533279242,\n",
              "  'precision_per_class': array([0.98254894, 0.88167053, 0.94080338, 0.80141844, 0.99424552]),\n",
              "  'recall_per_class': array([0.99442543, 0.68345324, 0.92196133, 0.69753086, 0.9670398 ]),\n",
              "  'f1_per_class': array([0.98845152, 0.77001013, 0.93128706, 0.74587459, 0.98045397]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[18017,    46,    42,     8,     5],\n",
              "         [  158,   380,    17,     0,     1],\n",
              "         [   85,     5,  1335,    20,     3],\n",
              "         [   32,     0,    17,   113,     0],\n",
              "         [   45,     0,     8,     0,  1555]])}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_knn)\n",
        "results['KNN']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.3 Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/RandomForest_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model RandomForest already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"RandomForest\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_rf = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    param_dist_rf = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [10, 15, 20], # prevent overfitting majority class\n",
        "        \n",
        "        'min_samples_split': [2, 5, 10, 20, 50],\n",
        "        'min_samples_leaf': [1, 2, 4, 8], # higher = better regularization\n",
        "        \n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'bootstrap': [True], # better generalization\n",
        "        \n",
        "        'class_weight': ['balanced', None], # for imbalanced data\n",
        "        \n",
        "        # Split criterion: entropy can help with imbalanced classes\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "    }\n",
        "\n",
        "    rs_rf = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_dist_rf,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_rf.fit(X_train, y_train) # using unscaled data - RF is not sensitive to feature scaling\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_rf.best_params_,\n",
        "        'best_score': rs_rf.best_score_,\n",
        "        'cv_results': rs_rf.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_rf, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_rf = rs_rf.best_estimator_\n",
        "results['RandomForest'] = eval_model( \n",
        "    best_rf, \n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
              "                       max_depth=20, min_samples_leaf=8, min_samples_split=20,\n",
              "                       n_estimators=200, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
              "                       max_depth=20, min_samples_leaf=8, min_samples_split=20,\n",
              "                       n_estimators=200, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
              "                       max_depth=20, min_samples_leaf=8, min_samples_split=20,\n",
              "                       n_estimators=200, n_jobs=-1, random_state=42)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9785290086797624,\n",
              "  'precision_macro': 0.9160207060087867,\n",
              "  'recall_macro': 0.8648953216324944,\n",
              "  'f1_macro': 0.8885240457117929,\n",
              "  'precision_per_class': array([0.98467013, 0.88172043, 0.94210526, 0.78571429, 0.98589342]),\n",
              "  'recall_per_class': array([0.99254967, 0.73873874, 0.92746114, 0.6875    , 0.97822706]),\n",
              "  'f1_per_class': array([0.9885942 , 0.80392157, 0.93472585, 0.73333333, 0.98204528]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7194,   20,   20,    8,    6],\n",
              "         [  54,  164,    3,    0,    1],\n",
              "         [  34,    2,  537,    4,    2],\n",
              "         [  14,    0,    6,   44,    0],\n",
              "         [  10,    0,    4,    0,  629]])},\n",
              " 'test': {'accuracy': 0.9748309884889458,\n",
              "  'precision_macro': 0.901553466600747,\n",
              "  'recall_macro': 0.8709987482601733,\n",
              "  'f1_macro': 0.8848821016625263,\n",
              "  'precision_per_class': array([0.98157362, 0.8516129 , 0.94247159, 0.74556213, 0.98654709]),\n",
              "  'recall_per_class': array([0.99083784, 0.71223022, 0.91643646, 0.77777778, 0.95771144]),\n",
              "  'f1_per_class': array([0.98618398, 0.77571009, 0.92927171, 0.76132931, 0.97191543]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17952,    66,    64,    21,    15],\n",
              "         [  158,   396,     1,     0,     1],\n",
              "         [   92,     2,  1327,    22,     5],\n",
              "         [   27,     0,     9,   126,     0],\n",
              "         [   60,     1,     7,     0,  1540]])}}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_rf)\n",
        "results['RandomForest']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.4 SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/SVM_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model SVM already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"SVM\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_svm = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    svm = SVC()\n",
        "    param_dist_svm = {\n",
        "        'kernel': ['rbf', 'poly'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'gamma': [0.001, 0.01, 0.1, 0.5, 1],\n",
        "    }\n",
        "    rs_svm = RandomizedSearchCV(\n",
        "        estimator=svm,\n",
        "        param_distributions=param_dist_svm,\n",
        "        n_iter=15,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "    rs_svm.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_svm.best_params_,\n",
        "        'best_score': rs_svm.best_score_,\n",
        "        'cv_results': rs_svm.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_svm, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_svm = rs_svm.best_estimator_\n",
        "results['SVM'] = eval_model(\n",
        "    best_svm,\n",
        "    X_train_s, y_train,\n",
        "    X_val_s, y_val,\n",
        "    X_test_s, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.01, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.01, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=10, gamma=0.01, kernel='poly')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9745317496573778,\n",
              "  'precision_macro': 0.9163739251346034,\n",
              "  'recall_macro': 0.8540245675024011,\n",
              "  'f1_macro': 0.8822902628187215,\n",
              "  'precision_per_class': array([0.98194995, 0.84615385, 0.91872792, 0.8490566 , 0.98598131]),\n",
              "  'recall_per_class': array([0.99075607, 0.69369369, 0.89810017, 0.703125  , 0.9844479 ]),\n",
              "  'f1_per_class': array([0.98633336, 0.76237624, 0.90829694, 0.76923077, 0.98521401]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7181,   23,   35,    3,    6],\n",
              "         [  65,  154,    3,    0,    0],\n",
              "         [  46,    5,  520,    5,    3],\n",
              "         [  12,    0,    7,   45,    0],\n",
              "         [   9,    0,    1,    0,  633]])},\n",
              " 'test': {'accuracy': 0.9740544491138315,\n",
              "  'precision_macro': 0.9049136882358036,\n",
              "  'recall_macro': 0.8394617444559591,\n",
              "  'f1_macro': 0.8684037795992783,\n",
              "  'precision_per_class': array([0.98054602, 0.87347932, 0.92642857, 0.75675676, 0.98735777]),\n",
              "  'recall_per_class': array([0.99315598, 0.64568345, 0.89571823, 0.69135802, 0.97139303]),\n",
              "  'f1_per_class': array([0.98681072, 0.74250259, 0.91081461, 0.72258065, 0.97931034]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17994,    32,    67,    12,    13],\n",
              "         [  182,   359,    14,     1,     0],\n",
              "         [  102,    19,  1297,    23,     7],\n",
              "         [   34,     0,    16,   112,     0],\n",
              "         [   39,     1,     6,     0,  1562]])}}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_svm)\n",
        "results['SVM']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.5 Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/DecisionTree_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model DecisionTree already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"DecisionTree\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_dt = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    param_dist_dt = {\n",
        "        'max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
        "        'min_samples_split': [2, 5, 10, 20, 50],\n",
        "        'min_samples_leaf': [1, 2, 4, 8, 16],\n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'criterion': ['gini', 'entropy'],  \n",
        "        'class_weight': ['balanced', None],\n",
        "        'splitter': ['best', 'random'],  # Split strategy\n",
        "    }\n",
        "\n",
        "    rs_dt = RandomizedSearchCV(\n",
        "        estimator=dt,\n",
        "        param_distributions=param_dist_dt,\n",
        "        n_iter=100,  \n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_dt.fit(X_train, y_train)  # Using unscaled data - DT doesn't need scaling\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_dt.best_params_,\n",
        "        'best_score': rs_dt.best_score_,\n",
        "        'cv_results': rs_dt.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_dt, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_dt = rs_dt.best_estimator_\n",
        "results['DecisionTree'] = eval_model(\n",
        "    best_dt,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=25, min_samples_leaf=2,\n",
              "                       min_samples_split=20, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=25, min_samples_leaf=2,\n",
              "                       min_samples_split=20, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=25, min_samples_leaf=2,\n",
              "                       min_samples_split=20, random_state=42)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9611694837825491,\n",
              "  'precision_macro': 0.8286714991952492,\n",
              "  'recall_macro': 0.8113420712229086,\n",
              "  'f1_macro': 0.8192777361500603,\n",
              "  'precision_per_class': array([0.97892852, 0.7357513 , 0.86677909, 0.61290323, 0.94899536]),\n",
              "  'recall_per_class': array([0.98068433, 0.63963964, 0.88773748, 0.59375   , 0.95489891]),\n",
              "  'f1_per_class': array([0.97980564, 0.68433735, 0.87713311, 0.6031746 , 0.95193798]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7108,   41,   58,   15,   26],\n",
              "         [  71,  142,    7,    0,    2],\n",
              "         [  47,    5,  514,    9,    4],\n",
              "         [  16,    1,    8,   38,    1],\n",
              "         [  19,    4,    6,    0,  614]])},\n",
              " 'test': {'accuracy': 0.9594372373469761,\n",
              "  'precision_macro': 0.8282860612296581,\n",
              "  'recall_macro': 0.7983514845333289,\n",
              "  'f1_macro': 0.8124014481179902,\n",
              "  'precision_per_class': array([0.97427195, 0.72995781, 0.8837535 , 0.59119497, 0.96225208]),\n",
              "  'recall_per_class': array([0.98233801, 0.62230216, 0.87154696, 0.58024691, 0.93532338]),\n",
              "  'f1_per_class': array([0.97828835, 0.67184466, 0.87760779, 0.58566978, 0.94859666]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[17798,   114,   116,    45,    45],\n",
              "         [  192,   346,    12,     0,     6],\n",
              "         [  148,    11,  1262,    19,     8],\n",
              "         [   49,     0,    19,    94,     0],\n",
              "         [   81,     3,    19,     1,  1504]])}}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_dt)\n",
        "results['DecisionTree']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.6 XGBoost / Gradien Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.models.exploration_phase.model_saver:Model loaded: src/models/exploration_phase/XGBoost_no_sampling.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model XGBoost already exists for experiment no_sampling. Loading...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"XGBoost\"\n",
        "experiment_name = \"no_sampling\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_xgb = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        objective='multi:softmax',\n",
        "        num_class=5,  # no of classes\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    param_dist_xgb = {\n",
        "        'n_estimators': [100, 200, 300, 500],\n",
        "        'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
        "        'subsample': [0.8, 0.9, 1.0],\n",
        "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "        'reg_alpha': [0, 0.1, 0.5, 1.0],  # L1 regularization\n",
        "        'reg_lambda': [0, 0.1, 0.5, 1.0],  # L2 regularization\n",
        "        'min_child_weight': [1, 3, 5, 7],\n",
        "        'gamma': [0, 0.1, 0.2, 0.3],  # Minimum loss reduction\n",
        "    }\n",
        "\n",
        "    rs_xgb = RandomizedSearchCV(\n",
        "        estimator=xgb_model,\n",
        "        param_distributions=param_dist_xgb,\n",
        "        n_iter=30,  \n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_xgb.fit(X_train, y_train)  # XGBoost handles scaling internally\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_xgb.best_params_,\n",
        "        'best_score': rs_xgb.best_score_,\n",
        "        'cv_results': rs_xgb.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_xgb, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_xgb = rs_xgb.best_estimator_\n",
        "results['XGBoost'] = eval_model(\n",
        "    best_xgb,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=0, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
              "              max_leaves=None, min_child_weight=5, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
              "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=0, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
              "              max_leaves=None, min_child_weight=5, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
              "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='mlogloss',\n",
              "              feature_types=None, gamma=0, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
              "              max_leaves=None, min_child_weight=5, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
              "              n_jobs=-1, num_class=5, num_parallel_tree=None, ...)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'labels': array([0, 1, 2, 3, 4]),\n",
              " 'val': {'accuracy': 0.9816126084970306,\n",
              "  'precision_macro': 0.9503427741288547,\n",
              "  'recall_macro': 0.8653017509227453,\n",
              "  'f1_macro': 0.9026234500019875,\n",
              "  'precision_per_class': array([0.98499318, 0.92397661, 0.94903339, 0.9       , 0.99371069]),\n",
              "  'recall_per_class': array([0.99613687, 0.71171171, 0.93264249, 0.703125  , 0.98289269]),\n",
              "  'f1_per_class': array([0.99053368, 0.80407125, 0.94076655, 0.78947368, 0.98827209]),\n",
              "  'support_per_class': array([7248,  222,  579,   64,  643]),\n",
              "  'confusion_matrix': array([[7220,   11,   13,    2,    2],\n",
              "         [  62,  158,    1,    0,    1],\n",
              "         [  34,    1,  540,    3,    1],\n",
              "         [   7,    0,   12,   45,    0],\n",
              "         [   7,    1,    3,    0,  632]])},\n",
              " 'test': {'accuracy': 0.9818198428649735,\n",
              "  'precision_macro': 0.9545382548756202,\n",
              "  'recall_macro': 0.8654063021130722,\n",
              "  'f1_macro': 0.9046987238778078,\n",
              "  'precision_per_class': array([0.98292922, 0.95588235, 0.97383721, 0.86764706, 0.99239544]),\n",
              "  'recall_per_class': array([0.99790264, 0.70143885, 0.92541436, 0.72839506, 0.9738806 ]),\n",
              "  'f1_per_class': array([0.99035933, 0.80912863, 0.9490085 , 0.79194631, 0.98305085]),\n",
              "  'support_per_class': array([18118,   556,  1448,   162,  1608]),\n",
              "  'confusion_matrix': array([[18080,    17,    13,     2,     6],\n",
              "         [  160,   390,     5,     0,     1],\n",
              "         [   86,     1,  1340,    16,     5],\n",
              "         [   31,     0,    13,   118,     0],\n",
              "         [   37,     0,     5,     0,  1566]])}}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(best_xgb)\n",
        "results['XGBoost']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.7 Results Summary and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "MODEL COMPARISON WITH BEST PARAMETERS FROM RANDOMIZEDSEARCHCV\n",
            "====================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_f1_macro</th>\n",
              "      <th>best_cv_score</th>\n",
              "      <th>best_parameters</th>\n",
              "      <th>val_f1_cls_0</th>\n",
              "      <th>val_f1_cls_1</th>\n",
              "      <th>val_f1_cls_2</th>\n",
              "      <th>val_f1_cls_3</th>\n",
              "      <th>val_f1_cls_4</th>\n",
              "      <th>test_f1_cls_0</th>\n",
              "      <th>test_f1_cls_1</th>\n",
              "      <th>test_f1_cls_2</th>\n",
              "      <th>test_f1_cls_3</th>\n",
              "      <th>test_f1_cls_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "      <td>{'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha...</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.88</td>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 4, 'p':...</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.88</td>\n",
              "      <td>{'n_estimators': 200, 'min_samples_split': 20,...</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.87</td>\n",
              "      <td>{'kernel': 'poly', 'gamma': 0.01, 'C': 10}</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.83</td>\n",
              "      <td>{'splitter': 'best', 'min_samples_split': 20, ...</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>{'C': 4.0428727350273315, 'penalty': 'l2', 'so...</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model  val_accuracy  val_f1_macro  test_accuracy  \\\n",
              "0             XGBoost          0.98          0.90           0.98   \n",
              "1                 KNN          0.98          0.89           0.98   \n",
              "2        RandomForest          0.98          0.89           0.97   \n",
              "3                 SVM          0.97          0.88           0.97   \n",
              "4        DecisionTree          0.96          0.82           0.96   \n",
              "5  LogisticRegression          0.92          0.68           0.92   \n",
              "\n",
              "   test_f1_macro  best_cv_score  \\\n",
              "0           0.90           0.90   \n",
              "1           0.88           0.88   \n",
              "2           0.88           0.88   \n",
              "3           0.87           0.87   \n",
              "4           0.81           0.83   \n",
              "5           0.66           0.66   \n",
              "\n",
              "                                     best_parameters  val_f1_cls_0  \\\n",
              "0  {'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha...          0.99   \n",
              "1  {'metric': 'manhattan', 'n_neighbors': 4, 'p':...          0.99   \n",
              "2  {'n_estimators': 200, 'min_samples_split': 20,...          0.99   \n",
              "3         {'kernel': 'poly', 'gamma': 0.01, 'C': 10}          0.99   \n",
              "4  {'splitter': 'best', 'min_samples_split': 20, ...          0.98   \n",
              "5  {'C': 4.0428727350273315, 'penalty': 'l2', 'so...          0.95   \n",
              "\n",
              "   val_f1_cls_1  val_f1_cls_2  val_f1_cls_3  val_f1_cls_4  test_f1_cls_0  \\\n",
              "0          0.80          0.94          0.79          0.99           0.99   \n",
              "1          0.79          0.94          0.76          0.99           0.99   \n",
              "2          0.80          0.93          0.73          0.98           0.99   \n",
              "3          0.76          0.91          0.77          0.99           0.99   \n",
              "4          0.68          0.88          0.60          0.95           0.98   \n",
              "5          0.61          0.46          0.44          0.93           0.95   \n",
              "\n",
              "   test_f1_cls_1  test_f1_cls_2  test_f1_cls_3  test_f1_cls_4  \n",
              "0           0.81           0.95           0.79           0.98  \n",
              "1           0.77           0.93           0.75           0.98  \n",
              "2           0.78           0.93           0.76           0.97  \n",
              "3           0.74           0.91           0.72           0.98  \n",
              "4           0.67           0.88           0.59           0.95  \n",
              "5           0.56           0.44           0.45           0.92  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def _safe_col(label):\n",
        "    # Make safe column names like \"val_f1_cls_0\" or \"val_f1_cls_N\"\n",
        "    return re.sub(r'[^0-9a-zA-Z_]+', '_', str(label)).strip('_')\n",
        "\n",
        "# Mapping of model names to their RandomizedSearchCV objects\n",
        "models_and_searchers = {\n",
        "    \"LogisticRegression\": rs_logreg,\n",
        "    \"KNN\": rs_knn, \n",
        "    \"RandomForest\": rs_rf,\n",
        "    \"SVM\": rs_svm,\n",
        "    \"DecisionTree\": rs_dt,\n",
        "    \"XGBoost\": rs_xgb  \n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, res in results.items():\n",
        "    row = {\n",
        "        'model': name,\n",
        "        'val_accuracy': round(res['val']['accuracy'], 2),\n",
        "        'val_f1_macro': round(res['val']['f1_macro'], 2),\n",
        "        'test_accuracy': round(res['test']['accuracy'], 2),\n",
        "        'test_f1_macro': round(res['test']['f1_macro'], 2),\n",
        "    }\n",
        "\n",
        "    # Add best parameters from RandomizedSearchCV\n",
        "    if name in models_and_searchers:\n",
        "        searcher = models_and_searchers[name]\n",
        "        best_params = searcher.best_params_\n",
        "        best_cv_score = searcher.best_score_\n",
        "        row['best_cv_score'] = round(best_cv_score, 2)\n",
        "        row['best_parameters'] = str(best_params)\n",
        "    else:\n",
        "        row['best_cv_score'] = None\n",
        "        row['best_parameters'] = None\n",
        "\n",
        "    labels = res['labels']\n",
        "    f1_v = res['val']['f1_per_class']\n",
        "    f1_t = res['test']['f1_per_class']\n",
        "\n",
        "    # Add per-class F1 columns\n",
        "    for lbl, f1 in zip(labels, f1_v):\n",
        "        row[f'val_f1_cls_{_safe_col(lbl)}'] = round(f1, 2)\n",
        "    for lbl, f1 in zip(labels, f1_t):\n",
        "        row[f'test_f1_cls_{_safe_col(lbl)}'] = round(f1, 2)\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "comparison_df = (\n",
        "    pd.DataFrame(rows)\n",
        "      .sort_values(by=['val_f1_macro','test_f1_macro'], ascending=False)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "best_model_name = comparison_df.iloc[0]['model']\n",
        "best_model_results = results[best_model_name]\n",
        "\n",
        "comparison_df_display = comparison_df.copy()\n",
        "comparison_df_display['best_parameters'] = comparison_df_display['best_parameters'].apply(\n",
        "    lambda x: json.dumps(x, indent=2) if isinstance(x, dict) else x\n",
        ")\n",
        "import os \n",
        "\n",
        "comparison_df_display.to_csv(\"../src/data/03_model_testing_results/model_comparison_without_resampling.csv\", index=False)\n",
        "\n",
        "# Display the comparison table with best parameters\n",
        "print(\"=\" * 100)\n",
        "print(\"MODEL COMPARISON WITH BEST PARAMETERS FROM RANDOMIZEDSEARCHCV\")\n",
        "print(\"=\" * 100)\n",
        "display(comparison_df_display)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SAVED MODELS INFORMATION\n",
            "================================================================================\n",
            "\n",
            "Model: DecisionTree_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/DecisionTree_no_sampling.joblib\n",
            "  Size: 232415 bytes\n",
            "  Modified: 1760415820.9521165\n",
            "\n",
            "Model: SVM_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/SVM_no_sampling.joblib\n",
            "  Size: 12504219 bytes\n",
            "  Modified: 1760415063.7689745\n",
            "\n",
            "Model: KNN_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/KNN_no_sampling.joblib\n",
            "  Size: 118528799 bytes\n",
            "  Modified: 1760396388.739042\n",
            "\n",
            "Model: RandomForest_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/RandomForest_no_sampling.joblib\n",
            "  Size: 48327727 bytes\n",
            "  Modified: 1760399598.0772789\n",
            "\n",
            "Model: LogisticRegression_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/LogisticRegression_no_sampling.joblib\n",
            "  Size: 26175 bytes\n",
            "  Modified: 1760395829.1684663\n",
            "\n",
            "Model: XGBoost_no_sampling\n",
            "  Exists: True\n",
            "  Path: ../src/models/exploration_phase/XGBoost_no_sampling.joblib\n",
            "  Size: 2872222 bytes\n",
            "  Modified: 1760417090.5740137\n"
          ]
        }
      ],
      "source": [
        "# Check saved models\n",
        "print(\"=\" * 80)\n",
        "print(\"SAVED MODELS INFORMATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "saved_models = model_saver.list_saved_models()\n",
        "if saved_models:\n",
        "    for model_key, info in saved_models.items():\n",
        "        print(f\"\\nModel: {model_key}\")\n",
        "        print(f\"  Exists: {info['exists']}\")\n",
        "        print(f\"  Path: {info['model_path']}\")\n",
        "        if info['exists']:\n",
        "            print(f\"  Size: {info['size_bytes']} bytes\")\n",
        "            print(f\"  Modified: {info['modified_time']}\")\n",
        "        \n",
        "        # Load and display metadata if available\n",
        "        if info['metadata_exists']:\n",
        "            try:\n",
        "                metadata = model_saver.load_metadata(model_key.split('_')[0], model_key.split('_')[1] if '_' in model_key else 'default')\n",
        "                if metadata:\n",
        "                    print(f\"  Best Score: {metadata.get('best_score', 'N/A')}\")\n",
        "                    print(f\"  Best Params: {metadata.get('best_params', 'N/A')}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error loading metadata: {e}\")\n",
        "else:\n",
        "    print(\"No saved models found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. With Sampling Methods\n",
        "\n",
        "Quick run - Using the best models from above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing sampling methods on best models...\n",
            "================================================================================\n",
            "\n",
            "Testing No_Sampling...\n",
            "  - KNN\n",
            "  - RandomForest\n",
            "  - XGBoost\n",
            "\n",
            "Testing RandomOverSampler...\n",
            "  - KNN\n",
            "    Class distribution after RandomOverSampler:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - RandomForest\n",
            "    Class distribution after RandomOverSampler:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - XGBoost\n",
            "    Class distribution after RandomOverSampler:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "\n",
            "Testing SMOTE...\n",
            "  - KNN\n",
            "    Class distribution after SMOTE:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - RandomForest\n",
            "    Class distribution after SMOTE:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - XGBoost\n",
            "    Class distribution after SMOTE:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,223 samples\n",
            "      Class 2: 65,223 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "\n",
            "Testing ADASYN...\n",
            "  - KNN\n",
            "    Class distribution after ADASYN:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,311 samples\n",
            "      Class 2: 65,243 samples\n",
            "      Class 3: 65,181 samples\n",
            "      Class 4: 65,200 samples\n",
            "  - RandomForest\n",
            "    Class distribution after ADASYN:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,311 samples\n",
            "      Class 2: 65,243 samples\n",
            "      Class 3: 65,181 samples\n",
            "      Class 4: 65,200 samples\n",
            "  - XGBoost\n",
            "    Class distribution after ADASYN:\n",
            "      Class 0: 65,223 samples\n",
            "      Class 1: 65,311 samples\n",
            "      Class 2: 65,243 samples\n",
            "      Class 3: 65,181 samples\n",
            "      Class 4: 65,200 samples\n",
            "\n",
            "Testing SMOTETomek...\n",
            "  - KNN\n",
            "    Class distribution after SMOTETomek:\n",
            "      Class 0: 65,220 samples\n",
            "      Class 1: 65,222 samples\n",
            "      Class 2: 65,221 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - RandomForest\n",
            "    Class distribution after SMOTETomek:\n",
            "      Class 0: 65,220 samples\n",
            "      Class 1: 65,222 samples\n",
            "      Class 2: 65,221 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "  - XGBoost\n",
            "    Class distribution after SMOTETomek:\n",
            "      Class 0: 65,220 samples\n",
            "      Class 1: 65,222 samples\n",
            "      Class 2: 65,221 samples\n",
            "      Class 3: 65,223 samples\n",
            "      Class 4: 65,223 samples\n",
            "\n",
            "Testing SMOTEENN...\n",
            "  - KNN\n",
            "    Class distribution after SMOTEENN:\n",
            "      Class 0: 61,969 samples\n",
            "      Class 1: 65,191 samples\n",
            "      Class 2: 65,186 samples\n",
            "      Class 3: 65,222 samples\n",
            "      Class 4: 65,211 samples\n",
            "  - RandomForest\n",
            "    Class distribution after SMOTEENN:\n",
            "      Class 0: 61,969 samples\n",
            "      Class 1: 65,191 samples\n",
            "      Class 2: 65,186 samples\n",
            "      Class 3: 65,222 samples\n",
            "      Class 4: 65,211 samples\n",
            "  - XGBoost\n",
            "    Class distribution after SMOTEENN:\n",
            "      Class 0: 61,969 samples\n",
            "      Class 1: 65,191 samples\n",
            "      Class 2: 65,186 samples\n",
            "      Class 3: 65,222 samples\n",
            "      Class 4: 65,211 samples\n"
          ]
        }
      ],
      "source": [
        "## Test Models with Different Sampling Methods\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sampling_methods = {\n",
        "    'No_Sampling': None,\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42, k_neighbors=5),\n",
        "    'ADASYN': ADASYN(random_state=42, n_neighbors=5),\n",
        "    'SMOTETomek': SMOTETomek(random_state=42, smote=SMOTE(random_state=42, k_neighbors=5)),\n",
        "    'SMOTEENN': SMOTEENN(random_state=42, smote=SMOTE(random_state=42, k_neighbors=5)),\n",
        "}\n",
        "\n",
        "sampling_results = {}\n",
        "\n",
        "best_models = {\n",
        "    'KNN': best_knn,\n",
        "    'RandomForest': best_rf,\n",
        "    'XGBoost': best_xgb,\n",
        "}\n",
        "\n",
        "scale_sensitive = ['LogisticRegression', 'SVM', 'KNN']\n",
        "\n",
        "print(\"Testing sampling methods on best models...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for sampling_name, sampler in sampling_methods.items():\n",
        "    print(f\"\\nTesting {sampling_name}...\")\n",
        "    sampling_results[sampling_name] = {}\n",
        "    \n",
        "    for model_name, model in best_models.items():\n",
        "        print(f\"  - {model_name}\")\n",
        "        \n",
        "        try:\n",
        "            if sampler is None:\n",
        "                # No sampling - use original, only scaled data\n",
        "                result = eval_model(model,\n",
        "                                    X_train_s if model_name in scale_sensitive else X_train , y_train,\n",
        "                                    X_val_s if model_name in scale_sensitive else X_val, y_val,\n",
        "                                    X_test_s if model_name in scale_sensitive else X_test, y_test)\n",
        "            else:\n",
        "                # Apply sampling on unscaled data\n",
        "                X_train_sampled, y_train_sampled = sampler.fit_resample(X_train, y_train)\n",
        "                \n",
        "                # Re-scale if needed for models that require scaling\n",
        "                if model_name in scale_sensitive:\n",
        "                    scaler_sampling = StandardScaler()\n",
        "                    X_train_sampled = scaler_sampling.fit_transform(X_train_sampled)\n",
        "                    X_val_sampled = scaler_sampling.transform(X_val)\n",
        "                    X_test_sampled = scaler_sampling.transform(X_test)\n",
        "                else: # e.g. RF, XGBoost\n",
        "                    X_val_sampled = X_val\n",
        "                    X_test_sampled = X_test\n",
        "            \n",
        "                result = eval_model(\n",
        "                    model,\n",
        "                    X_train_sampled, y_train_sampled,\n",
        "                    X_val_sampled, y_val,\n",
        "                    X_test_sampled, y_test,\n",
        "                )\n",
        "            \n",
        "            sampling_results[sampling_name][model_name] = result\n",
        "            \n",
        "            # Printing statistics\n",
        "            if sampler is not None:\n",
        "                unique, counts = np.unique(y_train_sampled, return_counts=True)\n",
        "                print(f\"    Class distribution after {sampling_name}:\")\n",
        "                for cls, count in zip(unique, counts):\n",
        "                    print(f\"      Class {cls}: {count:,} samples\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"    ERROR with {sampling_name} + {model_name}: {str(e)}\")\n",
        "            sampling_results[sampling_name][model_name] = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create comprehensive comparison table\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"SAMPLING METHODS COMPARISON\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Prepare comparison data\n",
        "comparison_rows = []\n",
        "\n",
        "for sampling_name, models_results in sampling_results.items():\n",
        "    for model_name, result in models_results.items():\n",
        "        if result is not None:\n",
        "            row = {\n",
        "                'sampling_method': sampling_name,\n",
        "                'model': model_name,\n",
        "                'val_accuracy': round(result['val']['accuracy'],2),\n",
        "                'val_f1_macro': round(result['val']['f1_macro'],2),\n",
        "                'test_accuracy': round(result['test']['accuracy'],2),\n",
        "                'test_f1_macro': round(result['test']['f1_macro'],2)\n",
        "            }\n",
        "            \n",
        "            # Add per-class F1 scores\n",
        "            labels = result['labels']\n",
        "            f1_v = result['val']['f1_per_class']\n",
        "            f1_t = result['test']['f1_per_class']\n",
        "            \n",
        "            for lbl, f1 in zip(labels, f1_v):\n",
        "                row[f'val_f1_cls_{_safe_col(lbl)}'] = round(f1,2)\n",
        "            for lbl, f1 in zip(labels, f1_t):\n",
        "                row[f'test_f1_cls_{_safe_col(lbl)}'] = round(f1,2)\n",
        "            \n",
        "            comparison_rows.append(row)\n",
        "\n",
        "# Create and display comparison DataFrame\n",
        "sampling_comparison_df = (\n",
        "    pd.DataFrame(comparison_rows)\n",
        "    .sort_values(by=['test_f1_macro', 'val_f1_macro'], ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BEST COMBINATION:\n",
            "Sampling Method: RandomOverSampler\n",
            "Model: XGBoost\n",
            "Test F1-Macro: 0.9200\n",
            "Validation F1-Macro: 0.9200\n",
            "\n",
            "SUMMARY STATISTICS:\n",
            "Total combinations tested: 18\n",
            "Best test F1-macro: 0.9200\n",
            "Best validation F1-macro: 0.9200\n",
            "\n",
            "TOP 5 COMBINATIONS:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sampling_method</th>\n",
              "      <th>model</th>\n",
              "      <th>test_f1_macro</th>\n",
              "      <th>val_f1_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomOverSampler</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SMOTE</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SMOTETomek</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No_Sampling</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomOverSampler</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sampling_method         model  test_f1_macro  val_f1_macro\n",
              "0  RandomOverSampler       XGBoost           0.92          0.92\n",
              "1              SMOTE       XGBoost           0.91          0.91\n",
              "2         SMOTETomek       XGBoost           0.91          0.91\n",
              "3        No_Sampling       XGBoost           0.90          0.90\n",
              "4  RandomOverSampler  RandomForest           0.90          0.90"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sampling_comparison_df.to_csv(\"../src/data/03_model_testing_results/model_comparison_with_sampling_on_best_models.csv\", index=False)\n",
        "\n",
        "# Find best combination\n",
        "best_sampling_model = sampling_comparison_df.iloc[0]\n",
        "print(f\"\\nBEST COMBINATION:\")\n",
        "print(f\"Sampling Method: {best_sampling_model['sampling_method']}\")\n",
        "print(f\"Model: {best_sampling_model['model']}\")\n",
        "print(f\"Test F1-Macro: {best_sampling_model['test_f1_macro']:.4f}\")\n",
        "print(f\"Validation F1-Macro: {best_sampling_model['val_f1_macro']:.4f}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nSUMMARY STATISTICS:\")\n",
        "print(f\"Total combinations tested: {len(comparison_rows)}\")\n",
        "print(f\"Best test F1-macro: {sampling_comparison_df['test_f1_macro'].max():.4f}\")\n",
        "print(f\"Best validation F1-macro: {sampling_comparison_df['val_f1_macro'].max():.4f}\")\n",
        "\n",
        "# Show top 5 combinations\n",
        "print(f\"\\nTOP 5 COMBINATIONS:\")\n",
        "top_5 = sampling_comparison_df.head(5)[['sampling_method', 'model', 'test_f1_macro', 'val_f1_macro']]\n",
        "display(top_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Possible improvements - Not Tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Implement Leak-free scaling\n",
        "    - current: scale X_train once then run CV on X_train_s -> leaks validation-fold info into scaling\n",
        "    - solution: Pipeline(StandardScaler(), model) so scaling is fit per CV fold\n",
        "- RepeatedStratifiedKFold for more stable estimates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score, balanced_accuracy_score\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=10000, multi_class='multinomial'))\n",
        "])\n",
        "\n",
        "param_dist_logreg = {\n",
        "    'C': loguniform(1e-3, 1e3), # Big C = less penalty on large weights (more freedom, risk of overfitting). \n",
        "                                # Small C = more penalty (more discipline, less overfitting).\n",
        "                                # loguniform = means we try values spread across tiny to big scales (e.g., 0.001 up to 100), not just small steps.\n",
        "    'penalty': ['l2'], # gently pushes weights toward zero, which keeps the model simpler and more stable.\n",
        "    'solver': ['lbfgs'],\n",
        "}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
        "scoring = {'f1_macro': 'f1_macro', 'bal_acc': 'balanced_accuracy', 'f1_weighted': 'f1_weighted'}\n",
        "\n",
        "rs_logreg = RandomizedSearchCV(\n",
        "    pipe,\n",
        "    param_distributions=param_dist_logreg,\n",
        "    n_iter=20,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        ")\n",
        "rs_logreg.fit(X_train, y_train) # not fitting on X_train_s because Pipeline will do it for us"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
