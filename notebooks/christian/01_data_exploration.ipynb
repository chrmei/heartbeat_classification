{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heartbeat Classification - Data Exploration\n",
        "\n",
        "## Project Overview\n",
        "Exploratory data analysis on ECG heartbet classification dataset from Kaggle competition.\n",
        "\n",
        "**Datasets:**\n",
        "- MIT-BIH Arrhythmia Dataset (5 classes)\n",
        "- PTB Diagnostic ECG Database (2 classes: normal/abnormal)\n",
        "\n",
        "**Objective:** Understand data structure, identify patterns, and prepare for preprocessing. Create 5 High-Quality graphs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Statistical analysis\n",
        "from scipy.stats import kruskal, chisquare, kstest\n",
        "\n",
        "# Data handling\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# System libraries\n",
        "import sys\n",
        "# Add the project root directory to Python path\n",
        "sys.path.append('..')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Custom utils\n",
        "from src.data.audit_report import generate_data_audit_report, generate_summary_report\n",
        "from src.visualization.visualization import plot_heartbeat, plot_multiple_heartbeats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. DataSet Descriptions\n",
        "\n",
        "### PTBDB_*.csv\n",
        "\n",
        "- derived from PTB Diagnostic ECG Database\n",
        "- designed for classifying electrocardiogram ECG signals into normal and abnormal heartbeats\n",
        "\n",
        "### MITBIH_*.csv\n",
        "\n",
        "- derived form Physionet's MIT-BIH Arrhytmia Dataset\n",
        "- designed for classifying ECG signals into 5 categories (N, S, V, F, Q)\n",
        "- each column represents a time point in a 10-second ECG signal, sampled at 125Hz. Values normalized between 0 and 1.\n",
        "\n",
        "### What they have in common\n",
        "\n",
        "- each column represents a time point in a 10-second ECG signal, sampled at 125HZ. Values normalized between 0 and 1.\n",
        "- padded with zeros if necessary to the fixed dimension of 188\n",
        "- Column 188 = class label (target), while dataset is already splitted according to the label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading & Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ptbdb_normal = pd.read_csv(\"../data/original/ptbdb_normal.csv\", header=None)\n",
        "display(ptbdb_normal.head())\n",
        "\n",
        "print(\"Dataset shapes:\", ptbdb_normal.shape, ptbdb_normal.shape)\n",
        "print(\"Data types:\", ptbdb_normal.dtypes.value_counts())\n",
        "print(\"Memory usage:\", ptbdb_normal.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
        "print(\"Duplicates - deleted! \", ptbdb_normal.duplicated().sum())\n",
        "print(ptbdb_normal[187].value_counts())\n",
        "\n",
        "ptbdb_normal.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ptbdb_abnormal = pd.read_csv(\"../data/original/ptbdb_abnormal.csv\", header=None)\n",
        "display(ptbdb_abnormal.head())\n",
        "\n",
        "print(\"Dataset shapes:\", ptbdb_abnormal.shape, ptbdb_abnormal.shape)\n",
        "print(\"Data types:\", ptbdb_abnormal.dtypes.value_counts())\n",
        "print(\"Memory usage:\", ptbdb_abnormal.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
        "print(\"Duplicates - deleted! \", ptbdb_abnormal.duplicated().sum())\n",
        "\n",
        "print(ptbdb_abnormal[187].value_counts())\n",
        "\n",
        "ptbdb_abnormal.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mitbih_test = pd.read_csv(\"../data/original/mitbih_test.csv\", header=None)\n",
        "display(mitbih_test.head())\n",
        "\n",
        "print(\"Dataset shapes:\", mitbih_test.shape, mitbih_test.shape)\n",
        "print(\"Data types:\", mitbih_test.dtypes.value_counts())\n",
        "print(\"Memory usage:\", mitbih_test.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
        "print(\"Duplicates - 0! \", mitbih_test.duplicated().sum())\n",
        "\n",
        "print(mitbih_test[187].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mitbih_train = pd.read_csv(\"../data/original/mitbih_train.csv\", header=None)\n",
        "display(mitbih_train.head())\n",
        "\n",
        "print(\"Dataset shapes:\", mitbih_train.shape, mitbih_train.shape)\n",
        "print(\"Data types:\", mitbih_train.dtypes.value_counts())\n",
        "print(\"Memory usage:\", mitbih_train.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
        "print(\"Duplicates - 0! \", mitbih_train.duplicated().sum())\n",
        "\n",
        "print(mitbih_train[187].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mitbih labels mapping\n",
        "mitbih_labels_map = {0: 'N', 1: 'S', 2: 'V', 3: 'F', 4: 'Q'}\n",
        "mitbih_labels_to_desc = {\"N\": \"Normal\", \"S\": \"Supraventricular premature beat\", \"V\": \"Premature ventricular contraction\", \"F\": \"Fusion of V+N\", \"Q\": \"Unclassified\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing values analysis\n",
        "datasets = [mitbih_train, mitbih_test, ptbdb_normal, ptbdb_abnormal]\n",
        "for i, dataset in enumerate(datasets):\n",
        "    total_missing = dataset.isnull().sum().sum()\n",
        "    missing_per_column = dataset.isnull().sum()\n",
        "    missing_percentage = (dataset.isnull().sum() / len(dataset)) * 100\n",
        "    print(f\"Dataset {i+1} - Total missing values: {total_missing}\")\n",
        "    # print(f\"Dataset {i+1} - Missing values per column:\\n{missing_per_column}\")\n",
        "    # print(f\"Dataset {i+1} - Missing values percentage per column:\\n{missing_percentage}\\n\")\n",
        "\n",
        "    # Data range analysis\n",
        "    # print(\"Signal amplitude range:\", dataset.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*NO MISSING VALUES!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ptbdb = pd.concat([ptbdb_abnormal, ptbdb_normal], axis=0).reset_index(drop=True)\n",
        "mitbih = pd.concat([mitbih_train, mitbih_test], axis=0).reset_index(drop=True)\n",
        "for i, dataset in enumerate([ptbdb, mitbih ]):\n",
        "    if i == 0:\n",
        "        name = \"ptbdb\"\n",
        "    else:\n",
        "        name = \"mitbih\"\n",
        "    print(f\"Dataset {name} - Shape: {dataset.shape}\")\n",
        "    zero_mean_columns = dataset.columns[dataset.describe().loc['mean'] == 0].tolist()\n",
        "    print(f\"Dataset {name} - Columns (columnname(s)) with zero mean: {zero_mean_columns}\")\n",
        "    display(dataset.describe())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Class Distribution & Imbalance Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MITBIH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_counts = mitbih.iloc[:, -1].value_counts().sort_index()\n",
        "imbalance_ratio = class_counts.min() / class_counts.max()\n",
        "\n",
        "# Statistical tests for imbalance\n",
        "from scipy.stats import chi2_contingency\n",
        "chi2, p_value, dof, expected = chi2_contingency(class_counts.values.reshape(1, -1))\n",
        "\n",
        "print(f\"Chi-squared test statistic: {chi2}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "print(f\"Degrees of freedom: {dof}\") \n",
        "\n",
        "print(f\"Class counts:\\t{class_counts}\") # pie chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Map class IDs -> short + description labels\n",
        "labels = [\n",
        "    f\"{mitbih_labels_map[i]} - {mitbih_labels_to_desc[mitbih_labels_map[i]]}\"\n",
        "    for i in class_counts.index\n",
        "]\n",
        "\n",
        "# --- Colors ---\n",
        "colors = sns.color_palette(\"pastel\", len(class_counts))\n",
        "\n",
        "# --- Plot setup ---\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "plt.pie(class_counts, labels=labels, colors=colors, autopct='%1.1f%%')\n",
        "\n",
        "ax.set_title(\"Class Distribution in MIT-BIH Arrhythmia Dataset\", fontsize=16, weight='bold', pad=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PTBDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_counts = ptbdb.iloc[:, -1].value_counts().sort_index()\n",
        "expected = [class_counts.mean()] * len(class_counts)\n",
        "imbalance_ratio = class_counts.min() / class_counts.max()\n",
        "\n",
        "chi2, p_value = chisquare(class_counts, expected)\n",
        "\n",
        "print(f\"Chi-squared test statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Imbalance ratio: {imbalance_ratio:.4f}\")\n",
        "\n",
        "print(f\"Class counts:\\t{class_counts}\") # pie chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "colors = sns.color_palette(\"pastel\", len(class_counts))\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "class_counts = ptbdb[187].value_counts().sort_index()\n",
        "class_counts.plot(kind='bar', color='skyblue')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('PTB: Class Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PTBDB: Normal vs Abnormal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normal_heartbeat = ptbdb[ptbdb[187] == 0].sample(3)\n",
        "abnormal_heartbeat = ptbdb[ptbdb[187] == 1].sample(3)\n",
        "fig = plot_multiple_heartbeats(normal_heartbeat, title=\"PTBDB Normal\")\n",
        "fig = plot_multiple_heartbeats(abnormal_heartbeat, title=\"PTBDB Abnormal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MITBIH: Plots for all classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = mitbih[187].unique()\n",
        "colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown', 'pink', 'cyan', 'magenta', 'lime']\n",
        "\n",
        "for i, _class in enumerate(classes):\n",
        "    heartbeat = mitbih[mitbih[187] == _class].sample(3)\n",
        "    title = f\"MITBIH Class {_class} - {mitbih_labels_map[_class]}: {mitbih_labels_to_desc[mitbih_labels_map[_class]]}\"\n",
        "    fig = plot_multiple_heartbeats(heartbeat, title=title, color=colors[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Check classifications\n",
        "\n",
        "Are the classifications correct or are there unusual data rows? \n",
        "\n",
        "Can be answered by looking at extrem R-R distances ( times between R peaks ).\n",
        "\n",
        "Each row contains 1.2R ( heartbeats) - and is zero-padded to allow Deep Learning techniques to be applied.\n",
        "Calculate R by:\n",
        "- index of zero padding \n",
        "- dividing by 1.2\n",
        "\n",
        "Thus:\n",
        "- compare classes\n",
        "- plot differences / outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_first_nonzero_index(arr):\n",
        "    for i in range(len(arr) - 1, -1, -1):\n",
        "        if arr[i] != 0:\n",
        "            first_zero_index = ( i + 1 ) / 1.2\n",
        "            break\n",
        "        else:\n",
        "            first_zero_index = 0  # all zeros\n",
        "    return first_zero_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ptbdb_r = ptbdb.iloc[:, :-1].apply(lambda row: find_first_nonzero_index(row.values), axis=1)\n",
        "result_ptbdb_r = pd.concat([ptbdb_r.rename('zero_pad_start'), ptbdb.iloc[:, -1].rename('target')], axis=1)\n",
        "\n",
        "result_ptbdb_r.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_ptbdb_r[result_ptbdb_r[\"target\"] == 1].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_ptbdb_r[result_ptbdb_r[\"target\"] == 0].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='target', y='zero_pad_start', data=result_ptbdb_r)\n",
        "plt.title('PTB Zero-padding Start vs Class', fontsize=16)\n",
        "plt.xlabel('PTB Class', fontsize=12)\n",
        "plt.ylabel('Zero-padding Start Index', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Extremes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get outlier indices for each class\n",
        "def get_outliers_idx(df, value_col, class_col):\n",
        "    outlier_indices = []\n",
        "    \n",
        "    for cls, group in df.groupby(class_col):\n",
        "        q1 = group[value_col].quantile(0.25)\n",
        "        q3 = group[value_col].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_whisker = q1 - 1.5 * iqr\n",
        "        upper_whisker = q3 + 1.5 * iqr\n",
        "        \n",
        "        # Identify outliers\n",
        "        outliers = group[(group[value_col] < lower_whisker) | (group[value_col] > upper_whisker)]\n",
        "        outlier_indices.extend(outliers.index.tolist())\n",
        "    \n",
        "    return outlier_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for c in [0,1]:\n",
        "    df = result_ptbdb_r[result_ptbdb_r[\"target\"] == c]\n",
        "    idx = get_outliers_idx(df, 'zero_pad_start', 'target')\n",
        "    \n",
        "    proportion = len(idx) / len(df) * 100\n",
        "\n",
        "    if c == 0:\n",
        "        n = \"Normal\"\n",
        "    if c == 1:\n",
        "        n = \"Abnormal\"\n",
        "\n",
        "    plot_multiple_heartbeats(ptbdb.iloc[idx].sample(3), title=f\"PTBDB Extremes in {n} Class. Proportion:{proportion:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MITBIH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mitbih_r = mitbih.iloc[:, :-1].apply(lambda row: find_first_nonzero_index(row.values), axis=1)\n",
        "result_mitbih_r = pd.concat([mitbih_r.rename('zero_pad_start'), mitbih.iloc[:, -1].rename('target')], axis=1)\n",
        "\n",
        "result_mitbih_r.describe()\n",
        "\n",
        "result_mitbih_r.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for c in mitbih[187].unique():\n",
        "    display(result_mitbih_r[result_mitbih_r[\"target\"] == c].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='target', y='zero_pad_start', data=result_mitbih_r)\n",
        "plt.title('PTB Zero-padding Start vs Target', fontsize=16)\n",
        "plt.xlabel('PTB Class', fontsize=12)\n",
        "plt.ylabel('Zero-padding Start Index', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for c in mitbih[187].unique():\n",
        "    df = result_mitbih_r[result_mitbih_r[\"target\"] == c]\n",
        "    idx = get_outliers_idx(df, 'zero_pad_start', 'target')\n",
        "    \n",
        "    proportion = len(idx) / len(df) * 100\n",
        "\n",
        "    sample = mitbih.iloc[idx]\n",
        "    \n",
        "    if len(sample) > 0:\n",
        "        min_len = min([len(sample), 3])\n",
        "        plot_multiple_heartbeats(sample.sample(min_len), title=f\"MIT-BIH Extremes in {str(c)} Class. Proportion:{proportion:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Is data between classes significantly different?\n",
        "\n",
        "#### Kruskal Wallis Test on Targets + Rs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kruskal-Wallis is univariate, so it tests differences along a single variable at a time --> multivariate approach needed\n",
        "\n",
        "1. use PCA\n",
        "2. run kruskal wallis on each principal component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import kruskal\n",
        "import pandas as pd\n",
        "\n",
        "def kruskal_multivariate(df, target_col=None, n_components=5):\n",
        "    if target_col is None:\n",
        "        target_col = df.columns[-1]\n",
        "\n",
        "    X = df.drop(columns=target_col)\n",
        "    y = df[target_col]\n",
        "\n",
        "    p_values = []\n",
        "    # Reduce to n_components using PCA\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    for i in range(n_components):\n",
        "        groups = [X_pca[y == cls, i] for cls in pd.unique(y)]\n",
        "        stat, p = kruskal(*groups)\n",
        "        p_values.append(p)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'PC': [f'PC{i+1}' for i in range(n_components)],\n",
        "        'p_value': p_values\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kruskal_results_mit = kruskal_multivariate(mitbih, target_col=187, n_components=5)\n",
        "print(kruskal_results_mit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kruskal_results_ptb = kruskal_multivariate(ptbdb, target_col=187, n_components=2)\n",
        "print(kruskal_results_ptb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--> low p-vals -> significantly different along principal component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pairwise comparison of R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import combinations \n",
        "\n",
        "def kruskal_class_pairs(df, target_col=None, agg_func='mean'):\n",
        "    if target_col is None:\n",
        "        target_col = df.columns[-1]\n",
        "\n",
        "    X = df.drop(columns=target_col)\n",
        "    y = df[target_col]\n",
        "\n",
        "    # Aggregate features into a single value per sample\n",
        "    if agg_func == 'mean':\n",
        "        X_agg = X.mean(axis=1)\n",
        "    elif agg_func == 'sum':\n",
        "        X_agg = X.sum(axis=1)\n",
        "    else:\n",
        "        raise ValueError(\"agg_func must be 'mean' or 'sum'\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    classes = pd.unique(y)\n",
        "    for class1, class2 in combinations(classes, 2):\n",
        "        group1 = X_agg[y == class1]\n",
        "        group2 = X_agg[y == class2]\n",
        "\n",
        "        stat, p = kruskal(group1, group2)\n",
        "        results.append({\n",
        "            'class1': class1,\n",
        "            'class2': class2,\n",
        "            'p_value': p\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results).sort_values('p_value')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mitbih_r_copy = result_mitbih_r.copy()\n",
        "result_ptbdb_r_copy = result_ptbdb_r.copy()\n",
        "\n",
        "mitbih_r_copy['target'] = 'MIT_' + mitbih_r_copy['target'].astype(str)\n",
        "result_ptbdb_r_copy['target'] = 'PTB_' + result_ptbdb_r_copy['target'].astype(str)\n",
        "\n",
        "combined_df = pd.concat([mitbih_r_copy, result_ptbdb_r_copy], ignore_index=True)\n",
        "\n",
        "combined_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kruskal_pairwise_df = kruskal_class_pairs(combined_df, target_col='target', agg_func='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kruskal_pairwise_df[kruskal_pairwise_df[\"p_value\"] > 0.01]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kruskal_pairwise_df.sort_values(by='class1', ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results / Anomalies\n",
        " \n",
        "### PTB\n",
        "\n",
        "1. Last column in PTBDB is always empty, probably added to make comparison possible ( don't delete )\n",
        "2. Imbalanced classes validated through CHI2 -> resampling needed\n",
        "3. For extreme values in R-R distances: check classifications / decision needed. But count is low (0.2%)\n",
        "\n",
        "### MITBIH\n",
        "\n",
        "1. Large imbalance in MITBIH dataset validated through CHI2 -> resampling needed\n",
        "2. For extreme values in R-R distances: check classifications / decision needed. Count for class 3 and 4 are relatively high.\n",
        "3. MIT class 1 vs PTB class 1 might define the same abnormal heart beats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Audit Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate audit reports for all CSV files (specify the correct path)\n",
        "generate_data_audit_report(data_dir=\"../data/original/\", output_dir=\"../reports/DataAudit/\")\n",
        "\n",
        "# Generate summary report (specify the correct path)\n",
        "generate_summary_report(data_dir=\"../data/original/\", output_file=\"../reports/DataAudit/data_summary.txt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
