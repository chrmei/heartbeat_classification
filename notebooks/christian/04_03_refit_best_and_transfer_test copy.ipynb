{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14eab3c2",
   "metadata": {},
   "source": [
    "# 4.3 Refit best and transfer test on PTB dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64239f57",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n",
    ")\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Show working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Ensure `src` is importable when running from the notebook\n",
    "sys.path.append(str((Path.cwd() / \"src\").resolve()))\n",
    "\n",
    "# Custom utilities\n",
    "from src.utils.preprocessing import (\n",
    "    load_processed_dataset,\n",
    "    build_full_suffix as pp_build_full_suffix,\n",
    "    generate_all_processed_datasets,\n",
    ")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3a6a8",
   "metadata": {},
   "source": [
    "## 2. Refit best Model from part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"classifier__colsample_bytree\": 0.9, \"classifier__gamma\": 0.0,\n",
    "               \"classifier__learning_rate\": 0.2, \"classifier__max_depth\": 9,\n",
    "               \"classifier__min_child_weight\": 5, \"classifier__n_estimators\": 250,\n",
    "               \"classifier__reg_alpha\": 0.2, \"classifier__reg_lambda\": 0.05,\n",
    "               \"classifier__subsample\": 0.7}\n",
    "\n",
    "# Preprocessed data sampling (loader) vs. model-time sampler\n",
    "DATA_DIR = \"data/processed/mitbih\"\n",
    "sampling_method = \"No_Sampling\"   # dataset loader suffix\n",
    "model_sampler = \"SMOTE\"           # sampler applied inside the pipeline\n",
    "\n",
    "model_name = \"XGBoost\"\n",
    "remove_outliers = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ae363",
   "metadata": {},
   "source": [
    "### XGBoost, SMOTE, no outlier removal,\tno feature engineering\n",
    "\n",
    "### Model Results\n",
    "\n",
    "- **Accuracy**: 0.9834  \n",
    "- **F1-Macro**: 0.9148  \n",
    "- **CV-Score**: 0.9134  \n",
    "\n",
    "### Per-class F1\n",
    "\n",
    "| Class | F1 |\n",
    "|---|---|\n",
    "| 1 | 0.99 |\n",
    "| 2 | 0.83 |\n",
    "| 3 | 0.96 |\n",
    "| 4 | 0.81 |\n",
    "| 5 | 0.99 |\n",
    "\n",
    "### Best Parameters\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"classifier__colsample_bytree\": 0.9,\n",
    "  \"classifier__gamma\": 0.0,\n",
    "  \"classifier__learning_rate\": 0.2,\n",
    "  \"classifier__max_depth\": 9,\n",
    "  \"classifier__min_child_weight\": 5,\n",
    "  \"classifier__n_estimators\": 250,\n",
    "  \"classifier__reg_alpha\": 0.2,\n",
    "  \"classifier__reg_lambda\": 0.05,\n",
    "  \"classifier__subsample\": 0.7\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_with_sampling(\n",
    "    data_dir: str = DATA_DIR,\n",
    "    sampling_method: str = \"No_Sampling\",\n",
    "    remove_outliers: bool = False\n",
    ") -> Tuple[np.ndarray, Optional[np.ndarray], np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"Load an existing processed dataset for the given configuration.\n",
    "\n",
    "    Datasets are assumed to be pre-generated by preprocessing utilities. This\n",
    "    function never overwrites or generates new data; it only loads.\n",
    "    \"\"\"\n",
    "    # Ensure all datasets are generated once (no-op if already done)\n",
    "    generate_all_processed_datasets(data_dir=data_dir, only_once=True)\n",
    "\n",
    "    full_suffix = pp_build_full_suffix(sampling_method, remove_outliers)\n",
    "    split = load_processed_dataset(data_dir=data_dir, sampling_suffix=full_suffix)\n",
    "\n",
    "    X_train_res = split.X_train.values\n",
    "    y_train_res = split.y_train.values\n",
    "    X_val = split.X_val.values if split.X_val is not None else None\n",
    "    y_val = split.y_val.values if split.y_val is not None else None\n",
    "\n",
    "    return X_train_res, X_val, y_train_res, y_val\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Refitting {model_name} with best parameters and transferring to PTB (5-class as-is)\")\n",
    "print(f\"Data sampling (loader): {sampling_method} | Model sampler: {model_sampler} | Outlier removal: {remove_outliers}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# 1) Train multi-class on MIT-BIH (as-is, 5 classes)\n",
    "X_train, X_val, y_train, y_val = prepare_dataset_with_sampling(\n",
    "    sampling_method=sampling_method,\n",
    "    remove_outliers=remove_outliers\n",
    ")\n",
    "\n",
    "best_params_clean = {k.replace(\"classifier__\", \"\"): v for k, v in params.items()}\n",
    "estimator = Pipeline([\n",
    "    (\"sampler\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", xgb.XGBClassifier(\n",
    "        **best_params_clean,\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=5,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        eval_metric=\"mlogloss\",\n",
    "    )),\n",
    "])\n",
    "\n",
    "# Fit once\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on MIT validation set first\n",
    "y_pred_mit = estimator.predict(X_val)\n",
    "mit_accuracy = accuracy_score(y_val, y_pred_mit)\n",
    "mit_precision_macro, mit_recall_macro, mit_f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_val, y_pred_mit, average='macro', zero_division=0\n",
    ")\n",
    "mit_labels = np.unique(np.concatenate([y_train, y_val]))\n",
    "mit_precision_per_class, mit_recall_per_class, mit_f1_per_class, _ = precision_recall_fscore_support(\n",
    "    y_val, y_pred_mit, average=None, labels=mit_labels, zero_division=0\n",
    ")\n",
    "mit_confusion = confusion_matrix(y_val, y_pred_mit, labels=mit_labels)\n",
    "\n",
    "print(f\"\\nMIT-BIH Validation Metrics:\")\n",
    "print(f\"Accuracy: {mit_accuracy:.4f}\")\n",
    "print(f\"F1-Macro: {mit_f1_macro:.4f}\")\n",
    "print(f\"Precision-Macro: {mit_precision_macro:.4f}\")\n",
    "print(f\"Recall-Macro: {mit_recall_macro:.4f}\")\n",
    "print(f\"\\nPer-class F1 scores:\")\n",
    "for lbl, f1 in zip(mit_labels, mit_f1_per_class):\n",
    "    print(f\"  Class {int(lbl)}: {f1:.4f}\")\n",
    "print(f\"\\nMIT-BIH Confusion Matrix (rows=true, cols=pred):\\n{mit_confusion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fitted MIT-trained XGBoost on the entire PTB dataset (train + val)\n",
    "from src.utils.preprocessing import prepare_ptbdb\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Evaluating MIT-trained 5-class XGBoost mapped to binary on full PTB (train+val)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load PTB split (both train and test)\n",
    "# validation is left out to compare \n",
    "ptb_dir = \"/home/christianm/Projects/Repos/heartbeat_classification/data/processed/ptb\"\n",
    "X_ptb_train = pd.read_csv(f\"{ptb_dir}/X_ptb_train.csv\").values\n",
    "y_ptb_train = pd.read_csv(f\"{ptb_dir}/y_ptb_train.csv\").iloc[:, 0].values.astype(int)\n",
    "X_ptb_train_sm = pd.read_csv(f\"{ptb_dir}/X_ptb_train_sm.csv\").values\n",
    "y_ptb_train_sm = pd.read_csv(f\"{ptb_dir}/y_ptb_train_sm.csv\").iloc[:, 0].values.astype(int)\n",
    "X_ptb_test = pd.read_csv(f\"{ptb_dir}/X_ptb_test.csv\").values\n",
    "y_ptb_test = pd.read_csv(f\"{ptb_dir}/y_ptb_test.csv\").iloc[:, 0].values.astype(int)\n",
    "X_ptb_val = pd.read_csv(f\"{ptb_dir}/X_ptb_val.csv\").values\n",
    "y_ptb_val = pd.read_csv(f\"{ptb_dir}/y_ptb_val.csv\").iloc[:, 0].values.astype(int)\n",
    "X_ptb_full = np.vstack([X_ptb_train, X_ptb_test, X_ptb_val])\n",
    "y_ptb_full = np.concatenate([y_ptb_train, y_ptb_test, y_ptb_val])\n",
    "\n",
    "# Predict probabilities for 5 classes and map to binary (0 -> 0, 1/2/3/4 -> 1)\n",
    "ptb_proba_5_full = estimator.predict_proba(X_ptb_full)\n",
    "y_pred_ptb_5_full = np.argmax(ptb_proba_5_full, axis=1)\n",
    "\n",
    "y_pred_ptb_bin_full = (y_pred_ptb_5_full != 0).astype(int)\n",
    "\n",
    "# Metrics\n",
    "acc_full = accuracy_score(y_ptb_full, y_pred_ptb_bin_full)\n",
    "prec_macro_full, rec_macro_full, f1_macro_full, _ = precision_recall_fscore_support(\n",
    "    y_ptb_full, y_pred_ptb_bin_full, average=\"macro\", zero_division=0\n",
    ")\n",
    "cm_full = confusion_matrix(y_ptb_full, y_pred_ptb_bin_full, labels=[0, 1])\n",
    "\n",
    "# Distributions\n",
    "unique_full, counts_full = np.unique(y_pred_ptb_5_full, return_counts=True)\n",
    "pred_dist = {int(k): int(v) for k, v in zip(unique_full.tolist(), counts_full.tolist())}\n",
    "true_dist = {int(k): int(v) for k, v in zip(*np.unique(y_ptb_full, return_counts=True))}\n",
    "\n",
    "print(\"PTB (full) predicted 5-class distribution:\", pred_dist)\n",
    "print(\"PTB (full) true binary distribution:\", true_dist)\n",
    "print(f\"PTB (full, mapped) Accuracy: {acc_full:.4f}\")\n",
    "print(f\"PTB (full, mapped) F1-Macro: {f1_macro_full:.4f}\")\n",
    "print(\"PTB (full, mapped) Confusion Matrix (rows=true, cols=pred):\\n\", cm_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acce4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit XGBoost on PTB (binary) with SMOTE using the same params, then evaluate on PTB full\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Refitting XGBoost with best parameters and evaluating on PTB (binary) TEST using pre-processed dataset - leaving out validation dataset.\")\n",
    "print(f\"Sampling: SMOTE | Outlier removal: {False}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 2) Clean params from GridSearchCV (strip 'classifier__' prefix)\n",
    "best_params_clean_ptb = {k.replace(\"classifier__\", \"\"): v for k, v in params.items()}\n",
    "\n",
    "print(f\"Best Params: {best_params_clean_ptb}\")\n",
    "\n",
    "# 3) Build pipeline: SMOTE (train only) + XGBClassifier (binary)\n",
    "pipe_ptb = Pipeline([\n",
    "    (\"sampler\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", xgb.XGBClassifier(\n",
    "        **best_params_clean_ptb,\n",
    "        objective=\"binary:logistic\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\",\n",
    "    )),\n",
    "])\n",
    "\n",
    "# 4) Fit on PTB train\n",
    "pipe_ptb.fit(X_ptb_train, y_ptb_train)\n",
    "\n",
    "# 5) Evaluate on PTB full (binary)\n",
    "# Option A: use direct class predictions\n",
    "y_pred_val = pipe_ptb.predict(X_ptb_test).astype(int)\n",
    "\n",
    "# Option B (equivalent): threshold positive-class probability at 0.5\n",
    "# proba_full = pipe_ptb.predict_proba(X_ptb_full)[:, 1]\n",
    "# y_pred_ptb_full = (proba_full >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "acc_full = accuracy_score(y_ptb_test, y_pred_val)\n",
    "prec_macro_full, rec_macro_full, f1_macro_full, _ = precision_recall_fscore_support(\n",
    "    y_ptb_test, y_pred_val, average=\"macro\", zero_division=0\n",
    ")\n",
    "cm_full = confusion_matrix(y_ptb_test, y_pred_val, labels=[0, 1])\n",
    "\n",
    "# Distributions\n",
    "pred_labels, pred_counts = np.unique(y_pred_val, return_counts=True)\n",
    "true_labels, true_counts = np.unique(y_ptb_full, return_counts=True)\n",
    "pred_dist = dict(zip(pred_labels.tolist(), pred_counts.tolist()))\n",
    "true_dist = dict(zip(true_labels.tolist(), true_counts.tolist()))\n",
    "\n",
    "print(\"PTB (full) predicted binary distribution:\", pred_dist)\n",
    "print(\"PTB (full) true binary distribution:\", true_dist)\n",
    "print(f\"PTB (full) Accuracy: {acc_full:.4f}\")\n",
    "print(f\"PTB (full) F1-Macro: {f1_macro_full:.4f}\")\n",
    "print(\"PTB (full) Confusion Matrix (rows=true, cols=pred):\\n\", cm_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PTB-trained binary model on MIT dataset\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Transfer Learning: Evaluating PTB-trained binary XGBoost on MIT-BIH dataset\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use MIT validation set (already loaded from previous cells)\n",
    "# X_val and y_val are from MIT-BIH\n",
    "\n",
    "# Get binary predictions from PTB model on MIT data\n",
    "y_pred_mit_binary = pipe_ptb.predict(X_val)\n",
    "\n",
    "# ============================================================================\n",
    "# Evaluation 1: Multi-class abnormal mapping\n",
    "# Map MIT classes: 0→0 (normal), {1,2,3,4}→1 (all abnormal)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Evaluation 1: All abnormal classes (1-4) mapped to binary class 1\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "y_true_mit_multi_binary = (y_val != 0).astype(int)  # 0 stays 0, all others become 1\n",
    "\n",
    "acc_1 = accuracy_score(y_true_mit_multi_binary, y_pred_mit_binary)\n",
    "prec_macro_1, rec_macro_1, f1_macro_1, _ = precision_recall_fscore_support(\n",
    "    y_true_mit_multi_binary, y_pred_mit_binary, average=\"macro\", zero_division=0\n",
    ")\n",
    "prec_per_class_1, rec_per_class_1, f1_per_class_1, _ = precision_recall_fscore_support(\n",
    "    y_true_mit_multi_binary, y_pred_mit_binary, average=None, labels=[0, 1], zero_division=0\n",
    ")\n",
    "cm_1 = confusion_matrix(y_true_mit_multi_binary, y_pred_mit_binary, labels=[0, 1])\n",
    "\n",
    "# Distribution info\n",
    "true_dist_multi = {int(k): int(v) for k, v in zip(*np.unique(y_true_mit_multi_binary, return_counts=True))}\n",
    "pred_dist_multi = {int(k): int(v) for k, v in zip(*np.unique(y_pred_mit_binary, return_counts=True))}\n",
    "\n",
    "print(f\"\\nMIT true binary distribution (all abnormal): {true_dist_multi}\")\n",
    "print(f\"PTB model predictions distribution: {pred_dist_multi}\")\n",
    "print(f\"\\nAccuracy: {acc_1:.4f}\")\n",
    "print(f\"F1-Macro: {f1_macro_1:.4f}\")\n",
    "print(f\"Precision-Macro: {prec_macro_1:.4f}\")\n",
    "print(f\"Recall-Macro: {rec_macro_1:.4f}\")\n",
    "print(f\"\\nPer-class F1 scores:\")\n",
    "for lbl, f1 in zip([0, 1], f1_per_class_1):\n",
    "    class_name = \"Normal\" if lbl == 0 else \"Abnormal (all 1-4)\"\n",
    "    print(f\"  Class {lbl} ({class_name}): {f1:.4f}\")\n",
    "print(f\"\\nConfusion Matrix (rows=true, cols=pred):\\n{cm_1}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Evaluation 2: Single-class abnormal mapping\n",
    "# Map MIT classes: 0→0 (normal), 1→1 (abnormal), drop classes {2,3,4}\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Evaluation 2: Only class 1 mapped to binary class 1 (classes 2,3,4 dropped)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create mask: keep only MIT classes 0 and 1\n",
    "keep_mask = (y_val == 0) | (y_val == 1)\n",
    "y_val_filtered = y_val[keep_mask]\n",
    "X_val_filtered = X_val[keep_mask]\n",
    "y_pred_mit_binary_filtered = pipe_ptb.predict(X_val_filtered)\n",
    "\n",
    "# Map to binary: 0→0, 1→1 (already binary since we filtered)\n",
    "y_true_mit_single_binary = y_val_filtered.astype(int)\n",
    "\n",
    "acc_2 = accuracy_score(y_true_mit_single_binary, y_pred_mit_binary_filtered)\n",
    "prec_macro_2, rec_macro_2, f1_macro_2, _ = precision_recall_fscore_support(\n",
    "    y_true_mit_single_binary, y_pred_mit_binary_filtered, average=\"macro\", zero_division=0\n",
    ")\n",
    "prec_per_class_2, rec_per_class_2, f1_per_class_2, _ = precision_recall_fscore_support(\n",
    "    y_true_mit_single_binary, y_pred_mit_binary_filtered, average=None, labels=[0, 1], zero_division=0\n",
    ")\n",
    "cm_2 = confusion_matrix(y_true_mit_single_binary, y_pred_mit_binary_filtered, labels=[0, 1])\n",
    "\n",
    "# Distribution info\n",
    "true_dist_single = {int(k): int(v) for k, v in zip(*np.unique(y_true_mit_single_binary, return_counts=True))}\n",
    "pred_dist_single = {int(k): int(v) for k, v in zip(*np.unique(y_pred_mit_binary_filtered, return_counts=True))}\n",
    "dropped_count = len(y_val) - len(y_val_filtered)\n",
    "\n",
    "print(f\"\\nMIT samples: {len(y_val)} total, {dropped_count} dropped (classes 2,3,4), {len(y_val_filtered)} kept\")\n",
    "print(f\"MIT true binary distribution (class 1 only): {true_dist_single}\")\n",
    "print(f\"PTB model predictions distribution: {pred_dist_single}\")\n",
    "print(f\"\\nAccuracy: {acc_2:.4f}\")\n",
    "print(f\"F1-Macro: {f1_macro_2:.4f}\")\n",
    "print(f\"Precision-Macro: {prec_macro_2:.4f}\")\n",
    "print(f\"Recall-Macro: {rec_macro_2:.4f}\")\n",
    "print(f\"\\nPer-class F1 scores:\")\n",
    "for lbl, f1 in zip([0, 1], f1_per_class_2):\n",
    "    class_name = \"Normal\" if lbl == 0 else \"Abnormal (class 1 only)\"\n",
    "    print(f\"  Class {lbl} ({class_name}): {f1:.4f}\")\n",
    "print(f\"\\nConfusion Matrix (rows=true, cols=pred):\\n{cm_2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
