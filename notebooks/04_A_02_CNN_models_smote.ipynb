{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16e5bf6",
   "metadata": {},
   "source": [
    "# CNN Models\n",
    "\n",
    "--> Results for Table 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c93d0b-2da6-494a-be5c-c0b962c399b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from src.utils.dl_architectures import cnn1, cnn2, cnn3, cnn4, cnn5, cnn6, cnn7, cnn8, cnn9\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "from pathlib import Path\n",
    "import re \n",
    "\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "print(tf.config.list_physical_devices('GPU'))  # should show []\n",
    "from contextlib import redirect_stdout\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from src.visualization.visualization import plot_training_history \n",
    "from src.visualization.confusion_matrix import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3585c9f-5063-4232-9b19-8de0daafe70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_METHOD = \"SMOTE\"\n",
    "REMOVE_OUTLIERS = False\n",
    "OUTPUT_PATH = \"src/models/MIT_02_03_dl_models/CNN/\"\n",
    "REPORTS_PATH = \"reports/04_dl_models/\" \n",
    "results_csv = REPORTS_PATH+\"05_DL_model_comparison.csv\"\n",
    "models = {\"cnn1_sm\": {}, \"cnn2_sm\": {}, \"cnn3_sm\": {}, \"cnn4_sm\": {}, 'cnn5_sm': {},\n",
    "          \"cnn6_sm\": {}, \"cnn7_sm\": {}, \"cnn8_sm\": {}, \"cnn9_sm\": {}}\n",
    "model_names = list(models.keys())\n",
    "\n",
    "#import MIT data\n",
    "df_mitbih_test = pd.read_csv('data/original/mitbih_test.csv', header = None)\n",
    "\n",
    "#X_train = pd.read_csv('data/processed/mitbih/X_train.csv')\n",
    "#y_train = pd.read_csv('data/processed/mitbih/y_train.csv')\n",
    "#y_train = y_train['187']\n",
    "\n",
    "X_train_sm = pd.read_csv('data/processed/mitbih/X_train_sm.csv')\n",
    "y_train_sm = pd.read_csv('data/processed/mitbih/y_train_sm.csv')\n",
    "y_train_sm = y_train_sm['187']\n",
    "\n",
    "X_val = pd.read_csv('data/processed/mitbih/X_val.csv')\n",
    "y_val = pd.read_csv('data/processed/mitbih/y_val.csv')\n",
    "y_val = y_val['187']\n",
    "\n",
    "X_test = df_mitbih_test.drop(187, axis = 1)\n",
    "y_test = df_mitbih_test[187]\n",
    "\n",
    "# Optional: Reduce dataset size for quicker testing\n",
    "if False:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # Subsample training set to 10 % (keeping all classes)\n",
    "    X_train_small, _, y_train_small, _ = train_test_split(\n",
    "        X_train_sm, y_train_sm,\n",
    "        train_size=0.05,\n",
    "        stratify=y_train_sm,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Subsample test set to 10 % as well\n",
    "    X_test_small, _, y_test_small, _ = train_test_split(\n",
    "        X_test, y_test,\n",
    "        train_size=0.05,\n",
    "        stratify=y_test,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Reduced MIT-BIH dataset\")\n",
    "    print(f\"\\tTraining size: {X_train_small.shape}, {y_train_small.shape}\")\n",
    "    print(f\"\\tTest size: {X_test_small.shape}, {y_test_small.shape}\")\n",
    "\n",
    "    # Assign back for your pipeline\n",
    "    X_train_sm, y_train_sm = X_train_small, y_train_small\n",
    "    X_test,  y_test  = X_test_small,  y_test_small\n",
    "\n",
    "# Reshape the data for 1D CNN\n",
    "X_train_sm_cnn = np.expand_dims(X_train_sm, axis=2)\n",
    "X_val_cnn = np.expand_dims(X_val, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2) \n",
    "\n",
    "display(X_train_sm_cnn.shape)\n",
    "display(X_val_cnn.shape)\n",
    "display(X_test_cnn.shape)\n",
    "\n",
    "\n",
    "def parse_epoch_from_name(name, default_epochs=512):\n",
    "    # Expect pattern like ..._epoch_12_...; returns int if found else default\n",
    "    m = re.search(r\"epoch_(\\d+)\", name)\n",
    "    return int(m.group(1)) if m else default_epochs\n",
    "\n",
    "def parse_val_loss_from_name(name):\n",
    "    # Expect pattern like ..._valloss_0.1234.keras\n",
    "    m = re.search(r\"valloss_([0-9]+\\.[0-9]+)\", name)\n",
    "    return float(m.group(1)) if m else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f3101-3dea-4302-9ba0-89798614a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"cnn1_sm\"][\"model\"] = cnn1\n",
    "models[\"cnn2_sm\"][\"model\"] = cnn2\n",
    "models[\"cnn3_sm\"][\"model\"] = cnn3\n",
    "models[\"cnn4_sm\"][\"model\"] = cnn4\n",
    "models[\"cnn5_sm\"][\"model\"] = cnn5\n",
    "models[\"cnn6_sm\"][\"model\"] = cnn6\n",
    "models[\"cnn7_sm\"][\"model\"] = cnn7\n",
    "models[\"cnn8_sm\"][\"model\"] = cnn8\n",
    "models[\"cnn9_sm\"][\"model\"] = cnn9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737fc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model summary\n",
    "cnn1.summary()\n",
    "\n",
    "cnn2.summary()\n",
    "\n",
    "cnn3.summary()\n",
    "\n",
    "cnn4.summary()\n",
    "\n",
    "cnn5.summary()\n",
    "\n",
    "cnn6.summary()\n",
    "\n",
    "cnn7.summary()\n",
    "\n",
    "cnn8.summary()\n",
    "\n",
    "cnn9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9789e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_metrics_to_csv(metrics: dict, csv_path: str):\n",
    "    \"\"\"\n",
    "    Appends or updates a row in the CSV based on a unique key:\n",
    "    (model_name, batch_size, training_size, lr_start, lr_schedule).\n",
    "\n",
    "    If a matching row exists, it is replaced with the new row.\n",
    "    All other rows remain unchanged.\n",
    "    \"\"\"\n",
    "\n",
    "    df_new = pd.DataFrame([metrics])\n",
    "\n",
    "    # identifier columns for uniqueness\n",
    "    key_cols = [\"model_name\", \"batch_size\", \"training_size\", \"lr_start\", \"lr_schedule\"]\n",
    "\n",
    "    if os.path.exists(csv_path):\n",
    "        df_existing = pd.read_csv(csv_path)\n",
    "\n",
    "        # ensure column alignment\n",
    "        all_cols = sorted(set(df_existing.columns).union(df_new.columns))\n",
    "        df_existing = df_existing.reindex(columns=all_cols)\n",
    "        df_new = df_new.reindex(columns=all_cols)\n",
    "\n",
    "        # remove row(s) with matching key\n",
    "        mask_match = np.ones(len(df_existing), dtype=bool)\n",
    "        for col in key_cols:\n",
    "            mask_match &= (df_existing[col] == df_new.iloc[0][col])\n",
    "\n",
    "        df_existing = df_existing[~mask_match]  # drop matching row(s)\n",
    "\n",
    "        # append new row\n",
    "        df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "\n",
    "        # save\n",
    "        df_combined.to_csv(csv_path, index=False)\n",
    "\n",
    "    else:\n",
    "        # create new CSV\n",
    "        df_new.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca563f08-e666-43be-b470-e0e9e8a3eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(\"*\"*80)\n",
    "    print(\"*\"*5,'\\t',model_name,'\\t',\"*\"*5)\n",
    "    print(\"*\"*80)\n",
    "\n",
    "    BATCH_SIZE = 512\n",
    "    EPOCHS = 200\n",
    "\n",
    "    initial_learning_rate = 1e-3\n",
    "    lr_schedule = ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.96)\n",
    "\n",
    "\n",
    "    #Early stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',        # what to monitor \n",
    "        patience=20,               # how many epochs with no improvement before stopping\n",
    "        restore_best_weights=True, \n",
    "        min_delta=0.001            #only stop if improvement < 0.001\n",
    "    )\n",
    "\n",
    "\n",
    "    cf = model[\"model\"]\n",
    "\n",
    "    #Compile model, change model when needed\n",
    "    cf.compile(\n",
    "        optimizer=Adam(learning_rate=lr_schedule),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    #Define where and how to save the best model, note lr and bs\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=f'{OUTPUT_PATH}{model_name}_BS{BATCH_SIZE}_best.keras',\n",
    "        monitor='val_loss',            # metric to monitor\n",
    "        mode='min',                    # minimize loss\n",
    "        save_best_only=True,          \n",
    "        verbose=1                      # print message when a model is saved\n",
    "    )\n",
    "\n",
    "    #Training\n",
    "    history = cf.fit(                      \n",
    "        X_train_sm_cnn,\n",
    "        y_train_sm,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val_cnn, y_val),\n",
    "        callbacks=[checkpoint, early_stop] \n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1) Basic training info\n",
    "    # ----------------------------\n",
    "    hist = history.history\n",
    "    n_epochs = len(hist[\"loss\"])\n",
    "\n",
    "    # best epoch according to val_loss\n",
    "    best_epoch = int(np.argmin(hist[\"val_loss\"]))\n",
    "    last_epoch = n_epochs - 1\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) Predictions for test\n",
    "    # ----------------------------\n",
    "\n",
    "    # !!! make sure to set restore_best_weights=True in early stopping\n",
    "    # or load best model before predicting \n",
    "    y_prob = cf.predict(X_test)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3) F1-macro and per-class F1 on TEST\n",
    "    # ----------------------------\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    f1_per_class = f1_score(y_test, y_pred, average=None)  # array (0–4)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4) Build output dictionary\n",
    "    # ----------------------------\n",
    "    # flatten F1-per-class into separate columns\n",
    "    f1_class_columns = {\n",
    "        f\"test_f1_class_{i}\": float(score) \n",
    "        for i, score in enumerate(f1_per_class)\n",
    "    }\n",
    "\n",
    "    metrics = {\n",
    "        \"model_name\": model_name,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"training_size\": X_train_sm_cnn.shape[0],\n",
    "        \"lr_start\": initial_learning_rate,\n",
    "        \"lr_schedule\": 'EXP_DECAY',\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"last_epoch\": last_epoch,\n",
    "        \n",
    "        # best epoch values (from history)\n",
    "        \"train_loss_best\": float(hist[\"loss\"][best_epoch]),\n",
    "        \"val_loss_best\": float(hist[\"val_loss\"][best_epoch]),\n",
    "        \"train_acc_best\": float(hist[\"accuracy\"][best_epoch]),\n",
    "        \"val_acc_best\": float(hist[\"val_accuracy\"][best_epoch]),\n",
    "\n",
    "        # last epoch values\n",
    "        \"train_loss_last\": float(hist[\"loss\"][last_epoch]),\n",
    "        \"val_loss_last\": float(hist[\"val_loss\"][last_epoch]),\n",
    "        \"train_acc_last\": float(hist[\"accuracy\"][last_epoch]),\n",
    "        \"val_acc_last\": float(hist[\"val_accuracy\"][last_epoch]),\n",
    "\n",
    "        # TEST metrics\n",
    "        \"test_f1_macro\": float(f1_macro),\n",
    "        \"test_accuracy\": float(acc)\n",
    "    }\n",
    "\n",
    "    # merge F1-per-class columns\n",
    "    metrics.update(f1_class_columns)\n",
    "\n",
    "\n",
    "    append_metrics_to_csv(metrics, csv_path=results_csv)\n",
    "\n",
    "\n",
    "    with open(f\"{OUTPUT_PATH}{model_name}_BS{BATCH_SIZE}_full.pkl\", \"wb\") as f: #change for model\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    fig_cm, ax_cm = plot_confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "        normalize=True,\n",
    "        class_names=[\"1\",\"2\",\"3\",\"4\",\"5\"],\n",
    "        title=f\"Confusion Matrix — {model_name}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    fig_cm.savefig(\n",
    "        f\"{REPORTS_PATH}/{model_name}_BS{BATCH_SIZE}_confusion_matrix.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close(fig_cm)\n",
    "\n",
    "    plot_training_history(\n",
    "        history=history,                     # raw history\n",
    "        save_dir=REPORTS_PATH,               # where plots go\n",
    "        prefix=f\"{model_name}_BS{BATCH_SIZE}_training_history\"  # prefix for filenames\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
