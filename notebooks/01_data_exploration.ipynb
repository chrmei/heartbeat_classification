{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heartbeat Classification - Data Exploration\n",
    "\n",
    "## Project Overview\n",
    "Exploratory data analysis on ECG heartbeat classification datasets.\n",
    "\n",
    "**Datasets:**\n",
    "- MIT-BIH Arrhythmia Dataset (5 classes: Normal, Supraventricular, Ventricular, Fusion, Unknown)\n",
    "- PTB Diagnostic ECG Database (2 classes: Normal, Abnormal/MI)\n",
    "\n",
    "**Objective:** Analyze data structure, class distributions, and identify preprocessing requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy.stats import kruskal, chisquare, kstest\n",
    "\n",
    "# Data handling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# System libraries\n",
    "import sys\n",
    "# Add the project root directory to Python path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Custom utils\n",
    "from src.utils import generate_data_audit_report, generate_summary_report\n",
    "from src.visualization.visualization import plot_heartbeat, plot_multiple_heartbeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Descriptions\n",
    "\n",
    "### PTBDB_*.csv\n",
    "\n",
    "- Derived from PTB Diagnostic ECG Database\n",
    "- Binary classification: normal vs abnormal (myocardial infarction) heartbeats\n",
    "\n",
    "### MITBIH_*.csv\n",
    "\n",
    "- Derived from PhysioNet's MIT-BIH Arrhythmia Dataset\n",
    "- Multiclass classification: 5 categories (N: Normal, S: Supraventricular, V: Ventricular, F: Fusion, Q: Unknown)\n",
    "- Each column represents a time point in a 10-second ECG signal, sampled at 125Hz\n",
    "- Values normalized between 0 and 1\n",
    "\n",
    "### Common Characteristics\n",
    "\n",
    "- Each column represents a time point in a 10-second ECG signal, sampled at 125Hz\n",
    "- Values normalized between 0 and 1\n",
    "- Zero-padded to fixed dimension of 188 columns\n",
    "- Column 187 = class label (target)\n",
    "- Datasets are pre-split into train/test partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_normal = pd.read_csv(\"data/original/ptbdb_normal.csv\", header=None)\n",
    "display(ptbdb_normal.head())\n",
    "\n",
    "print(\"Dataset shapes:\", ptbdb_normal.shape, ptbdb_normal.shape)\n",
    "print(\"Data types:\", ptbdb_normal.dtypes.value_counts())\n",
    "print(\"Memory usage:\", ptbdb_normal.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
    "print(\"Duplicates - deleted! \", ptbdb_normal.duplicated().sum())\n",
    "print(ptbdb_normal[187].value_counts())\n",
    "\n",
    "ptbdb_normal.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_abnormal = pd.read_csv(\"data/original/ptbdb_abnormal.csv\", header=None)\n",
    "display(ptbdb_abnormal.head())\n",
    "\n",
    "print(\"Dataset shapes:\", ptbdb_abnormal.shape, ptbdb_abnormal.shape)\n",
    "print(\"Data types:\", ptbdb_abnormal.dtypes.value_counts())\n",
    "print(\"Memory usage:\", ptbdb_abnormal.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
    "print(\"Duplicates - deleted! \", ptbdb_abnormal.duplicated().sum())\n",
    "\n",
    "print(ptbdb_abnormal[187].value_counts())\n",
    "\n",
    "ptbdb_abnormal.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitbih_test = pd.read_csv(\"data/original/mitbih_test.csv\", header=None)\n",
    "display(mitbih_test.head())\n",
    "\n",
    "print(\"Dataset shapes:\", mitbih_test.shape, mitbih_test.shape)\n",
    "print(\"Data types:\", mitbih_test.dtypes.value_counts())\n",
    "print(\"Memory usage:\", mitbih_test.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
    "print(\"Duplicates - 0! \", mitbih_test.duplicated().sum())\n",
    "\n",
    "print(mitbih_test[187].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitbih_train = pd.read_csv(\"data/original/mitbih_train.csv\", header=None)\n",
    "display(mitbih_train.head())\n",
    "\n",
    "print(\"Dataset shapes:\", mitbih_train.shape, mitbih_train.shape)\n",
    "print(\"Data types:\", mitbih_train.dtypes.value_counts())\n",
    "print(\"Memory usage:\", mitbih_train.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
    "print(\"Duplicates - 0! \", mitbih_train.duplicated().sum())\n",
    "\n",
    "print(mitbih_train[187].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitbih labels mapping\n",
    "mitbih_labels_map = {0: 'N', 1: 'S', 2: 'V', 3: 'F', 4: 'Q'}\n",
    "mitbih_labels_to_desc = {\"N\": \"Normal\", \"S\": \"Supraventricular premature beat\", \"V\": \"Premature ventricular contraction\", \"F\": \"Fusion of V+N\", \"Q\": \"Unclassified\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "datasets = [mitbih_train, mitbih_test, ptbdb_normal, ptbdb_abnormal]\n",
    "for i, dataset in enumerate(datasets):\n",
    "    total_missing = dataset.isnull().sum().sum()\n",
    "    missing_per_column = dataset.isnull().sum()\n",
    "    missing_percentage = (dataset.isnull().sum() / len(dataset)) * 100\n",
    "    print(f\"Dataset {i+1} - Total missing values: {total_missing}\")\n",
    "    # print(f\"Dataset {i+1} - Missing values per column:\\n{missing_per_column}\")\n",
    "    # print(f\"Dataset {i+1} - Missing values percentage per column:\\n{missing_percentage}\\n\")\n",
    "\n",
    "    # Data range analysis\n",
    "    # print(\"Signal amplitude range:\", dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NO MISSING VALUES!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb = pd.concat([ptbdb_abnormal, ptbdb_normal], axis=0).reset_index(drop=True)\n",
    "mitbih = pd.concat([mitbih_train, mitbih_test], axis=0).reset_index(drop=True)\n",
    "for i, dataset in enumerate([ptbdb, mitbih ]):\n",
    "    if i == 0:\n",
    "        name = \"ptbdb\"\n",
    "    else:\n",
    "        name = \"mitbih\"\n",
    "    print(f\"Dataset {name} - Shape: {dataset.shape}\")\n",
    "    zero_mean_columns = dataset.columns[dataset.describe().loc['mean'] == 0].tolist()\n",
    "    print(f\"Dataset {name} - Columns (columnname(s)) with zero mean: {zero_mean_columns}\")\n",
    "    display(dataset.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Distribution & Imbalance Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MITBIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = mitbih.iloc[:, -1].value_counts().sort_index()\n",
    "imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "\n",
    "# Statistical tests for imbalance\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p_value, dof, expected = chi2_contingency(class_counts.values.reshape(1, -1))\n",
    "\n",
    "print(f\"Chi-squared test statistic: {chi2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of freedom: {dof}\") \n",
    "\n",
    "print(f\"Class counts:\\t{class_counts}\") # pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map class IDs -> short + description labels\n",
    "labels = [\n",
    "    f\"{mitbih_labels_map[i]} - {mitbih_labels_to_desc[mitbih_labels_map[i]]}\"\n",
    "    for i in class_counts.index\n",
    "]\n",
    "\n",
    "# --- Colors ---\n",
    "colors = sns.color_palette(\"pastel\", len(class_counts))\n",
    "\n",
    "# --- Plot setup ---\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "plt.pie(class_counts, labels=labels, colors=colors, autopct='%1.1f%%')\n",
    "\n",
    "ax.set_title(\"Class Distribution in MIT-BIH Arrhythmia Dataset\", fontsize=16, weight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PTBDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = ptbdb.iloc[:, -1].value_counts().sort_index()\n",
    "expected = [class_counts.mean()] * len(class_counts)\n",
    "imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "\n",
    "chi2, p_value = chisquare(class_counts, expected)\n",
    "\n",
    "print(f\"Chi-squared test statistic: {chi2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.4f}\")\n",
    "\n",
    "print(f\"Class counts:\\t{class_counts}\") # pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"pastel\", len(class_counts))\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "class_counts = ptbdb[187].value_counts().sort_index()\n",
    "class_counts.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('PTB: Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTBDB: Normal vs Abnormal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_heartbeat = ptbdb[ptbdb[187] == 0].sample(3)\n",
    "abnormal_heartbeat = ptbdb[ptbdb[187] == 1].sample(3)\n",
    "fig = plot_multiple_heartbeats(normal_heartbeat, title=\"PTBDB Normal\")\n",
    "fig = plot_multiple_heartbeats(abnormal_heartbeat, title=\"PTBDB Abnormal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MITBIH: Plots for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mitbih[187].unique()\n",
    "colors = ['blue', 'green', 'red', 'orange', 'purple', 'brown', 'pink', 'cyan', 'magenta', 'lime']\n",
    "\n",
    "for i, _class in enumerate(classes):\n",
    "    heartbeat = mitbih[mitbih[187] == _class].sample(3)\n",
    "    title = f\"MITBIH Class {_class} - {mitbih_labels_map[_class]}: {mitbih_labels_to_desc[mitbih_labels_map[_class]]}\"\n",
    "    fig = plot_multiple_heartbeats(heartbeat, title=title, color=colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. R-R Distance Analysis\n",
    "\n",
    "Analysis of R-R distances (time between R peaks) to identify potential classification errors or unusual patterns.\n",
    "\n",
    "Each row contains 1.2R (heartbeat duration) and is zero-padded to fixed length for deep learning compatibility.\n",
    "R distance is calculated by:\n",
    "- Finding the index where zero-padding starts\n",
    "- Dividing by 1.2\n",
    "\n",
    "This analysis enables:\n",
    "- Comparison of R-R distances across classes\n",
    "- Identification of outliers and extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_nonzero_index(arr):\n",
    "    for i in range(len(arr) - 1, -1, -1):\n",
    "        if arr[i] != 0:\n",
    "            first_zero_index = ( i + 1 ) / 1.2\n",
    "            break\n",
    "        else:\n",
    "            first_zero_index = 0  # all zeros\n",
    "    return first_zero_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_r = ptbdb.iloc[:, :-1].apply(lambda row: find_first_nonzero_index(row.values), axis=1)\n",
    "result_ptbdb_r = pd.concat([ptbdb_r.rename('zero_pad_start'), ptbdb.iloc[:, -1].rename('target')], axis=1)\n",
    "\n",
    "result_ptbdb_r.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ptbdb_r[result_ptbdb_r[\"target\"] == 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ptbdb_r[result_ptbdb_r[\"target\"] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='target', y='zero_pad_start', data=result_ptbdb_r)\n",
    "plt.title('PTB Zero-padding Start vs Class', fontsize=16)\n",
    "plt.xlabel('PTB Class', fontsize=12)\n",
    "plt.ylabel('Zero-padding Start Index', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get outlier indices for each class\n",
    "def get_outliers_idx(df, value_col, class_col):\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for cls, group in df.groupby(class_col):\n",
    "        q1 = group[value_col].quantile(0.25)\n",
    "        q3 = group[value_col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_whisker = q1 - 1.5 * iqr\n",
    "        upper_whisker = q3 + 1.5 * iqr\n",
    "        \n",
    "        # Identify outliers\n",
    "        outliers = group[(group[value_col] < lower_whisker) | (group[value_col] > upper_whisker)]\n",
    "        outlier_indices.extend(outliers.index.tolist())\n",
    "    \n",
    "    return outlier_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [0,1]:\n",
    "    df = result_ptbdb_r[result_ptbdb_r[\"target\"] == c]\n",
    "    idx = get_outliers_idx(df, 'zero_pad_start', 'target')\n",
    "    \n",
    "    proportion = len(idx) / len(df) * 100\n",
    "\n",
    "    if c == 0:\n",
    "        n = \"Normal\"\n",
    "    if c == 1:\n",
    "        n = \"Abnormal\"\n",
    "\n",
    "    plot_multiple_heartbeats(ptbdb.iloc[idx].sample(3), title=f\"PTBDB Extremes in {n} Class. Proportion:{proportion:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MITBIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitbih_r = mitbih.iloc[:, :-1].apply(lambda row: find_first_nonzero_index(row.values), axis=1)\n",
    "result_mitbih_r = pd.concat([mitbih_r.rename('zero_pad_start'), mitbih.iloc[:, -1].rename('target')], axis=1)\n",
    "\n",
    "result_mitbih_r.describe()\n",
    "\n",
    "result_mitbih_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in mitbih[187].unique():\n",
    "    display(result_mitbih_r[result_mitbih_r[\"target\"] == c].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='target', y='zero_pad_start', data=result_mitbih_r)\n",
    "plt.title('PTB Zero-padding Start vs Target', fontsize=16)\n",
    "plt.xlabel('PTB Class', fontsize=12)\n",
    "plt.ylabel('Zero-padding Start Index', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in mitbih[187].unique():\n",
    "    df = result_mitbih_r[result_mitbih_r[\"target\"] == c]\n",
    "    idx = get_outliers_idx(df, 'zero_pad_start', 'target')\n",
    "    \n",
    "    proportion = len(idx) / len(df) * 100\n",
    "\n",
    "    sample = mitbih.iloc[idx]\n",
    "    \n",
    "    if len(sample) > 0:\n",
    "        min_len = min([len(sample), 3])\n",
    "        plot_multiple_heartbeats(sample.sample(min_len), title=f\"MIT-BIH Extremes in {str(c)} Class. Proportion:{proportion:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Tests for Class Differences\n",
    "\n",
    "#### Kruskal-Wallis Test on Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal-Wallis is univariate, so a multivariate approach is needed:\n",
    "1. Apply PCA to reduce dimensionality\n",
    "2. Run Kruskal-Wallis test on each principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import kruskal\n",
    "import pandas as pd\n",
    "\n",
    "def kruskal_multivariate(df, target_col=None, n_components=5):\n",
    "    if target_col is None:\n",
    "        target_col = df.columns[-1]\n",
    "\n",
    "    X = df.drop(columns=target_col)\n",
    "    y = df[target_col]\n",
    "\n",
    "    p_values = []\n",
    "    # Reduce to n_components using PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    for i in range(n_components):\n",
    "        groups = [X_pca[y == cls, i] for cls in pd.unique(y)]\n",
    "        stat, p = kruskal(*groups)\n",
    "        p_values.append(p)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'PC': [f'PC{i+1}' for i in range(n_components)],\n",
    "        'p_value': p_values\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_results_mit = kruskal_multivariate(mitbih, target_col=187, n_components=5)\n",
    "print(kruskal_results_mit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_results_ptb = kruskal_multivariate(ptbdb, target_col=187, n_components=2)\n",
    "print(kruskal_results_ptb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low p-values indicate significant differences along principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairwise comparison of R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "\n",
    "def kruskal_class_pairs(df, target_col=None, agg_func='mean'):\n",
    "    if target_col is None:\n",
    "        target_col = df.columns[-1]\n",
    "\n",
    "    X = df.drop(columns=target_col)\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Aggregate features into a single value per sample\n",
    "    if agg_func == 'mean':\n",
    "        X_agg = X.mean(axis=1)\n",
    "    elif agg_func == 'sum':\n",
    "        X_agg = X.sum(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"agg_func must be 'mean' or 'sum'\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    classes = pd.unique(y)\n",
    "    for class1, class2 in combinations(classes, 2):\n",
    "        group1 = X_agg[y == class1]\n",
    "        group2 = X_agg[y == class2]\n",
    "\n",
    "        stat, p = kruskal(group1, group2)\n",
    "        results.append({\n",
    "            'class1': class1,\n",
    "            'class2': class2,\n",
    "            'p_value': p\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values('p_value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitbih_r_copy = result_mitbih_r.copy()\n",
    "result_ptbdb_r_copy = result_ptbdb_r.copy()\n",
    "\n",
    "mitbih_r_copy['target'] = 'MIT_' + mitbih_r_copy['target'].astype(str)\n",
    "result_ptbdb_r_copy['target'] = 'PTB_' + result_ptbdb_r_copy['target'].astype(str)\n",
    "\n",
    "combined_df = pd.concat([mitbih_r_copy, result_ptbdb_r_copy], ignore_index=True)\n",
    "\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_pairwise_df = kruskal_class_pairs(combined_df, target_col='target', agg_func='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_pairwise_df[kruskal_pairwise_df[\"p_value\"] > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_pairwise_df.sort_values(by='class1', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Findings\n",
    " \n",
    "### PTB Dataset\n",
    "\n",
    "1. Last column in PTBDB is empty (preserved for compatibility)\n",
    "2. Class imbalance validated through chi-squared test → resampling required\n",
    "3. Extreme values in R-R distances identified; proportion is low (0.2%)\n",
    "\n",
    "### MIT-BIH Dataset\n",
    "\n",
    "1. Severe class imbalance validated through chi-squared test → resampling required\n",
    "2. Extreme values in R-R distances identified; counts for classes 3 and 4 are relatively high\n",
    "3. MIT class 1 vs PTB class 1 may represent similar abnormal heartbeat patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Audit Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate audit reports for all CSV files (specify the correct path)\n",
    "generate_data_audit_report(data_dir=\"../data/original/\", output_dir=\"../reports/data_audit/\")\n",
    "\n",
    "# Generate summary report (specify the correct path)\n",
    "generate_summary_report(data_dir=\"../data/original/\", output_file=\"../reports/data_audit/data_summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
