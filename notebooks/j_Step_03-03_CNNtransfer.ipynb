{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5694e-e5a1-4b6e-90a9-8f566d9122b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Conv1D, MaxPooling1D, Flatten, Add, ReLU, LSTM, Reshape, Concatenate, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d1421-cfb0-47d4-a052-5e5fe4930f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PTB data\n",
    "X_ptb_train = pd.read_csv('data/processed/PTB/X_ptb_train.csv')\n",
    "y_ptb_train = pd.read_csv('data/processed/PTB/y_ptb_train.csv')\n",
    "\n",
    "X_ptb_train_sm = pd.read_csv('data/processed/PTB/X_ptb_train_sm.csv')\n",
    "y_ptb_train_sm = pd.read_csv('data/processed/PTB/y_ptb_train_sm.csv')\n",
    "\n",
    "X_ptb_val = pd.read_csv('data/processed/PTB/X_ptb_val.csv')\n",
    "y_ptb_val = pd.read_csv('data/processed/PTB/y_ptb_val.csv')\n",
    "\n",
    "X_ptb_test = pd.read_csv('data/processed/PTB/X_ptb_test.csv')\n",
    "y_ptb_test = pd.read_csv('data/processed/PTB/y_ptb_test.csv')\n",
    "\n",
    "\n",
    "display(X_ptb_train.shape)\n",
    "display(y_ptb_train.shape)\n",
    "\n",
    "display(X_ptb_train_sm.shape)\n",
    "display(y_ptb_train_sm.shape)\n",
    "\n",
    "display(X_ptb_val.shape)\n",
    "display(y_ptb_val.shape)\n",
    "\n",
    "display(X_ptb_test.shape)\n",
    "display(y_ptb_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the data for 1D CNN\n",
    "X_ptb_train_cnn = np.expand_dims(X_ptb_train, axis=2)\n",
    "X_ptb_train_sm_cnn = np.expand_dims(X_ptb_train_sm, axis=2)\n",
    "X_ptb_val_cnn = np.expand_dims(X_ptb_val, axis=2)\n",
    "X_ptb_test_cnn = np.expand_dims(X_ptb_test, axis=2)\n",
    "\n",
    "display(X_ptb_train_cnn.shape)\n",
    "display(y_ptb_train.shape)\n",
    "\n",
    "display(X_ptb_train_sm_cnn.shape)\n",
    "display(y_ptb_train_sm.shape)\n",
    "\n",
    "display(X_ptb_val_cnn.shape)\n",
    "display(y_ptb_val.shape)\n",
    "\n",
    "display(X_ptb_test_cnn.shape)\n",
    "display(y_ptb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f0c94-f018-403d-8482-d44575cb6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model for that will be retrained\n",
    "model_trained = load_model('best_dl_model/cnn8_sm_lrexpdec1e-3_earlystop_bs512_epoch_52_valloss_0.0676.keras')\n",
    "\n",
    "model_trained.summary()\n",
    "\n",
    "\n",
    "# Extract features \n",
    "feature_extractor = Model(inputs=model_trained.input, outputs=model_trained.get_layer('max_pooling1d_4').output)\n",
    "\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffff9b-52a3-4505-920c-cc8629198bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze all convolutional layers in feature_extractor\n",
    "for layer in feature_extractor.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a48bc2-4be9-4acc-a05e-4d425cf602e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested transfer models\n",
    "\n",
    "#transfer 2, with added dropout\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "\n",
    "#transfer 3, with changed dropout\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "\n",
    "#transfer 4, with dropout and batch normalization \n",
    "x = Flatten()(x)\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "transfer_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "#transfer 5, with changed dropout and batch normalization \n",
    "x = Flatten()(x)\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "transfer_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "#transfer 6\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "\n",
    "#transfer 7 \n",
    "x = Flatten()(x)\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "transfer_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "#transfer 8\n",
    "x = Flatten()(x)\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "transfer_model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759499f4-4efb-4eb4-8ca8-f9db011f5eec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build new classifier for 2 class problem\n",
    "\n",
    "# Input same shape as original\n",
    "input_layer = Input(shape=(187, 1))\n",
    "x = feature_extractor(input_layer, training=False)  # frozen convolutional base\n",
    "\n",
    "#add transfer model here: transfer 6\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "transfer_model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f52285-af6f-4a3b-ad8e-2026c7e486da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr exp dec: Learning rate with exponential decay\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96)\n",
    "\n",
    "#Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # what to monitor \n",
    "    patience=20,               # how many epochs with no improvement before stopping\n",
    "    restore_best_weights=True, \n",
    "    min_delta=0.001            #only stop if improvement < 0.001\n",
    ")\n",
    "\n",
    "#Compile when lr exp decay\n",
    "transfer_model.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Define where and how to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../transfer/cnn8_sm_lrexpdec_earlystop_bs512_transfer6_model_lrexpdec_earlystop_bs512_epoch_{epoch:02d}_valloss_{val_loss:.4f}.keras',   # file path (can be .keras or .h5), change name when needed\n",
    "    monitor='val_loss',            # metric to monitor\n",
    "    mode='min',                    # minimize loss\n",
    "    save_best_only=False,          # save model of every epoch\n",
    "    verbose=1                      # print message when a model is saved\n",
    ")\n",
    "\n",
    "#training\n",
    "history = transfer_model.fit(\n",
    "    X_ptb_train_sm_cnn, #PTB data\n",
    "    y_ptb_train_sm, #PTB data\n",
    "    epochs=500,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_ptb_val_cnn, y_ptb_val), #PTB data\n",
    "    callbacks=[checkpoint, early_stop] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cd13e-2128-4f00-ad0d-692cbab4ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, save_dir=\"../transfer\", prefix=\"cnn8_sm_lrexpdec_earlystop_bs512_transfer6_model_lrexpdec_earlystop_bs512\") #change name when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc61fa-6e11-4850-868d-f67031000958",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfer/cnn8_sm_lrexpdec_earlystop_bs512_transfer6_model_lrexpdec_earlystop_bs512.pkl\", \"wb\") as f: #change name when needed\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "\n",
    "best_model = load_model('../transfer/cnn8_sm_lrexpdec_earlystop_bs512_transfer6_model_lrexpdec_earlystop_bs512.keras') #change name when needed\n",
    "\n",
    "test_pred = best_model.predict(X_ptb_test_cnn) #PTB data\n",
    "y_test_class = y_ptb_test #PTB data\n",
    "y_pred_class = np.argmax(test_pred, axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class, digits=4))\n",
    "\n",
    "print(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions']))\n",
    "\n",
    "\n",
    "#save results of metrics\n",
    "with open(\"../transfer/cnn8_sm_lrexpdec_earlystop_bs512_transfer6_model_lrexpdec_earlystop_bs512.txt\", \"w\") as file: # change name when needed\n",
    "    file.write(\"\\nModel: CNN8 MIT transfer6 PTB\\n\")\n",
    "    file.write(\"\\nData augmentation: MIT Smote, PTB Smote\\n\")\n",
    "    file.write(\"\\nConfusion Matrix on test set:\\n\")\n",
    "    file.write(str(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions'])))\n",
    "    file.write(\"\\n\\nClassification Report on test set:\\n\")\n",
    "    file.write(classification_report(y_test_class, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66541ef1-a334-4d2a-b72a-7d19af4ec3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5582346-d48a-418f-9d0a-154e3b76919a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retraining with last residual block unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d7853-94b4-4d35-a7e8-3a7eba558e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all layers to see structure\n",
    "print(\"Feature extractor layers:\")\n",
    "for i, layer in enumerate(feature_extractor.layers):\n",
    "    print(f\"{i}: {layer.name} - Trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664b326-979b-4867-82b6-74398171c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make feature extractor trainable\n",
    "feature_extractor.trainable = True\n",
    "\n",
    "# first: Freeze all layers\n",
    "for layer in feature_extractor.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze ONLY the last residual block (here: last 7 layers)\n",
    "num_layers_last_block = 7  \n",
    "\n",
    "for layer in feature_extractor.layers[-num_layers_last_block:]:\n",
    "    layer.trainable = True\n",
    "    print(f\"Unfrozen: {layer.name}\")\n",
    "\n",
    "# Verification of trainable layers\n",
    "print(f\"\\nTotal layers: {len(feature_extractor.layers)}\")\n",
    "print(f\"Trainable layers: {sum([layer.trainable for layer in feature_extractor.layers])}\")\n",
    "print(f\"Frozen layers: {sum([not layer.trainable for layer in feature_extractor.layers])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5a853-f1b6-4c15-802f-a555ced63c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new classifier for 2 class problem\n",
    "\n",
    "# Input same shape as original\n",
    "input_layer = Input(shape=(187, 1))\n",
    "x = feature_extractor(input_layer, training=False)  # frozen convolutional base\n",
    "\n",
    "#add transfer model here: transfer 6\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "transfer_model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6460a0-f76d-4b85-b4bc-bd62bb889d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr exp dec\n",
    "# Learning rate with exponential decay\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96)\n",
    "\n",
    "#Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # what to monitor \n",
    "    patience=20,               # how many epochs with no improvement before stopping\n",
    "    restore_best_weights=True, \n",
    "    min_delta=0.001            #only stop if improvement < 0.001\n",
    ")\n",
    "\n",
    "#Compile when lr exp decay\n",
    "transfer_model.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Define where and how to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../transfer/cnn8_sm_lrexpdec_earlystop_bs512_unfrozen_transfer6_model_lrexpdec_earlystop_bs512_epoch_{epoch:02d}_valloss_{val_loss:.4f}.keras',   # file path (can be .keras or .h5), change name when needed\n",
    "    monitor='val_loss',            # metric to monitor\n",
    "    mode='min',                    # minimize loss\n",
    "    save_best_only=False,          # save model of every epoch\n",
    "    verbose=1                      # print message when a model is saved\n",
    ")\n",
    "\n",
    "#training\n",
    "history = transfer_model.fit(\n",
    "    X_ptb_train_sm_cnn, #PTB data\n",
    "    y_ptb_train_sm, #PTB data\n",
    "    epochs=500,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_ptb_val_cnn, y_ptb_val), #PTB data\n",
    "    callbacks=[checkpoint, early_stop] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe5fe1-da7d-468e-ac9b-c156d5899b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, save_dir=\"../transfer\", prefix=\"cnn8_sm_lrexpdec_earlystop_bs512_unfrozen_transfer6_model_lrexpdec_earlystop_bs512\") # change name when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ec76b-bf42-4021-a1b9-cb2cac3b8543",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../transfer/cnn8_sm_lrexpdec_earlystop_bs512_unfrozen_transfer6_model_lrexpdec_earlystop_bs512.pkl\", \"wb\") as f: # change name when needed\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "\n",
    "best_model = load_model('../transfer/cnn8_sm_lrexpdec_earlystop_bs512_unfrozen_transfer6_model_lrexpdec_earlystop_bs512.keras') # change name when needed\n",
    "\n",
    "test_pred = best_model.predict(X_ptb_test_cnn) #PTB data\n",
    "y_test_class = y_ptb_test #PTB data\n",
    "y_pred_class = np.argmax(test_pred, axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class, digits=4))\n",
    "\n",
    "print(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions']))\n",
    "\n",
    "\n",
    "#save results of metrics\n",
    "with open(\"../transfer/cnn8_sm_lrexpdec_earlystop_bs512_unfrozen_transfer6_model_lrexpdec_earlystop_bs512.txt\", \"w\") as file: # change name when needed\n",
    "    file.write(\"\\nModel: CNN8 MIT, transfer6 PTB \\n\")\n",
    "    file.write(\"\\nData augmentation: MIT Smote, PTB Smote\\n\")\n",
    "    file.write(\"\\nConfusion Matrix on test set:\\n\")\n",
    "    file.write(str(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions'])))\n",
    "    file.write(\"\\n\\nClassification Report on test set:\\n\")\n",
    "    file.write(classification_report(y_test_class, y_pred_class, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascientest_project",
   "language": "python",
   "name": "datascientest_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
