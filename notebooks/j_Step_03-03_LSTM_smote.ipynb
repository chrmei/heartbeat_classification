{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ec3a8-c7d6-4d69-807a-f2dcc8e0e7ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Conv1D, MaxPooling1D, Flatten, Add, ReLU, LSTM, Reshape, Concatenate, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOversampler\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80f5f1-cf8a-4b16-a726-47ec715edaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MIT data\n",
    "df_mitbih_test = pd.read_csv('data/original/mitbih_test.csv', header = None)\n",
    "\n",
    "X_train = pd.read_csv('data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('data/processed/y_train.csv')\n",
    "y_train = y_train['187']\n",
    "\n",
    "X_train_sm = pd.read_csv('data/processed/X_train_sm.csv')\n",
    "y_train_sm = pd.read_csv('data/processed/y_train_sm.csv')\n",
    "y_train_sm = y_train_sm['187']\n",
    "\n",
    "X_val = pd.read_csv('data/processed/X_val.csv')\n",
    "y_val = pd.read_csv('data/processed/y_val.csv')\n",
    "y_val = y_val['187']\n",
    "\n",
    "X_test = df_mitbih_test.drop(187, axis = 1)\n",
    "y_test = df_mitbih_test[187]\n",
    "\n",
    "\n",
    "# Reshape the data for 1D CNN\n",
    "X_train_sm_cnn = np.expand_dims(X_train_sm, axis=2)\n",
    "X_val_cnn = np.expand_dims(X_val, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2) \n",
    "\n",
    "display(X_train_sm_cnn.shape)\n",
    "display(X_val_cnn.shape)\n",
    "display(X_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ddbb7-d23d-4689-9cb6-23a1a1a029e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot and save loss and accuracy over epochs from history\n",
    "def plot_training_history(history, save_dir, prefix): \n",
    "    hist = history.history\n",
    "    metrics = [m for m in hist.keys() if not m.startswith('val_')]  \n",
    "\n",
    "    # Create the output folder if it does not exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for m in metrics:\n",
    "        plt.figure()\n",
    "        plt.plot(hist[m], label=f'Train {m}')\n",
    "        if f'val_{m}' in hist:\n",
    "            plt.plot(hist[f'val_{m}'], label=f'Val {m}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(m)\n",
    "        plt.title(f'{m} over epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Construct filename with prefix and filepath with directory and filename\n",
    "        filename = f\"{prefix}_{m}.png\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(filepath, format='png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {filepath}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82af94-c4e6-4a68-9593-78d9ccd9f4c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Used LSTMs\n",
    "\n",
    "#LSTM1, 2 layers\n",
    "lstm1 = Sequential()\n",
    "\n",
    "# First LSTM layer\n",
    "lstm1.add(LSTM(units=32, return_sequences=True, input_shape=(187, 1)))\n",
    "\n",
    "# Second LSTM layer\n",
    "lstm1.add(LSTM(units=32, return_sequences=False))\n",
    "\n",
    "# Fully connected layer\n",
    "lstm1.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer with softmax activation for classification\n",
    "lstm1.add(Dense(5, activation='softmax')) \n",
    "\n",
    "\n",
    "\n",
    "#LSTM2, 6 layers\n",
    "lstm2 = Sequential()\n",
    "\n",
    "# First LSTM layer\n",
    "lstm2.add(LSTM(units=32, return_sequences=True, input_shape=(187, 1)))\n",
    "\n",
    "# Second LSTM layer\n",
    "lstm2.add(LSTM(units=32, return_sequences=True))\n",
    "\n",
    "# Third LSTM layer\n",
    "lstm2.add(LSTM(units=32, return_sequences=True))\n",
    "\n",
    "# Fourth LSTM layer\n",
    "lstm2.add(LSTM(units=32, return_sequences=True))\n",
    "\n",
    "# Fifth LSTM layer\n",
    "lstm2.add(LSTM(units=32, return_sequences=True))\n",
    "\n",
    "# Sixth LSTM layer\n",
    "lstm2.add(LSTM(units=32, return_sequences=False))\n",
    "\n",
    "# Fully connected layer\n",
    "lstm2.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer with softmax activation for classification\n",
    "lstm2.add(Dense(5, activation='softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81ae6f-e162-415b-a8c5-fba4f9ca55fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm1.summary()\n",
    "\n",
    "lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1e0e0-c397-4caa-b118-ee83a5394190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr reduction\n",
    "lrredpl = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  \n",
    "    factor=0.5,         \n",
    "    patience=10,         \n",
    "    min_lr=1e-7,        \n",
    "    verbose=1, \n",
    "    min_delta=0.001 \n",
    ")\n",
    "\n",
    "# Learning rate with exponential decay\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96)\n",
    "\n",
    "\n",
    "#Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       \n",
    "    patience=20,               \n",
    "    restore_best_weights=True, \n",
    "    min_delta=0.001  \n",
    ")\n",
    "\n",
    "\n",
    "#Compile when lr exp decay\n",
    "lstm1.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Define where and how to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../LSTM_output/lstm1_2layers_sm_lr_bs_epoch_{epoch:02d}_valloss_{val_loss:.4f}.keras',   # file path (can be .keras or .h5)\n",
    "    monitor='val_loss',       \n",
    "    mode='min',                    \n",
    "    save_best_only=False,           \n",
    "    verbose=1                      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8448ad-0b84-4d59-a780-fb41b1fa5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "history = lstm1.fit(\n",
    "    X_train_sm_cnn,\n",
    "    y_train_sm,\n",
    "    epochs=200,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[checkpoint, early_stop] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff430194-3757-4353-a6ba-591dfaea579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, save_dir=\"drive/MyDrive/COLAB/final/lstm2_sm\", prefix=\"lstm2_sm_lrexpdec_earlystop_bs512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d1163-cbb1-4bd3-ba7a-fd869016d332",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save training history\n",
    "with open(\"../LSTM_output/lstm1_2layers_sm_lr_bs_epoch__valloss_.pkl\", \"wb\") as f: #change for model\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "    \n",
    "best_model = load_model('../LSTM_output/lstm1_2layers_sm_lr_bs_epoch__valloss_.keras') #change for model\n",
    "\n",
    "\n",
    "#prediction of test data\n",
    "test_pred = best_model.predict(X_test_cnn)\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis=1)\n",
    "\n",
    "\n",
    "#classification report\n",
    "print(classification_report(y_test_class, y_pred_class, digits=4))\n",
    "\n",
    "\n",
    "#confusion matrix\n",
    "print(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions']))\n",
    "\n",
    "\n",
    "#save results of metrics\n",
    "with open(\"../LSTM_output/lstm1_2layers_sm_lr_bs_epoch__valloss_.txt\", \"w\") as file: #change for model\n",
    "    \n",
    "    file.write(\"\\nModel: LSTM1\\n\")#change for model\n",
    "        \n",
    "    file.write(\"\\nData augmentation: Smote\\n\")\n",
    "    \n",
    "    file.write(\"\\nConfusion Matrix on test set:\\n\")\n",
    "    file.write(str(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions'])))\n",
    "    \n",
    "    file.write(\"\\n\\nClassification Report on test set:\\n\")\n",
    "    file.write(classification_report(y_test_class, y_pred_class, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascientest_project",
   "language": "python",
   "name": "datascientest_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
