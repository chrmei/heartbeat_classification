{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59b3604",
   "metadata": {},
   "source": [
    "# Model Interpretability: SHAP Analysis for MIT-BIH Deep Learning Models\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) analysis to understand which temporal features contribute to the CNN8 model's classification decisions.\n",
    "\n",
    "**Analysis scope:**\n",
    "- 200 test samples (40 per class) for explanation\n",
    "- 100 background samples for reference distribution\n",
    "- DeepExplainer for neural network interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76779e39-81d4-4b33-898f-c5b8c49d406d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bed73-2e89-4caf-925e-eb41dc5a074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MIT data\n",
    "df_mitbih_test = pd.read_csv('data/original/mitbih_test.csv', header = None)\n",
    "\n",
    "X_train = pd.read_csv('data/processed/mitbih/X_train.csv')\n",
    "y_train = pd.read_csv('data/processed/mitbih/y_train.csv')\n",
    "y_train = y_train['187']\n",
    "\n",
    "X_train_sm = pd.read_csv('data/processed/mitbih/X_train_sm.csv')\n",
    "y_train_sm = pd.read_csv('data/processed/mitbih/y_train_sm.csv')\n",
    "y_train_sm = y_train_sm['187']\n",
    "\n",
    "X_val = pd.read_csv('data/processed/mitbih/X_val.csv')\n",
    "y_val = pd.read_csv('data/processed/mitbih/y_val.csv')\n",
    "y_val = y_val['187']\n",
    "\n",
    "X_test = df_mitbih_test.drop(187, axis = 1)\n",
    "y_test = df_mitbih_test[187]\n",
    "\n",
    "#reshape the data for 1D CNN\n",
    "X_train_sm_cnn = np.expand_dims(X_train_sm, axis=2)\n",
    "X_val_cnn = np.expand_dims(X_val, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327cb218-957f-4797-b66f-193c891477a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#configuration\n",
    "SAMPLES_PER_CLASS = 40  # 40 samples × 5 classes = 200 total samples\n",
    "N_BACKGROUND = 100      # Background samples for SHAP explainer\n",
    "RANDOM_SEED = 42        # reproducibility\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "#load best CNN\n",
    "model = load_model('models/MIT_02_03_dl_models/CNN/cnn8_sm_BS512_best.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc61ae-304a-4d32-872d-30c619a17fd6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# verify data shape \n",
    "print(f\"\\nTraining set (SMOTE):\")\n",
    "print(f\"  X_train_sm_cnn shape: {X_train_sm_cnn.shape}\")\n",
    "print(f\"  y_train_sm shape: {y_train_sm.shape}\")\n",
    "print(f\"  Unique classes: {np.unique(y_train_sm)}\")\n",
    "print(f\"  Class distribution: {np.bincount(y_train_sm)}\")\n",
    "\n",
    "print(f\"\\nValidation set:\")\n",
    "print(f\"  X_val_cnn shape: {X_val_cnn.shape}\")\n",
    "print(f\"  y_val shape: {y_val.shape}\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  X_test_cnn shape: {X_test_cnn.shape}\")\n",
    "print(f\"  y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nModel input shape: {model.input_shape}\")\n",
    "print(f\"Model output shape: {model.output_shape}\")\n",
    "\n",
    "# Expected output:\n",
    "# X_train_sm shape: (289885, 187, 1)\n",
    "# y_train_sm shape: (289885,)\n",
    "# Unique classes: [0 1 2 3 4]\n",
    "# Class distribution: [57977 57977 57977 57977 57977]\n",
    "\n",
    "# X_val_cnn shape: (17511, 187, 1)\n",
    "# y_val shape: (17511,)\n",
    "\n",
    "# X_test_cnn shape: (21892, 187, 1)\n",
    "# y_test shape: (21892,)\n",
    "\n",
    "# Model input shape: (None, 187, 1)\n",
    "# Model output shape: (None, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1152a9-3c40-4d66-9f11-e1e7dc6fc027",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model performance check -> should be same results as results in Rendering2 for best model\n",
    "y_pred = model.predict(X_test_cnn)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9ec68-f0a1-4abe-b928-961bd2c6ea86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preparation for SHAP: StratifiedSampling\n",
    "\n",
    "# Select background data (random sample from training)\n",
    "background_indices = np.random.choice(len(X_train_sm_cnn), N_BACKGROUND, replace=False)\n",
    "background_data = X_train_sm_cnn[background_indices]\n",
    "\n",
    "print(f\"\\nBackground data shape: {background_data.shape}\")\n",
    "print(f\"Background data range: [{background_data.min():.3f}, {background_data.max():.3f}]\")\n",
    "\n",
    "# Select test samples -> ensure balanced class distribution\n",
    "test_indices = []\n",
    "for class_idx in range(5):\n",
    "    class_samples = np.where(y_test == class_idx)[0]\n",
    "    n_samples = min(SAMPLES_PER_CLASS, len(class_samples))\n",
    "    selected = np.random.choice(class_samples, n_samples, replace=False)\n",
    "    test_indices.extend(selected)\n",
    "\n",
    "test_indices = np.array(test_indices)\n",
    "X_explain = X_test_cnn[test_indices]\n",
    "y_explain = y_test[test_indices]\n",
    "\n",
    "print(f\"\\nTest samples to explain: {len(test_indices)}\")\n",
    "print(f\"X_explain shape: {X_explain.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y_explain.astype(int))}\")\n",
    "\n",
    "\n",
    "# expected output\n",
    "#Background data shape: (100, 187, 1)\n",
    "#Background data range: [0.000, 1.000]\n",
    "\n",
    "#Test samples to explain: 200\n",
    "#X_explain shape: (200, 187, 1)\n",
    "#Class distribution: [40 40 40 40 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7159e4e-e8fa-4f0d-9b5c-0e2dd86c6c6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SHAP Explainer -> DeepExplainer for DL model\n",
    "\n",
    "explainer = shap.DeepExplainer(model, background_data)\n",
    "\n",
    "print(f\"\\nExpected value (baseline) for each class:\")\n",
    "for i, ev in enumerate(explainer.expected_value):\n",
    "    print(f\"  Class {i}: {ev:.4f}\")\n",
    "\n",
    "baseline_sum = sum(explainer.expected_value)\n",
    "print(f\"\\nBaseline sum: {baseline_sum:.4f}\")\n",
    "\n",
    "#expected output: baseline sum should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb4997-9a25-4cf4-aeda-aa9b41f4a029",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculcation of SHAP values\n",
    "\n",
    "shap_values_raw = explainer.shap_values(X_explain)\n",
    "\n",
    "# Reshape SHAP values to correct format\n",
    "print(f\"\\nRaw SHAP values shape: {shap_values_raw.shape}\")\n",
    "\n",
    "if isinstance(shap_values_raw, np.ndarray) and len(shap_values_raw.shape) == 4:\n",
    "    shap_values = []\n",
    "    for class_idx in range(5):\n",
    "        shap_values.append(shap_values_raw[:, :, :, class_idx])\n",
    "else:\n",
    "    shap_values = shap_values_raw\n",
    "\n",
    "print(f\"\\nFinal SHAP structure:\")\n",
    "print(f\"  Type: {type(shap_values)}\")\n",
    "print(f\"  Length (classes): {len(shap_values)}\")\n",
    "print(f\"  Shape per class: {shap_values[0].shape}\")\n",
    "\n",
    "# Statistics\n",
    "for i in range(5):\n",
    "    print(f\"\\nClass {i} SHAP statistics:\")\n",
    "    print(f\"  Min: {shap_values[i].min():.4f}\")\n",
    "    print(f\"  Max: {shap_values[i].max():.4f}\")\n",
    "    print(f\"  Mean: {shap_values[i].mean():.4f}\")\n",
    "    print(f\"  Std: {shap_values[i].std():.4f}\")\n",
    "\n",
    "\n",
    "#expected output\n",
    "#Raw SHAP values shape: (200, 187, 1, 5)\n",
    "#Final SHAP structure:\n",
    "#Type: <class 'list'>\n",
    "#Length (classes): 5\n",
    "#Shape per class: (200, 187, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a537c7c-ccd5-4079-bc3b-88d0036d80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparations for plotting\n",
    "\n",
    "X_explain_2d = X_explain.reshape(len(X_explain), 187)\n",
    "shap_values_2d = [sv.reshape(len(X_explain), 187) for sv in shap_values]\n",
    "\n",
    "print(f\"X_explain_2d shape: {X_explain_2d.shape}\")\n",
    "print(f\"shap_values_2d[0] shape: {shap_values_2d[0].shape}\")\n",
    "\n",
    "\n",
    "# expected output\n",
    "#X_explain_2d shape: (200, 187)\n",
    "#shap_values_2d[0] shape: (200, 187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b7542-e848-4f64-a9a2-a73c7df5fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Top 20 most important features for every class\n",
    "\n",
    "# Calculate importance for each class\n",
    "class_importance = []\n",
    "for class_idx in range(5):\n",
    "    mean_abs_shap = np.mean(np.abs(shap_values_2d[class_idx]), axis=0)\n",
    "    class_importance.append(mean_abs_shap)\n",
    "\n",
    "# Create separate plot for each class\n",
    "for class_idx in range(5):\n",
    "    \n",
    "    # Create individual figure for class\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    \n",
    "    # Get top 20 features for this class\n",
    "    top_20 = np.argsort(class_importance[class_idx])[-20:][::-1]\n",
    "    \n",
    "    # Plot bars\n",
    "    y_pos = np.arange(len(top_20))\n",
    "    ax.barh(y_pos, class_importance[class_idx][top_20], \n",
    "            color=f'C{class_idx}', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([f'Feature {f}' for f in top_20], fontsize=10)\n",
    "    ax.set_xlabel('Mean |SHAP Value|', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Class {class_idx} - Top 20 Most Important Features', \n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for i, (feat, val) in enumerate(zip(top_20, class_importance[class_idx][top_20])):\n",
    "        ax.text(val, i, f' {val:.4f}', va='center', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'reports/interpretability/SHAP_MIT/feature_importance_class_{class_idx}.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top 10 for this class\n",
    "    print(f\"\\nClass {class_idx} - Top 10 features:\")\n",
    "    for rank, feat in enumerate(top_20[:10], 1):\n",
    "        print(f\"  {rank}. Feature {feat}: {class_importance[class_idx][feat]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12915cf7-e955-4b32-9b91-d13ebeebeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature effects class 0\n",
    "\n",
    "# Choose a class to analyze\n",
    "class_to_analyze = 0\n",
    "print(f\"\\nAnalyzing Class {class_to_analyze}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_2d[class_to_analyze], X_explain_2d, show=False)\n",
    "plt.title(f'SHAP Summary Plot - Class {class_to_analyze}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'reports/interpretability/SHAP_MIT/shap_summary_class_{class_to_analyze}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# feature effects class 1\n",
    "\n",
    "# Choose a class to analyze\n",
    "class_to_analyze = 1\n",
    "print(f\"\\nAnalyzing Class {class_to_analyze}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_2d[class_to_analyze], X_explain_2d, show=False)\n",
    "plt.title(f'SHAP Summary Plot - Class {class_to_analyze}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'reports/interpretability/SHAP_MIT/shap_summary_class_{class_to_analyze}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# feature effects class 2\n",
    "\n",
    "# Choose a class to analyze\n",
    "class_to_analyze = 2\n",
    "print(f\"\\nAnalyzing Class {class_to_analyze}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_2d[class_to_analyze], X_explain_2d, show=False)\n",
    "plt.title(f'SHAP Summary Plot - Class {class_to_analyze}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'reports/interpretability/SHAP_MIT/shap_summary_class_{class_to_analyze}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# feature effects class 3\n",
    "\n",
    "# Choose a class to analyze\n",
    "class_to_analyze = 3\n",
    "print(f\"\\nAnalyzing Class {class_to_analyze}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_2d[class_to_analyze], X_explain_2d, show=False)\n",
    "plt.title(f'SHAP Summary Plot - Class {class_to_analyze}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'reports/interpretability/SHAP_MIT/shap_summary_class_{class_to_analyze}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# feature effects class 4\n",
    "\n",
    "# Choose a class to analyze\n",
    "class_to_analyze = 4\n",
    "print(f\"\\nAnalyzing Class {class_to_analyze}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_2d[class_to_analyze], X_explain_2d, show=False)\n",
    "plt.title(f'SHAP Summary Plot - Class {class_to_analyze}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'reports/interpretability/SHAP_MIT/shap_summary_class_{class_to_analyze}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77292e69-1b74-4bd1-ac80-df6f79bab951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample ECG over SHAP values for 3 examples per class\n",
    "\n",
    "# Find correctly classified samples\n",
    "predicted_classes = np.argmax(model.predict(X_explain, verbose=0), axis=1)\n",
    "\n",
    "for target_class in range(5):\n",
    "    # Find samples of this class that were correctly predicted\n",
    "    correct_idx = np.where((y_explain == target_class) & \n",
    "                          (predicted_classes == target_class))[0]\n",
    "    \n",
    "    if len(correct_idx) > 0:\n",
    "        # Take up to 3 samples\n",
    "        n_samples = min(3, len(correct_idx))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            sample_idx = correct_idx[i]\n",
    "            \n",
    "            print(f\"Analyzing Sample {sample_idx} (True Class: {target_class}, Example {i+1}/3)\")\n",
    "            \n",
    "            # Get prediction\n",
    "            pred = model.predict(X_explain[sample_idx:sample_idx+1], verbose=0)[0]\n",
    "            print(f\"Predicted class: {np.argmax(pred)}\")\n",
    "            print(f\"Confidence: {pred[target_class]:.4f}\")\n",
    "            \n",
    "            # Plot ECG signal with SHAP values\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8), sharex=True)\n",
    "            \n",
    "            # ECG signal\n",
    "            ecg_signal = X_explain_2d[sample_idx]\n",
    "            ax1.plot(ecg_signal, 'b-', linewidth=1)\n",
    "            ax1.set_ylabel('Normalized ECG Signal', fontsize=12)\n",
    "            ax1.set_title(f'Sample {sample_idx} - True Class: {target_class}, Predicted: {np.argmax(pred)}', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # SHAP values for the predicted class\n",
    "            shap_vals = shap_values_2d[target_class][sample_idx]\n",
    "            colors = ['red' if x > 0 else 'blue' for x in shap_vals]\n",
    "            ax2.bar(range(len(shap_vals)), shap_vals, color=colors, alpha=0.6, width=1.0)\n",
    "            ax2.set_xlabel('Time Step (Feature Index)', fontsize=12)\n",
    "            ax2.set_ylabel('SHAP Value', fontsize=12)\n",
    "            ax2.set_title(f'Feature Importance - Class {target_class}', fontsize=12)\n",
    "            ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'reports/interpretability/SHAP_MIT/ecg_shap_sample_{sample_idx}_class_{target_class}_example_{i+1}.png', \n",
    "                       dpi=150, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # Show top important features\n",
    "            top_n = 10\n",
    "            top_features = np.argsort(np.abs(shap_vals))[-top_n:][::-1]\n",
    "            print(f\"\\nTop {top_n} most important time steps:\")\n",
    "            for rank, feat_idx in enumerate(top_features, 1):\n",
    "                print(f\"  {rank}. Feature {feat_idx}: SHAP={shap_vals[feat_idx]:.4f}, \"\n",
    "                      f\"Value={ecg_signal[feat_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912851d-ec2a-4a03-a4b1-47176e57ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4efb97-5c24-4285-acac-c5691fb7f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#misclassification analysis\n",
    "\n",
    "#identify misclassified samples\n",
    "\n",
    "# Get predictions on full test set\n",
    "y_pred_probs = model.predict(X_test_cnn, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Find misclassified samples\n",
    "misclassified_idx = np.where(y_test != y_pred)[0]\n",
    "correct_idx = np.where(y_test == y_pred)[0]\n",
    "\n",
    "print(f\"\\nTotal test samples: {len(y_test)}\")\n",
    "print(f\"Correctly classified: {len(correct_idx)} ({100*len(correct_idx)/len(y_test):.2f}%)\")\n",
    "print(f\"Misclassified: {len(misclassified_idx)} ({100*len(misclassified_idx)/len(y_test):.2f}%)\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Find most common misclassification patterns\n",
    "print(\"\\nMost Common Misclassification Patterns:\")\n",
    "misclassification_patterns = []\n",
    "for true_class in range(5):\n",
    "    for pred_class in range(5):\n",
    "        if true_class != pred_class:\n",
    "            count = cm[true_class, pred_class]\n",
    "            if count > 0:\n",
    "                misclassification_patterns.append({\n",
    "                    'true': true_class,\n",
    "                    'pred': pred_class,\n",
    "                    'count': count\n",
    "                })\n",
    "\n",
    "# Sort by frequency\n",
    "misclassification_patterns = sorted(misclassification_patterns, \n",
    "                                   key=lambda x: x['count'], \n",
    "                                   reverse=True)\n",
    "\n",
    "print(\"\\nTop 10 confusion patterns:\")\n",
    "for i, pattern in enumerate(misclassification_patterns[:10], 1):\n",
    "    print(f\"  {i}. True Class {pattern['true']} → Predicted Class {pattern['pred']}: \"\n",
    "          f\"{pattern['count']} cases\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d772a-ebb0-4268-b8ef-cf903e2a9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Misclassified Cases for SHAP\n",
    "\n",
    "# Select representative misclassified samples\n",
    "samples_to_analyze = []\n",
    "samples_info = []\n",
    "\n",
    "for pattern in misclassification_patterns[:5]:  # Top 5 patterns\n",
    "    true_class = pattern['true']\n",
    "    pred_class = pattern['pred']\n",
    "    \n",
    "    # Find samples matching this pattern\n",
    "    pattern_samples = misclassified_idx[\n",
    "        (y_test[misclassified_idx] == true_class) & \n",
    "        (y_pred[misclassified_idx] == pred_class)\n",
    "    ]\n",
    "    \n",
    "    # Select up to 3 samples from this pattern\n",
    "    n_samples = min(3, len(pattern_samples))\n",
    "    selected = np.random.choice(pattern_samples, n_samples, replace=False)\n",
    "    \n",
    "    samples_to_analyze.extend(selected)\n",
    "    samples_info.extend([{\n",
    "        'idx': idx,\n",
    "        'true': true_class,\n",
    "        'pred': pred_class,\n",
    "        'prob': y_pred_probs[idx]\n",
    "    } for idx in selected])\n",
    "\n",
    "print(f\"\\nSelected {len(samples_to_analyze)} misclassified samples\")\n",
    "print(f\"Patterns covered: {len(set([(s['true'], s['pred']) for s in samples_info]))}\")\n",
    "\n",
    "# Also select correctly classified samples for comparison\n",
    "correct_samples_per_class = []\n",
    "for class_idx in range(5):\n",
    "    class_correct = correct_idx[y_test[correct_idx] == class_idx]\n",
    "    if len(class_correct) > 0:\n",
    "        selected = np.random.choice(class_correct, min(3, len(class_correct)), replace=False)\n",
    "        correct_samples_per_class.extend(selected)\n",
    "\n",
    "print(f\"Selected {len(correct_samples_per_class)} correctly classified samples for comparison\")\n",
    "\n",
    "# Combine for SHAP analysis\n",
    "all_samples = np.array(samples_to_analyze + correct_samples_per_class)\n",
    "X_analyze = X_test_cnn[all_samples]\n",
    "y_analyze = y_test[all_samples]\n",
    "\n",
    "print(f\"\\nTotal samples for SHAP analysis: {len(all_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041d697-03c2-4e58-ad31-19ec672418e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP for Misclassified Cases\n",
    "\n",
    "shap_values_misc_raw = explainer.shap_values(X_analyze)\n",
    "\n",
    "# Reshape SHAP values\n",
    "print(f\"\\nRaw SHAP shape: {shap_values_misc_raw.shape}\")\n",
    "\n",
    "if isinstance(shap_values_misc_raw, np.ndarray) and len(shap_values_misc_raw.shape) == 4:\n",
    "    shap_values_misc = []\n",
    "    for class_idx in range(5):\n",
    "        shap_values_misc.append(shap_values_misc_raw[:, :, :, class_idx])\n",
    "else:\n",
    "    shap_values_misc = shap_values_misc_raw\n",
    "\n",
    "# Reshape to 2D for analysis\n",
    "X_analyze_2d = X_analyze.reshape(len(all_samples), 187)\n",
    "shap_values_misc_2d = [sv.reshape(len(all_samples), 187) for sv in shap_values_misc]\n",
    "\n",
    "print(f\"Final SHAP structure: {len(shap_values_misc_2d)} classes\")\n",
    "print(f\"Shape per class: {shap_values_misc_2d[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391dbcb-e748-4f13-9605-e8a17816579a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize Misclassified Cases\n",
    "\n",
    "# Analyze each misclassified sample\n",
    "for i, info in enumerate(samples_info[:10]):  # Top 10\n",
    "    sample_idx = info['idx']\n",
    "    true_class = info['true']\n",
    "    pred_class = info['pred']\n",
    "    probs = info['prob']\n",
    "    \n",
    "    # Find this sample in analyzed set\n",
    "    analyze_idx = np.where(all_samples == sample_idx)[0][0]\n",
    "    \n",
    "    print(f\"Misclassified Sample {i+1}: Index {sample_idx}\")\n",
    "    print(f\"  True Class: {true_class}\")\n",
    "    print(f\"  Predicted Class: {pred_class}\")\n",
    "    print(f\"  Prediction confidence: {probs[pred_class]:.4f}\")\n",
    "    print(f\"  True class probability: {probs[true_class]:.4f}\")\n",
    "    \n",
    "    # Create plot\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. ECG Signal\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ecg = X_analyze_2d[analyze_idx]\n",
    "    ax1.plot(ecg, 'b-', linewidth=1.2)\n",
    "    ax1.set_ylabel('ECG Signal', fontsize=11)\n",
    "    ax1.set_title(f'Sample {sample_idx}: True={true_class}, Predicted={pred_class} '\n",
    "                  f'(Confidence={probs[pred_class]:.3f})', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(0, 186)\n",
    "    \n",
    "    # 2. SHAP for PREDICTED class\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    shap_pred = shap_values_misc_2d[pred_class][analyze_idx]\n",
    "    colors_pred = ['red' if x > 0 else 'blue' for x in shap_pred]\n",
    "    ax2.bar(range(187), shap_pred, color=colors_pred, alpha=0.6, width=1.0)\n",
    "    ax2.set_ylabel('SHAP Value', fontsize=11)\n",
    "    ax2.set_title(f'Why Model Predicted Class {pred_class}', fontsize=12, fontweight='bold')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(0, 186)\n",
    "    \n",
    "    # 3. SHAP for TRUE class\n",
    "    ax3 = fig.add_subplot(gs[2, :])\n",
    "    shap_true = shap_values_misc_2d[true_class][analyze_idx]\n",
    "    colors_true = ['red' if x > 0 else 'blue' for x in shap_true]\n",
    "    ax3.bar(range(187), shap_true, color=colors_true, alpha=0.6, width=1.0)\n",
    "    ax3.set_ylabel('SHAP Value', fontsize=11)\n",
    "    ax3.set_title(f'Evidence for True Class {true_class} (Missed)', fontsize=12, fontweight='bold')\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_xlim(0, 186)\n",
    "    ax3.set_xlabel('Time Step (Feature Index)', fontsize=11)\n",
    "    \n",
    "    # 4. Prediction probabilities\n",
    "    ax4 = fig.add_subplot(gs[3, 0])\n",
    "    colors_bar = ['green' if idx == true_class else ('red' if idx == pred_class else 'gray') \n",
    "                  for idx in range(5)]\n",
    "    ax4.bar(range(5), probs, color=colors_bar, alpha=0.7)\n",
    "    ax4.set_xlabel('Class', fontsize=11)\n",
    "    ax4.set_ylabel('Probability', fontsize=11)\n",
    "    ax4.set_title('Prediction Probabilities', fontsize=11, fontweight='bold')\n",
    "    ax4.set_xticks(range(5))\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 5. Key features comparison\n",
    "    ax5 = fig.add_subplot(gs[3, 1])\n",
    "    top_n = 10\n",
    "    top_pred = np.argsort(np.abs(shap_pred))[-top_n:][::-1]\n",
    "    top_true = np.argsort(np.abs(shap_true))[-top_n:][::-1]\n",
    "    \n",
    "    comparison_text = \"Top Features:\\n\\n\"\n",
    "    comparison_text += f\"Pred Class {pred_class}:\\n\"\n",
    "    for rank, feat in enumerate(top_pred[:5], 1):\n",
    "        comparison_text += f\"  {rank}. F{feat}: {shap_pred[feat]:+.3f}\\n\"\n",
    "    comparison_text += f\"\\nTrue Class {true_class}:\\n\"\n",
    "    for rank, feat in enumerate(top_true[:5], 1):\n",
    "        comparison_text += f\"  {rank}. F{feat}: {shap_true[feat]:+.3f}\\n\"\n",
    "    \n",
    "    ax5.text(0.1, 0.5, comparison_text, fontsize=9, family='monospace',\n",
    "             verticalalignment='center', transform=ax5.transAxes)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    plt.savefig(f'reports/interpretability/SHAP_MIT/misclassified_sample_{i+1}_idx_{sample_idx}.png', \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top features\n",
    "    print(\"\\nTop 3 features:\")\n",
    "    print(f\"  Predicted Class {pred_class}:\")\n",
    "    for feat in top_pred[:3]:\n",
    "        print(f\"    Feature {feat}: SHAP={shap_pred[feat]:+.4f}, Value={ecg[feat]:.4f}\")\n",
    "    print(f\"  True Class {true_class}:\")\n",
    "    for feat in top_true[:3]:\n",
    "        print(f\"    Feature {feat}: SHAP={shap_true[feat]:+.4f}, Value={ecg[feat]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab2777-d27b-4a3a-a1b7-a68f0f72810d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
