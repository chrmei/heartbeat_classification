{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A 02 I: MIT Hyperparameter tuning for baseline models using RandomizedSearch  without sampling\n",
        "\n",
        "Establish baseline models via randomized search without any feature engineering or resampling, mainly to verify preprocessing and compare it to the DL models. \n",
        "\n",
        "## Content\n",
        "\n",
        "A) MIT-BIH Arrhytmia Dataset\n",
        "\n",
        "1. train/test split: 80%, 20% -> as defined at the beginning of the project to ensure result reproducibility, no duplicates or missing values present\n",
        "2. Hyperparameter tuning using RandomizedSearch with cross validation for the mentioned baseline models but no oversampling techniques\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "from typing import Dict, Optional\n",
        "import random \n",
        "\n",
        "from src.utils import eval_model, evaluate_model\n",
        "from src.visualization import save_cv_diagnostics, save_overfit_diagnostic, save_model_diagnostics, save_roc_curve\n",
        "from src.utils.model_saver import create_model_saver\n",
        "\n",
        "# external \n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import loguniform, randint, uniform\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Samplers\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from src.utils.preprocessing import (\n",
        "    _normalize_sampling_method_name,\n",
        "    _SAMPLING_REGISTRY\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Init model saver\n",
        "model_saver = create_model_saver(\"src/models/MIT_02_01_baseline_models_randomized_search_no_sampling\")\n",
        "\n",
        "#import MIT data \n",
        "df_mitbih_train = pd.read_csv('data/original/mitbih_train.csv', header = None)\n",
        "df_mitbih_test = pd.read_csv('data/original/mitbih_test.csv', header = None)\n",
        "\n",
        "#define train and test set\n",
        "X_train = df_mitbih_train.drop(187, axis = 1)\n",
        "y_train = df_mitbih_train[187]\n",
        "\n",
        "X_test = df_mitbih_test.drop(187, axis = 1)\n",
        "y_test = df_mitbih_test[187]\n",
        "\n",
        "print(\"MITBIH dataset\")\n",
        "print(f\"\\tTraining size: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"\\tTest size: {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if False:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    # Subsample training set to 10 % (keeping all classes)\n",
        "    X_train_small, _, y_train_small, _ = train_test_split(\n",
        "        X_train, y_train,\n",
        "        train_size=0.05,\n",
        "        stratify=y_train,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Subsample test set to 10 % as well\n",
        "    X_test_small, _, y_test_small, _ = train_test_split(\n",
        "        X_test, y_test,\n",
        "        train_size=0.05,\n",
        "        stratify=y_test,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(\"Reduced MIT-BIH dataset\")\n",
        "    print(f\"\\tTraining size: {X_train_small.shape}, {y_train_small.shape}\")\n",
        "    print(f\"\\tTest size: {X_test_small.shape}, {y_test_small.shape}\")\n",
        "\n",
        "    # Assign back for your pipeline\n",
        "    X_train, y_train = X_train_small, y_train_small\n",
        "    X_test,  y_test  = X_test_small,  y_test_small"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Constants & Param Spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "SCORING = {'f1_macro': 'f1_macro', 'bal_acc': 'balanced_accuracy', 'f1_weighted': 'f1_weighted'}\n",
        "\n",
        "PARAM_SPACES = {\n",
        "    \"LogisticRegression\": {\n",
        "        \"estimator\": LogisticRegression(max_iter=10000, solver='lbfgs', n_jobs=-1),\n",
        "        \"params\": {\n",
        "            \"C\": loguniform(1e-3, 1e3),      # Big C = less penalty on large weights (more freedom, risk of overfitting). \n",
        "                                             # Small C = more penalty (more discipline, less overfitting).\n",
        "                                             # loguniform = means we try values spread across tiny to big scales (e.g., 0.001 up to 100), not just small steps.\n",
        "            \"penalty\": [\"l2\"], # gently pushes weights toward zero, which keeps the model simpler and more stable.\n",
        "            \"solver\": [\"lbfgs\"],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 10,\n",
        "        \"create_new_model\": False,\n",
        "    },\n",
        "    \"KNN\": {\n",
        "        \"estimator\": KNeighborsClassifier(n_jobs=-1),\n",
        "        \"params\": {\n",
        "            \"n_neighbors\": randint(1, 51),\n",
        "            \"weights\": [\"uniform\", \"distance\"],\n",
        "            \"metric\": [\"minkowski\", \"manhattan\", \"euclidean\"],\n",
        "            \"p\": [1, 2],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 10,\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"estimator\": RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200, 300],\n",
        "            \"max_depth\": [10, 15, 20],\n",
        "            \"min_samples_split\": [2, 5, 10, 20, 50],\n",
        "            \"min_samples_leaf\": [1, 2, 4, 8],\n",
        "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "            \"bootstrap\": [True],\n",
        "            \"class_weight\": [\"balanced\", None],\n",
        "            \"criterion\": [\"gini\", \"entropy\"],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 10,\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"estimator\": SVC(probability=True),\n",
        "        \"params\": {\n",
        "            \"kernel\": [\"rbf\", \"poly\"],\n",
        "            \"C\": [0.1, 1, 10],\n",
        "            \"gamma\": [0.001, 0.01, 0.1, 0.5, 0.9],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 10,\n",
        "    },\n",
        "    \"DecisionTree\": {\n",
        "        \"estimator\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "        \"params\": {\n",
        "            \"max_depth\": [None, 5, 10, 15, 20, 25, 30],\n",
        "            \"min_samples_split\": [2, 5, 10, 20, 50],\n",
        "            \"min_samples_leaf\": [1, 2, 4, 8, 16],\n",
        "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "            \"criterion\": [\"gini\", \"entropy\"],\n",
        "            \"class_weight\": [\"balanced\", None],\n",
        "            \"splitter\": [\"best\", \"random\"],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 100,\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"estimator\": xgb.XGBClassifier(\n",
        "            objective=\"multi:softprob\",\n",
        "            num_class=5,\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=-1,\n",
        "            eval_metric=\"mlogloss\",\n",
        "        ),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200, 300, 500],\n",
        "            \"max_depth\": [3, 4, 5, 6, 7, 8],\n",
        "            \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
        "            \"subsample\": [0.8, 0.9, 1.0],\n",
        "            \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
        "            \"reg_alpha\": [0, 0.1, 0.5, 1.0],\n",
        "            \"reg_lambda\": [0, 0.1, 0.5, 1.0],\n",
        "            \"min_child_weight\": [1, 3, 5, 7],\n",
        "            \"gamma\": [0, 0.1, 0.2, 0.3],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 40,\n",
        "    },\n",
        "    \"LDA\": {\n",
        "        \"estimator\": LinearDiscriminantAnalysis(),\n",
        "        \"params\": [\n",
        "            {\"solver\": [\"svd\"], \"store_covariance\": [False, True], \"tol\": [1e-4, 1e-3, 1e-2]},\n",
        "            {\"solver\": [\"lsqr\", \"eigen\"], \"shrinkage\": [None, \"auto\", 0.0, 0.05, 0.1, 0.15, 0.25, 0.35, 0.5, 0.65, 0.75, 0.85, 0.9], \"tol\": [1e-4, 1e-3, 1e-2]},\n",
        "        ],\n",
        "        \"cv\": StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 10,\n",
        "    },\n",
        "    \"ANN\": {\n",
        "        \"estimator\": MLPClassifier(\n",
        "            max_iter=300,\n",
        "            early_stopping=True,\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_iter_no_change=10,\n",
        "            solver=\"adam\",\n",
        "        ),\n",
        "        \"params\": {\n",
        "            \"hidden_layer_sizes\": [(64,), (128,), (128, 64)],\n",
        "            \"activation\": [\"relu\"],\n",
        "            \"alpha\": loguniform(1e-4, 1e-2),\n",
        "            \"learning_rate_init\": loguniform(1e-3, 1e-2),\n",
        "            \"batch_size\": randint(64, 129),\n",
        "            \"beta_1\": uniform(0.9, 0.09),\n",
        "            \"beta_2\": uniform(0.95, 0.049),\n",
        "            \"validation_fraction\": [0.1, 0.15],\n",
        "        },\n",
        "        \"cv\": StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE),\n",
        "        \"n_iter\": 100,\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_leak_free_pipeline(\n",
        "    estimator,\n",
        "    sampling_method: Optional[str] = \"none\",\n",
        "    sampler_kwargs: Optional[Dict] = None,\n",
        "    random_state: Optional[int] = 42,\n",
        ") -> Pipeline:\n",
        "    \"\"\"\n",
        "    Build a leak-free pipeline:\n",
        "    - Using imblearn.Pipeline ensures fit/transform of SAMPLER happen within each CV fold on TRAIN only.\n",
        "    \"\"\"\n",
        "    sampler_kwargs = dict(sampler_kwargs or {})\n",
        "\n",
        "    # Provide a default random_state to samplers if not overridden\n",
        "    if random_state is not None and \"random_state\" not in sampler_kwargs:\n",
        "        sampler_kwargs[\"random_state\"] = random_state\n",
        "\n",
        "    internal_name = _normalize_sampling_method_name(sampling_method)\n",
        "\n",
        "    steps = []\n",
        "\n",
        "    SamplerClass = _SAMPLING_REGISTRY[internal_name]\n",
        "    steps.append((\"sampler\", SamplerClass(**sampler_kwargs)))\n",
        "\n",
        "    steps.append((\"classifier\", estimator))\n",
        "    display(steps)\n",
        "    return Pipeline(steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_randomized_search(\n",
        "    model_name,\n",
        "    estimator,\n",
        "    params,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_test,\n",
        "    y_test,\n",
        "    cv,\n",
        "    results_path,\n",
        "    sampling_method=\"No_Sampling\",\n",
        "    sampler_kwargs=None,\n",
        "    remove_outliers=False,\n",
        "    model_saver=None,\n",
        "    scoring=None,\n",
        "    n_iter=20,\n",
        "    refit_metric=\"f1_macro\"\n",
        "):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Running RandomizedSearchCV for {model_name} ({sampling_method})\")\n",
        "    print(f\"Outlier removal: {remove_outliers}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Create experiment name\n",
        "    experiment_name = f\"{sampling_method.lower()}_outliers_{remove_outliers}\"\n",
        "\n",
        "    # --- SKIP if model already exists ---\n",
        "    if model_saver and model_saver.model_exists(model_name, experiment_name):\n",
        "        print(f\"  Skipping {model_name} ({experiment_name}) - model already saved.\")\n",
        "        try:\n",
        "            meta = model_saver.load_metadata(model_name, experiment_name)\n",
        "            if meta:\n",
        "                print(f\"    Existing model best_score={meta.get('best_score'):.4f}, \"\n",
        "                      f\"params={meta.get('best_params')}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  (Could not load metadata: {e})\")\n",
        "        return None\n",
        "    # ---------------------------------------------------------------\n",
        "\n",
        "\n",
        "    # Create leak-free pipeline - only applies for sampling methods\n",
        "    if sampling_method != \"No_Sampling\":\n",
        "        estimator = create_leak_free_pipeline(estimator, sampling_method)\n",
        "        # Adjust parameter names for pipeline\n",
        "        params = {f'classifier__{param_name}': param_values \n",
        "                        for param_name, param_values in params.items()}\n",
        "    \n",
        "\n",
        "    # Run the search\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=estimator,\n",
        "        param_distributions=params,\n",
        "        scoring=scoring,\n",
        "        refit=refit_metric,\n",
        "        n_iter=n_iter,\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "        return_train_score=True,\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    # Save model\n",
        "    experiment_name = f\"{sampling_method.lower()}_outliers_{remove_outliers}\"\n",
        "\n",
        "    # Evaluate best model\n",
        "    eval_results = evaluate_model(search.best_estimator_, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Summary table (1 row per model)\n",
        "    summary = {\n",
        "        \"model\": model_name,\n",
        "        \"sampling_method\": sampling_method,\n",
        "        \"remove_outliers\": remove_outliers,\n",
        "        \"best_cv_score\": round(search.best_score_, 4), # Best mean validation score from CV (based on refit_metric), higher better!\n",
        "        \"best_params\": json.dumps(search.best_params_), \n",
        "        \"train_f1_macro\": round(eval_results[\"train\"][\"f1_macro\"], 4), # Macro-F1 on training - how well model fits seen data across all classes\n",
        "        \"test_f1_macro\": round(eval_results[\"test\"][\"f1_macro\"], 4), # Macro-F1 on test data - balanced generalization to all classes?\n",
        "        \"test_accuracy\": round(eval_results[\"test\"][\"accuracy\"], 4), # overall proportion of correct predictions \n",
        "        \"train_test_diff\": round(eval_results[\"train\"][\"f1_macro\"] - eval_results[\"test\"][\"f1_macro\"], 4), # Gap between train and test: Over/Underfitting indicator: smaller better!\n",
        "        \"roc_auc\": round(eval_results[\"test\"][\"roc_auc\"], 4) if not np.isnan(eval_results[\"test\"][\"roc_auc\"]) else None, # ROC-AUC on test data: Class separation: closer to 1 better separation!\n",
        "    }\n",
        "\n",
        "    # Log cross-fold metrics for best model\n",
        "\n",
        "    cv_df = pd.DataFrame(search.cv_results_)\n",
        "    best_idx = search.best_index_\n",
        "    summary[\"cv_mean_train_f1_macro\"] = round(cv_df[\"mean_train_f1_macro\"][best_idx],4) # High: model fits training folds well, too hig vs validation: possible overfitting\n",
        "    summary[\"cv_std_train_f1_macro\"]  = round(cv_df[\"std_train_f1_macro\"][best_idx],4) # should be low: stable learning across folds\n",
        "    summary[\"cv_mean_val_f1_macro\"] = round(cv_df[\"mean_test_f1_macro\"][best_idx],4) # balanced per class performance\n",
        "    summary[\"cv_std_val_f1_macro\"] = round(cv_df[\"std_test_f1_macro\"][best_idx],4) # should be low\n",
        "    summary[\"cv_diff_train_val_f1_macro\"] = round(cv_df[\"mean_train_f1_macro\"][best_idx] - cv_df[\"mean_test_f1_macro\"][best_idx],4)\n",
        "    summary[\"cv_mean_val_bal_acc\"] = round(cv_df[\"mean_test_bal_acc\"][best_idx],4) # Higher better: class imbalance  by averaging recall per class\n",
        "    summary[\"cv_std_val_bal_acc\"] = round(cv_df[\"std_test_bal_acc\"][best_idx],4) # should be low\n",
        "    summary[\"mean_fit_time\"] = round(cv_df[\"mean_fit_time\"][best_idx],4) \n",
        "    summary[\"std_fit_time\"] = round(cv_df[\"std_fit_time\"][best_idx],4)\n",
        "\n",
        "    for lbl, f1_val in zip(eval_results[\"labels\"], eval_results[\"test\"][\"f1_per_class\"]):\n",
        "        summary[f\"test_f1_class_{lbl}\"] = round(float(f1_val), 4)\n",
        "\n",
        "    for lbl, f1_val in zip(eval_results[\"labels\"], eval_results[\"train\"][\"f1_per_class\"]):\n",
        "        summary[f\"train_f1_class_{lbl}\"] = round(float(f1_val), 4)\n",
        "\n",
        "    os.makedirs(os.path.dirname(results_path), exist_ok=True)\n",
        "    pd.DataFrame([summary]).to_csv(results_path, mode=\"a\", header=not os.path.exists(results_path), index=False)\n",
        "\n",
        "    # Save full CV results for analysis\n",
        "    cv_full_path = results_path.replace(\".csv\", '_'+model_name+'_'+experiment_name+\"_cv_results.csv\")\n",
        "    cv_df.to_csv(cv_full_path, index=False)\n",
        "\n",
        "    # Generate diagnostics / graphics\n",
        "    save_overfit_diagnostic(cv_df, model_name, sampling_method, results_path)\n",
        "    save_cv_diagnostics(cv_df, model_name, sampling_method, results_path)\n",
        "    save_model_diagnostics(eval_results, model_name, sampling_method, results_path)\n",
        "    save_roc_curve(search.best_estimator_, X_test, y_test, model_name, sampling_method, results_path)\n",
        "\n",
        "    print(f\"Saved unified results to {results_path}\")\n",
        "\n",
        "    if model_saver:\n",
        "        meta = {\n",
        "            \"best_params\": search.best_params_,\n",
        "            \"best_score\": search.best_score_,\n",
        "            \"cv_results\": search.cv_results_,\n",
        "            \"experiment\": experiment_name,\n",
        "            \"classifier\": model_name,\n",
        "        }\n",
        "        model_saver.save_model(model_name, search, experiment_name, meta)\n",
        "    \n",
        "    print(f\"Saved model {model_name} ({experiment_name})!\")\n",
        "\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test models with Randomized Search CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.1 Run the randomized search CV without Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_path = \"reports/03_baseline_models/MIT_02_01_RANDOMIZED_SEARCH/A_02_01.csv\"\n",
        "\n",
        "for model_name, param_dict in PARAM_SPACES.items():\n",
        "    run_randomized_search(model_name, \n",
        "                        estimator=param_dict[\"estimator\"],\n",
        "                        params=param_dict[\"params\"],\n",
        "                        X_train=X_train,\n",
        "                        y_train=y_train,\n",
        "                        X_test=X_test,\n",
        "                        y_test=y_test,\n",
        "                        cv=param_dict[\"cv\"],\n",
        "                        results_path=results_path,\n",
        "                        sampling_method=\"No_Sampling\",\n",
        "                        remove_outliers=False,\n",
        "                        model_saver=model_saver,\n",
        "                        scoring=SCORING,\n",
        "                        n_iter=param_dict[\"n_iter\"],\n",
        "                        refit_metric=\"f1_macro\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
