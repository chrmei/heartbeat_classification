{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Testing - PTBDB Dataset\n",
        "\n",
        "Questions to be answered:\n",
        "\n",
        "- Remove outliers?\n",
        "- Which Sampling method to use?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from src.utils.preprocessing import (\n",
        "    prepare_mitbih,\n",
        "    prepare_ptbdb,\n",
        "    resample_training\n",
        ")\n",
        "from src.visualization import plot_confusion_matrix\n",
        "from src.models.exploration_phase import create_model_saver\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import loguniform, randint\n",
        "\n",
        "# Initialize model saver\n",
        "model_saver = create_model_saver()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_model(model, X_tr, y_tr, X_va, y_va, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    yv = model.predict(X_va)\n",
        "    yt = model.predict(X_te)\n",
        "\n",
        "    # Choose a consistent label order (dynamic)\n",
        "    labels = np.unique(np.concatenate([y_tr, y_va, y_te]))\n",
        "\n",
        "    # Validation\n",
        "    acc_v = accuracy_score(y_va, yv)\n",
        "    p_v_m, r_v_m, f1_v_m, _ = precision_recall_fscore_support(\n",
        "        y_va, yv, average='macro', zero_division=0\n",
        "    )\n",
        "    p_v_c, r_v_c, f1_v_c, sup_v = precision_recall_fscore_support(\n",
        "        y_va, yv, average=None, labels=labels, zero_division=0\n",
        "    )\n",
        "    cm_v = confusion_matrix(y_va, yv, labels=labels)\n",
        "\n",
        "    # Test\n",
        "    acc_t = accuracy_score(y_te, yt)\n",
        "    p_t_m, r_t_m, f1_t_m, _ = precision_recall_fscore_support(\n",
        "        y_te, yt, average='macro', zero_division=0\n",
        "    )\n",
        "    p_t_c, r_t_c, f1_t_c, sup_t = precision_recall_fscore_support(\n",
        "        y_te, yt, average=None, labels=labels, zero_division=0\n",
        "    )\n",
        "    cm_t = confusion_matrix(y_te, yt, labels=labels)\n",
        "\n",
        "    return {\n",
        "        'labels': labels,  # order for per-class arrays below\n",
        "        'val': {\n",
        "            'accuracy': acc_v,\n",
        "            'precision_macro': p_v_m,\n",
        "            'recall_macro': r_v_m,\n",
        "            'f1_macro': f1_v_m,\n",
        "            'precision_per_class': p_v_c,\n",
        "            'recall_per_class': r_v_c,\n",
        "            'f1_per_class': f1_v_c,\n",
        "            'support_per_class': sup_v,\n",
        "            'confusion_matrix': cm_v,\n",
        "        },\n",
        "        'test': {\n",
        "            'accuracy': acc_t,\n",
        "            'precision_macro': p_t_m,\n",
        "            'recall_macro': r_t_m,\n",
        "            'f1_macro': f1_t_m,\n",
        "            'precision_per_class': p_t_c,\n",
        "            'recall_per_class': r_t_c,\n",
        "            'f1_per_class': f1_t_c,\n",
        "            'support_per_class': sup_t,\n",
        "            'confusion_matrix': cm_t,\n",
        "        },\n",
        "    }\n",
        "\n",
        "results = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare datasets\n",
        "ptbdb = prepare_ptbdb(remove_outliers=False)\n",
        "\n",
        "print(\"PTBDB dataset prepared:\")\n",
        "print(f\"  Training size: {ptbdb.X_train.shape}\")\n",
        "print(f\"  Validation size: {ptbdb.X_val.shape if ptbdb.X_val is not None else 'None'}\")\n",
        "print(f\"  Test size: {ptbdb.X_test.shape if ptbdb.X_test is not None else 'None'}\")\n",
        "\n",
        "X_train, X_val, X_test = ptbdb.X_train.values, ptbdb.X_val.values, ptbdb.X_test.values\n",
        "y_train = ptbdb.y_train.astype(int).values\n",
        "y_val = ptbdb.y_val.astype(int).values\n",
        "y_test = ptbdb.y_test.astype(int).values\n",
        "\n",
        "# Scale features using train fit only\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "X_test_s = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test models with Randomized Search CV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scoring = {'f1_macro': 'f1_macro', 'bal_acc': 'balanced_accuracy', 'f1_weighted': 'f1_weighted'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Without outlier removal or sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.1 Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"LogisticRegression\"\n",
        "experiment_name = \"no_sampling_ptbdb\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_logreg = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    logreg = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
        "\n",
        "    param_dist_logreg = {\n",
        "        'C': loguniform(1e-3, 1e3),\n",
        "        'penalty': ['l2'],\n",
        "        'solver': ['lbfgs'],\n",
        "    }\n",
        "\n",
        "    rs_logreg = RandomizedSearchCV(\n",
        "        estimator=logreg,\n",
        "        param_distributions=param_dist_logreg,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    rs_logreg.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_logreg.best_params_,\n",
        "        'best_score': rs_logreg.best_score_,\n",
        "        'cv_results': rs_logreg.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_logreg, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_logreg = rs_logreg.best_estimator_\n",
        "results['LogisticRegression'] = eval_model(\n",
        "    best_logreg,\n",
        "    X_train_s, y_train,\n",
        "    X_val_s, y_val,\n",
        "    X_test_s, y_test,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.2 KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"KNN\"\n",
        "experiment_name = \"no_sampling_ptbdb\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_knn = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    knn = KNeighborsClassifier()\n",
        "    param_dist_knn = {\n",
        "        'n_neighbors': randint(1, 51),\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'metric': ['minkowski', 'manhattan', 'euclidean'],\n",
        "        'p': [1, 2],\n",
        "    }\n",
        "\n",
        "    rs_knn = RandomizedSearchCV(\n",
        "        estimator=knn,\n",
        "        param_distributions=param_dist_knn,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    rs_knn.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_knn.best_params_,\n",
        "        'best_score': rs_knn.best_score_,\n",
        "        'cv_results': rs_knn.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_knn, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_knn = rs_knn.best_estimator_\n",
        "results['KNN'] = eval_model(\n",
        "    best_knn,\n",
        "    X_train_s, y_train,\n",
        "    X_val_s, y_val,\n",
        "    X_test_s, y_test,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.3 Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"RandomForest\"\n",
        "experiment_name = \"no_sampling_ptbdb\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_rf = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    param_dist_rf = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [10, 15, 20],\n",
        "        'min_samples_split': [2, 5, 10, 20, 50],\n",
        "        'min_samples_leaf': [1, 2, 4, 8],\n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'bootstrap': [True],\n",
        "        'class_weight': ['balanced', None],\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "    }\n",
        "\n",
        "    rs_rf = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_dist_rf,\n",
        "        n_iter=20,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_rf.fit(X_train, y_train)\n",
        "    \n",
        "    metadata = {\n",
        "        'best_params': rs_rf.best_params_,\n",
        "        'best_score': rs_rf.best_score_,\n",
        "        'cv_results': rs_rf.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_rf, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_rf = rs_rf.best_estimator_\n",
        "results['RandomForest'] = eval_model( \n",
        "    best_rf, \n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.4 SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"SVM\"\n",
        "experiment_name = \"no_sampling_ptbdb\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_svm = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    svm = SVC()\n",
        "    param_dist_svm = {\n",
        "        'kernel': ['rbf', 'poly'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'gamma': [0.001, 0.01, 0.1, 0.5, 1],\n",
        "    }\n",
        "    rs_svm = RandomizedSearchCV(\n",
        "        estimator=svm,\n",
        "        param_distributions=param_dist_svm,\n",
        "        n_iter=15,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "    rs_svm.fit(X_train_s, y_train)\n",
        "    \n",
        "    # Save the trained model\n",
        "    metadata = {\n",
        "        'best_params': rs_svm.best_params_,\n",
        "        'best_score': rs_svm.best_score_,\n",
        "        'cv_results': rs_svm.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_svm, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_svm = rs_svm.best_estimator_\n",
        "results['SVM'] = eval_model(\n",
        "    best_svm,\n",
        "    X_train_s, y_train,\n",
        "    X_val_s, y_val,\n",
        "    X_test_s, y_test,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.5 Decision Tree Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"DecisionTree\"\n",
        "experiment_name = \"no_sampling_ptbdb\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_dt = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    param_dist_dt = {\n",
        "        'max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
        "        'min_samples_split': [2, 5, 10, 20, 50],\n",
        "        'min_samples_leaf': [1, 2, 4, 8, 16],\n",
        "        'max_features': ['sqrt', 'log2', None],\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'class_weight': ['balanced', None],\n",
        "        'splitter': ['best', 'random'],\n",
        "    }\n",
        "\n",
        "    rs_dt = RandomizedSearchCV(\n",
        "        estimator=dt,\n",
        "        param_distributions=param_dist_dt,\n",
        "        n_iter=100,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_dt.fit(X_train, y_train)\n",
        "    \n",
        "    metadata = {\n",
        "        'best_params': rs_dt.best_params_,\n",
        "        'best_score': rs_dt.best_score_,\n",
        "        'cv_results': rs_dt.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_dt, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_dt = rs_dt.best_estimator_\n",
        "results['DecisionTree'] = eval_model(\n",
        "    best_dt,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.6 XGBoost / Gradient Boosting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Check if model already exists\n",
        "classifier_name = \"XGBoost\"\n",
        "experiment_name = \"no_sampling_ptbdb\"\n",
        "\n",
        "if model_saver.model_exists(classifier_name, experiment_name):\n",
        "    print(f\"Model {classifier_name} already exists for experiment {experiment_name}. Loading...\")\n",
        "    rs_xgb = model_saver.load_model(classifier_name, experiment_name)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Model {classifier_name} not found. Training new model...\")\n",
        "    \n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "\n",
        "    param_dist_xgb = {\n",
        "        'n_estimators': [100, 200, 300, 500],\n",
        "        'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
        "        'subsample': [0.8, 0.9, 1.0],\n",
        "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "        'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
        "        'reg_lambda': [0, 0.1, 0.5, 1.0],\n",
        "        'min_child_weight': [1, 3, 5, 7],\n",
        "        'gamma': [0, 0.1, 0.2, 0.3],\n",
        "    }\n",
        "\n",
        "    rs_xgb = RandomizedSearchCV(\n",
        "        estimator=xgb_model,\n",
        "        param_distributions=param_dist_xgb,\n",
        "        n_iter=30,\n",
        "        scoring=scoring,\n",
        "        refit='f1_macro',\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "    )\n",
        "\n",
        "    rs_xgb.fit(X_train, y_train)\n",
        "    \n",
        "    metadata = {\n",
        "        'best_params': rs_xgb.best_params_,\n",
        "        'best_score': rs_xgb.best_score_,\n",
        "        'cv_results': rs_xgb.cv_results_,\n",
        "        'experiment': experiment_name,\n",
        "        'classifier': classifier_name\n",
        "    }\n",
        "    model_saver.save_model(classifier_name, rs_xgb, experiment_name, metadata)\n",
        "    print(f\"Model {classifier_name} saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_xgb = rs_xgb.best_estimator_\n",
        "results['XGBoost'] = eval_model(\n",
        "    best_xgb,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.7 Results Summary and Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _safe_col(label):\n",
        "    # Make safe column names like \"val_f1_cls_0\" or \"val_f1_cls_N\"\n",
        "    return re.sub(r'[^0-9a-zA-Z_]+', '_', str(label)).strip('_')\n",
        "\n",
        "# Mapping of model names to their RandomizedSearchCV objects\n",
        "models_and_searchers = {\n",
        "    \"LogisticRegression\": rs_logreg,\n",
        "    \"KNN\": rs_knn,\n",
        "    \"RandomForest\": rs_rf,\n",
        "    \"SVM\": rs_svm,\n",
        "    \"DecisionTree\": rs_dt,\n",
        "    \"XGBoost\": rs_xgb\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, res in results.items():\n",
        "    row = {\n",
        "        'model': name,\n",
        "        'val_accuracy': res['val']['accuracy'],\n",
        "        'val_f1_macro': res['val']['f1_macro'],\n",
        "        'test_accuracy': res['test']['accuracy'],\n",
        "        'test_f1_macro': res['test']['f1_macro'],\n",
        "    }\n",
        "\n",
        "    # Add best parameters from RandomizedSearchCV\n",
        "    if name in models_and_searchers:\n",
        "        searcher = models_and_searchers[name]\n",
        "        best_params = searcher.best_params_\n",
        "        best_cv_score = searcher.best_score_\n",
        "        row['best_cv_score'] = best_cv_score\n",
        "        row['best_parameters'] = str(best_params)\n",
        "    else:\n",
        "        row['best_cv_score'] = None\n",
        "        row['best_parameters'] = None\n",
        "\n",
        "    labels = res['labels']\n",
        "    f1_v = res['val']['f1_per_class']\n",
        "    f1_t = res['test']['f1_per_class']\n",
        "\n",
        "    # Add per-class F1 columns\n",
        "    for lbl, f1 in zip(labels, f1_v):\n",
        "        row[f'val_f1_cls_{_safe_col(lbl)}'] = f1\n",
        "    for lbl, f1 in zip(labels, f1_t):\n",
        "        row[f'test_f1_cls_{_safe_col(lbl)}'] = f1\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "comparison_df = (\n",
        "    pd.DataFrame(rows)\n",
        "      .sort_values(by=['val_f1_macro','test_f1_macro'], ascending=False)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "best_model_name = comparison_df.iloc[0]['model']\n",
        "best_model_results = results[best_model_name]\n",
        "\n",
        "comparison_df_display = comparison_df.copy()\n",
        "comparison_df_display['best_parameters'] = comparison_df_display['best_parameters'].apply(\n",
        "    lambda x: json.dumps(x, indent=2) if isinstance(x, dict) else x\n",
        ")\n",
        "comparison_df_display.to_csv(\"src/data/03_model_testing_results/model_comparison_ptbdb_without_resampling.csv\", index=False)\n",
        "\n",
        "# Display the comparison table with best parameters\n",
        "print(\"=\" * 100)\n",
        "print(\"MODEL COMPARISON WITH BEST PARAMETERS FROM RANDOMIZEDSEARCHCV - PTBDB\")\n",
        "print(\"=\" * 100)\n",
        "display(comparison_df_display)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Testing - PTBDB Dataset\n",
        "\n",
        "- **Binary Classification**: 2 classes (Normal vs Abnormal)\n",
        "\n",
        "Questions to be answered:\n",
        "\n",
        "- Remove outliers?\n",
        "- Which Sampling method to use?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from src.utils.preprocessing import (\n",
        "    prepare_mitbih, \n",
        "    prepare_ptbdb,\n",
        "    resample_training\n",
        ")\n",
        "from src.visualization import plot_confusion_matrix\n",
        "from src.models.exploration_phase import create_model_saver\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import loguniform, randint, uniform\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize model saver\n",
        "model_saver = create_model_saver()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_model(model, X_tr, y_tr, X_va, y_va, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    yv = model.predict(X_va)\n",
        "    yt = model.predict(X_te)\n",
        "\n",
        "    # Choose a consistent label order (dynamic)\n",
        "    labels = np.unique(np.concatenate([y_tr, y_va, y_te]))\n",
        "\n",
        "    # Validation\n",
        "    acc_v = accuracy_score(y_va, yv)\n",
        "    p_v_m, r_v_m, f1_v_m, _ = precision_recall_fscore_support(\n",
        "        y_va, yv, average='macro', zero_division=0\n",
        "    )\n",
        "    p_v_c, r_v_c, f1_v_c, sup_v = precision_recall_fscore_support(\n",
        "        y_va, yv, average=None, labels=labels, zero_division=0\n",
        "    )\n",
        "    cm_v = confusion_matrix(y_va, yv, labels=labels)\n",
        "\n",
        "    # Test\n",
        "    acc_t = accuracy_score(y_te, yt)\n",
        "    p_t_m, r_t_m, f1_t_m, _ = precision_recall_fscore_support(\n",
        "        y_te, yt, average='macro', zero_division=0\n",
        "    )\n",
        "    p_t_c, r_t_c, f1_t_c, sup_t = precision_recall_fscore_support(\n",
        "        y_te, yt, average=None, labels=labels, zero_division=0\n",
        "    )\n",
        "    cm_t = confusion_matrix(y_te, yt, labels=labels)\n",
        "\n",
        "    return {\n",
        "        'labels': labels,  # order for per-class arrays below\n",
        "        'val': {\n",
        "            'accuracy': acc_v,\n",
        "            'precision_macro': p_v_m,\n",
        "            'recall_macro': r_v_m,\n",
        "            'f1_macro': f1_v_m,\n",
        "            'precision_per_class': p_v_c,\n",
        "            'recall_per_class': r_v_c,\n",
        "            'f1_per_class': f1_v_c,\n",
        "            'support_per_class': sup_v,\n",
        "            'confusion_matrix': cm_v,\n",
        "        },\n",
        "        'test': {\n",
        "            'accuracy': acc_t,\n",
        "            'precision_macro': p_t_m,\n",
        "            'recall_macro': r_t_m,\n",
        "            'f1_macro': f1_t_m,\n",
        "            'precision_per_class': p_t_c,\n",
        "            'recall_per_class': r_t_c,\n",
        "            'f1_per_class': f1_t_c,\n",
        "            'support_per_class': sup_t,\n",
        "            'confusion_matrix': cm_t,\n",
        "        },\n",
        "    }\n",
        "\n",
        "results = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MITBIH dataset prepared:\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'mitbih' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m ptbdb = prepare_ptbdb(remove_outliers=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMITBIH dataset prepared:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Training size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmitbih\u001b[49m.X_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Validation size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmitbih.X_val.shape\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmitbih.X_val\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Test size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmitbih.X_test.shape\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmitbih.X_test\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'mitbih' is not defined"
          ]
        }
      ],
      "source": [
        "# Prepare datasets\n",
        "ptbdb = prepare_ptbdb(remove_outliers=False)\n",
        "\n",
        "print(\"MITBIH dataset prepared:\")\n",
        "print(f\"  Training size: {mitbih.X_train.shape}\")\n",
        "print(f\"  Validation size: {mitbih.X_val.shape if mitbih.X_val is not None else 'None'}\")\n",
        "print(f\"  Test size: {mitbih.X_test.shape if mitbih.X_test is not None else 'None'}\")\n",
        "\n",
        "print(\"\\nPTBDB dataset prepared:\")\n",
        "print(f\"  Training size: {ptbdb.X_train.shape}\")\n",
        "print(f\"  Validation size: {ptbdb.X_val.shape if ptbdb.X_val is not None else 'None'}\")\n",
        "print(f\"  Test size: {ptbdb.X_test.shape if ptbdb.X_test is not None else 'None'}\")\n",
        "\n",
        "# Check class distribution in PTBDB\n",
        "print(\"\\nPTBDB Class Distribution:\")\n",
        "print(f\"  Training classes: {np.unique(ptbdb.y_train, return_counts=True)}\")\n",
        "print(f\"  Validation classes: {np.unique(ptbdb.y_val, return_counts=True)}\")\n",
        "print(f\"  Test classes: {np.unique(ptbdb.y_test, return_counts=True)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "scoring = {'f1_macro': 'f1_macro', 'bal_acc': 'balanced_accuracy', 'f1_weighted': 'f1_weighted'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.6 XGBoost / Gradient Boosting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
