{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d328f-d220-4722-a362-25e4bd96fb17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run on Google Colab to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c93d0b-2da6-494a-be5c-c0b962c399b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Conv1D, MaxPooling1D, Flatten, Add, ReLU, LSTM, Reshape, Concatenate, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3585c9f-5063-4232-9b19-8de0daafe70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MIT data\n",
    "df_mitbih_test = pd.read_csv('data/original/mitbih_test.csv', header = None)\n",
    "\n",
    "X_train = pd.read_csv('data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('data/processed/y_train.csv')\n",
    "y_train = y_train['187']\n",
    "\n",
    "X_train_sm = pd.read_csv('data/processed/X_train_sm.csv')\n",
    "y_train_sm = pd.read_csv('data/processed/y_train_sm.csv')\n",
    "y_train_sm = y_train_sm['187']\n",
    "\n",
    "X_val = pd.read_csv('data/processed/X_val.csv')\n",
    "y_val = pd.read_csv('data/processed/y_val.csv')\n",
    "y_val = y_val['187']\n",
    "\n",
    "X_test = df_mitbih_test.drop(187, axis = 1)\n",
    "y_test = df_mitbih_test[187]\n",
    "\n",
    "\n",
    "# Reshape the data for 1D CNN\n",
    "X_train_sm_cnn = np.expand_dims(X_train_sm, axis=2)\n",
    "X_val_cnn = np.expand_dims(X_val, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2) \n",
    "\n",
    "display(X_train_sm_cnn.shape)\n",
    "display(X_val_cnn.shape)\n",
    "display(X_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59285ef6-c735-471f-a682-ef14b89432c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to plot and save loss and accuracy over epochs from training history\n",
    "def plot_training_history(history, save_dir, prefix): \n",
    "    hist = history.history\n",
    "    metrics = [m for m in hist.keys() if not m.startswith('val_')]  \n",
    "\n",
    "    # Create the output folder if it does not exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for m in metrics:\n",
    "        plt.figure()\n",
    "        plt.plot(hist[m], label=f'Train {m}')\n",
    "        if f'val_{m}' in hist:\n",
    "            plt.plot(hist[f'val_{m}'], label=f'Val {m}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(m)\n",
    "        plt.title(f'{m} over epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Construct filename with prefix and filepath with directory and filename\n",
    "        filename = f\"{prefix}_{m}.png\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(filepath, format='png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {filepath}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0663cbd-09fa-4067-af23-875237210c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used CNNs\n",
    "\n",
    "#CNN1\n",
    "cnn1 = Sequential([\n",
    "    Input((187, 1)),\n",
    "    \n",
    "    # First Conv Block\n",
    "    Conv1D(filters=64, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Second Conv Block\n",
    "    Conv1D(filters=64, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Third Conv Block\n",
    "    Conv1D(filters=32, kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Dense layers\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#CNN2, CNN4 Paper 2020\n",
    "cnn2 = Sequential([\n",
    "    Input((187, 1)),\n",
    "    \n",
    "    # First Conv Block: 5×32\n",
    "    Conv1D(filters=32, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Second Conv Block: 3×64\n",
    "    Conv1D(filters=64, kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Third Conv Block: 5×128\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Fourth Conv Block: 3×256\n",
    "    Conv1D(filters=256, kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Dense layers\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#CNN3, CNN4 Paper 2020, increased dropout compared to CNN2\n",
    "cnn3 = Sequential([\n",
    "    Input((187, 1)),\n",
    "    \n",
    "    # First Conv Block\n",
    "    Conv1D(filters=32, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),  \n",
    "    \n",
    "    # Second Conv Block\n",
    "    Conv1D(filters=64, kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),  \n",
    "    \n",
    "    # Third Conv Block\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.4),  \n",
    "    \n",
    "    # Fourth Conv Block\n",
    "    Conv1D(filters=256, kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.4),  \n",
    "    \n",
    "    # Dense layers\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#CNN4, CNN4 Paper 2020, changed dropout compared to CNN2 and CNN3\n",
    "cnn4 = Sequential([\n",
    "    Input((187, 1)),\n",
    "    \n",
    "    # First Conv Block\n",
    "    Conv1D(filters=32, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.25),  \n",
    "    \n",
    "    # Second Conv Block\n",
    "    Conv1D(filters=64, kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.25), \n",
    "    \n",
    "    # Third Conv Block\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),  \n",
    "    \n",
    "    # Fourth Conv Block\n",
    "    Conv1D(filters=256, kernel_size=3, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.35),  \n",
    "    \n",
    "    # Dense layers\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.4),  \n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#CNN5, Paper 2018\n",
    "# Input\n",
    "inputs = Input(shape=(187, 1))\n",
    "\n",
    "# Initial conv layer, 32 filters\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(inputs)\n",
    "\n",
    "# Residual Block 1\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 2\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 3 \n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 4\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 5 \n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Fully connected layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# output\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# create model\n",
    "cnn5 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "#CNN6, Paper 2018 added dropout and batch normalization \n",
    "inputs = Input(shape=(187, 1))\n",
    "# Initial conv\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(inputs)\n",
    "x = BatchNormalization()(x)  \n",
    "\n",
    "# Residual Block 1\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)  \n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)  \n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.2)(x)  \n",
    "\n",
    "# Residual Block 2\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Residual Block 3\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Residual Block 4\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# Residual Block 5\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# Fully connected layers \n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)  \n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)  \n",
    "\n",
    "# output\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "cnn6 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "#CNN7, Paper 2018 added batch normalization, without dropout\n",
    "inputs = Input(shape=(187, 1))\n",
    "\n",
    "# Initial conv layer\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(inputs)\n",
    "x = BatchNormalization()(x) \n",
    "\n",
    "# Residual Block 1\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)  \n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)  \n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 2\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 3\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 4\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Residual Block 5 \n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# Fully Connected Layers \n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Output\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "cnn7 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "#CNN8, Paper 2018 added dropout, without batch normalization\n",
    "inputs = Input(shape=(187, 1))\n",
    "\n",
    "# Initial conv layer\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(inputs)\n",
    "\n",
    "# Residual Block 1\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.1)(x) \n",
    "\n",
    "# Residual Block 2\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Residual Block 3\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Residual Block 4\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Residual Block 5 \n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Fully Connected Layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)  \n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)  \n",
    "\n",
    "# Output \n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "cnn8 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "# CNN9 - changed Dropout strategy compared to CNN8\n",
    "inputs = Input(shape=(187, 1))\n",
    "\n",
    "#initial conv layer\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(inputs)\n",
    "\n",
    "# Residual Block 1\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.1)(x)  \n",
    "\n",
    "# Residual Block 2\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.15)(x)  \n",
    "\n",
    "# Residual Block 3\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.2)(x)  \n",
    "\n",
    "# Residual Block 4\n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.25)(x)  \n",
    "\n",
    "# Residual Block 5 \n",
    "shortcut = x\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv1D(filters=32, kernel_size=5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "x = Dropout(0.3)(x)  \n",
    "\n",
    "# Fully Connected Layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)  \n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)  \n",
    "\n",
    "#output\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "cnn9 = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f3101-3dea-4302-9ba0-89798614a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model summary\n",
    "cnn1.summary()\n",
    "\n",
    "cnn2.summary()\n",
    "\n",
    "cnn3.summary()\n",
    "\n",
    "cnn4.summary()\n",
    "\n",
    "cnn5.summary()\n",
    "\n",
    "cnn6.summary()\n",
    "\n",
    "cnn7.summary()\n",
    "\n",
    "cnn8.summary()\n",
    "\n",
    "cnn9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bdb97-73e2-4584-9062-34d6e754d1ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lr exp dec\n",
    "# Learning rate with exponential decay\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96)\n",
    "\n",
    "#Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # what to monitor \n",
    "    patience=20,               # how many epochs with no improvement before stopping\n",
    "    restore_best_weights=True, \n",
    "    min_delta=0.001            #only stop if improvement < 0.001\n",
    ")\n",
    "\n",
    "#Compile when lr exp decay\n",
    "cnn6.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Define where and how to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../CNN_output/cnn6_sm_lrexpdec_earlystop_bs512_epoch_{epoch:02d}_valloss_{val_loss:.4f}.keras',   # file path (can be .keras or .h5)\n",
    "    monitor='val_loss',            # metric to monitor\n",
    "    mode='min',                    # minimize loss\n",
    "    save_best_only=False,          # save model of every epoch\n",
    "    verbose=1                      # print message when a model is saved\n",
    ")\n",
    "\n",
    "#training\n",
    "history = cnn6.fit(\n",
    "    X_train_sm_cnn,\n",
    "    y_train_sm,\n",
    "    epochs=200,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[checkpoint, early_stop] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fae64-4e28-4862-a2ae-53c0a2dbb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate with exponential decay - PAPER 2018\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.75\n",
    ")\n",
    "\n",
    "# Adam optimizer with specified hyperparameters\n",
    "optimizer = Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999\n",
    ")\n",
    "\n",
    "#Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       \n",
    "    patience=20,              \n",
    "    restore_best_weights=True, \n",
    "    min_delta=0.001  \n",
    ")\n",
    "\n",
    "cnn6.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Define where and how to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../CNN_output/cnn6_sm_lrrexpdecpaper_earlystop_bs512_epoch_{epoch:02d}_valloss_{val_loss:.4f}.keras',   # file path (can be .keras or .h5)\n",
    "    monitor='val_loss',        \n",
    "    mode='min',                    \n",
    "    save_best_only=False,           \n",
    "    verbose=1                      \n",
    ")\n",
    "\n",
    "#training\n",
    "history = cnn6.fit(\n",
    "    X_train_sm_cnn,\n",
    "    y_train_sm,\n",
    "    epochs=200,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[checkpoint, early_stop] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968fdf3-8b03-49b9-b334-e06fa9be1d7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lr reduction: lrredpl -> reduce on plateau\n",
    "lrredpl = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    factor=0.5,          # Factor by which the learning rate will be reduced\n",
    "    patience=10,         # Number of epochs with no improvement after which learning rate is reduced\n",
    "    min_lr=1e-7,         # Minimum learning rate\n",
    "    verbose=1,           # Print a message when the learning rate is reduced\n",
    "    min_delta=0.001 \n",
    ")\n",
    "\n",
    "#Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       \n",
    "    patience=20,               \n",
    "    restore_best_weights=True, \n",
    "    min_delta=0.001  \n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Define where and how to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../CNN_output/cnn6_sm_lrexpdec_earlystop_bs512_epoch_{epoch:02d}_valloss_{val_loss:.4f}.keras',   # file path (can be .keras or .h5)\n",
    "    monitor='val_loss',        \n",
    "    mode='min',                    \n",
    "    save_best_only=False,          \n",
    "    verbose=1                      \n",
    ")\n",
    "\n",
    "#training\n",
    "history = model.fit(\n",
    "    X_train_sm_cnn,\n",
    "    y_train_sm,\n",
    "    epochs=200,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    callbacks=[checkpoint, early_stop, lrredpl] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4442cb5-66a8-4cdf-93ee-e99b72ebef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save loss and accuracy over epochs from history\n",
    "plot_training_history(history, save_dir=\"../CNN_output\", prefix=\"cnn6_sm_lrexpdec_bs512\") #change for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca563f08-e666-43be-b470-e0e9e8a3eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save training history\n",
    "with open(\"../CNN_output/cnn1_sm_lr_bs_epoch__valloss_.pkl\", \"wb\") as f: #change for model\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "    \n",
    "best_model = load_model('../CNN_output/cnn1_sm_lr_bs_epoch__valloss_.keras') #change for model\n",
    "\n",
    "\n",
    "#prediction of test data\n",
    "test_pred = best_model.predict(X_test_cnn)\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis=1)\n",
    "\n",
    "\n",
    "#classification report\n",
    "print(classification_report(y_test_class, y_pred_class, digits=4))\n",
    "\n",
    "\n",
    "#confusion matrix\n",
    "print(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions']))\n",
    "\n",
    "\n",
    "#save results of metrics\n",
    "with open(\"../CNN_output/cnn1_sm_lr_bs_epoch__valloss_.txt\", \"w\") as file: #change for model\n",
    "    \n",
    "    file.write(\"\\nModel: CNN1\\n\")#change for model\n",
    "        \n",
    "    file.write(\"\\nData augmentation: Smote\\n\")\n",
    "    \n",
    "    file.write(\"\\nConfusion Matrix on test set:\\n\")\n",
    "    file.write(str(pd.crosstab(y_test_class, y_pred_class, colnames=['Predictions'])))\n",
    "    \n",
    "    file.write(\"\\n\\nClassification Report on test set:\\n\")\n",
    "    file.write(classification_report(y_test_class, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab9e7a-3d2c-4f98-8e2c-3e2814934d19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascientest_project",
   "language": "python",
   "name": "datascientest_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
