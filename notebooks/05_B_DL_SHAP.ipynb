{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6038821",
   "metadata": {},
   "source": [
    "# Model Interpretability: SHAP Analysis for PTB Deep Learning Models\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) analysis to understand which temporal features contribute to the CNN8 transfer model's binary classification decisions for MI detection.\n",
    "\n",
    "**Analysis scope:**\n",
    "- 100 test samples (50 per class) for explanation\n",
    "- 100 background samples for reference distribution\n",
    "- DeepExplainer for neural network interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76779e39-81d4-4b33-898f-c5b8c49d406d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bed73-2e89-4caf-925e-eb41dc5a074e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import PTB data\n",
    "X_ptb_train = pd.read_csv('data/processed/ptb/X_ptb_train.csv')\n",
    "y_ptb_train = pd.read_csv('data/processed/ptb/y_ptb_train.csv')\n",
    "\n",
    "X_ptb_train_sm = pd.read_csv('data/processed/ptb/X_ptb_train_sm.csv')\n",
    "y_ptb_train_sm = pd.read_csv('data/processed/ptb/y_ptb_train_sm.csv')\n",
    "\n",
    "X_ptb_val = pd.read_csv('data/processed/ptb/X_ptb_val.csv')\n",
    "y_ptb_val = pd.read_csv('data/processed/ptb/y_ptb_val.csv')\n",
    "\n",
    "X_ptb_test = pd.read_csv('data/processed/ptb/X_ptb_test.csv')\n",
    "y_ptb_test = pd.read_csv('data/processed/ptb/y_ptb_test.csv')\n",
    "\n",
    "\n",
    "display(X_ptb_train.shape)\n",
    "display(y_ptb_train.shape)\n",
    "\n",
    "display(X_ptb_train_sm.shape)\n",
    "display(y_ptb_train_sm.shape)\n",
    "\n",
    "display(X_ptb_val.shape)\n",
    "display(y_ptb_val.shape)\n",
    "\n",
    "display(X_ptb_test.shape)\n",
    "display(y_ptb_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the data for 1D CNN\n",
    "X_ptb_train_cnn = np.expand_dims(X_ptb_train, axis=2)\n",
    "X_ptb_train_sm_cnn = np.expand_dims(X_ptb_train_sm, axis=2)\n",
    "X_ptb_val_cnn = np.expand_dims(X_ptb_val, axis=2)\n",
    "X_ptb_test_cnn = np.expand_dims(X_ptb_test, axis=2)\n",
    "\n",
    "display(X_ptb_train_cnn.shape)\n",
    "display(y_ptb_train.shape)\n",
    "\n",
    "display(X_ptb_train_sm_cnn.shape)\n",
    "display(y_ptb_train_sm.shape)\n",
    "\n",
    "display(X_ptb_val_cnn.shape)\n",
    "display(y_ptb_val.shape)\n",
    "\n",
    "display(X_ptb_test_cnn.shape)\n",
    "display(y_ptb_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327cb218-957f-4797-b66f-193c891477a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SAMPLES_PER_CLASS = 50  # 50 samples Ã— 2 classes = 100 total samples\n",
    "N_BACKGROUND = 100      # Background samples for SHAP explainer\n",
    "RANDOM_SEED = 42        # reproducibility\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# load best CNN\n",
    "model = load_model('models/PTB_04_02_dl_models/CNN8_TRANSFER/transfer_model_6_BS512_best.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc61ae-304a-4d32-872d-30c619a17fd6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# verify data shape \n",
    "print(f\"\\nTraining set (SMOTE):\")\n",
    "print(f\"  X_ptb_train_sm_cnn shape: {X_ptb_train_sm_cnn.shape}\")\n",
    "print(f\"  y_ptb_train_sm_cnn shape: {y_ptb_train_sm.shape}\")\n",
    "print(f\"  Unique classes: {np.unique(y_ptb_train_sm)}\")\n",
    "print(f\"  Class distribution: {np.bincount(y_ptb_train_sm.values.flatten().astype(int))}\")\n",
    "\n",
    "print(f\"\\nValidation set:\")\n",
    "print(f\"  X_ptb_val_cnn shape: {X_ptb_val_cnn.shape}\")\n",
    "print(f\"  y_ptb_val_cnn shape: {y_ptb_val.shape}\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  X_ptb_test_cnn shape: {X_ptb_test_cnn.shape}\")\n",
    "print(f\"  y_ptb_test_cnn shape: {y_ptb_test.shape}\")\n",
    "\n",
    "print(f\"\\nModel input shape: {model.input_shape}\")\n",
    "print(f\"Model output shape: {model.output_shape}\")\n",
    "\n",
    "\n",
    "# Expected output:\n",
    "#Training set (SMOTE):\n",
    "#X_ptb_train_sm_cnn shape: (13438, 187, 1)\n",
    "#y_ptb_train_sm_cnn shape: (13438, 1)\n",
    "\n",
    "#Unique classes: [0. 1.]\n",
    "#Class distribution: [6719 6719]\n",
    "\n",
    "#Validation set:\n",
    "#X_ptb_val_cnn shape: (2328, 187, 1)\n",
    "#y_ptb_val_cnn shape: (2328, 1)\n",
    "\n",
    "#Test set:\n",
    "#X_ptb_test_cnn shape: (2909, 187, 1)\n",
    "#y_ptb_test_cnn shape: (2909, 1)\n",
    "\n",
    "#Model input shape: (None, 187, 1)\n",
    "#Model output shape: (None, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1152a9-3c40-4d66-9f11-e1e7dc6fc027",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model performance check -> should be same results as results in Rendering for best model\n",
    "y_pred = model.predict(X_ptb_test_cnn)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_ptb_test, y_pred_classes, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_ptb_test, y_pred_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336e179-d846-4137-a936-62c25e831096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1) Background selection\n",
    "# -------------------------------\n",
    "N_BACKGROUND = 100\n",
    "SAMPLES_PER_CLASS = 50\n",
    "\n",
    "# sample background windows from training set\n",
    "background_indices = np.random.choice(\n",
    "    len(X_ptb_train_sm_cnn),\n",
    "    size=N_BACKGROUND,\n",
    "    replace=False\n",
    ")\n",
    "background_data = X_ptb_train_sm_cnn[background_indices]\n",
    "\n",
    "print(\"\\nBackground data:\")\n",
    "print(f\"  shape: {background_data.shape}\")\n",
    "print(f\"  value range: [{background_data.min():.3f}, {background_data.max():.3f}]\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Test selection per class\n",
    "# -------------------------------\n",
    "y_test = np.asarray(y_ptb_test).flatten()\n",
    "\n",
    "test_indices = []\n",
    "\n",
    "for class_idx in [0, 1]:\n",
    "    class_mask = np.where(y_test == class_idx)[0]\n",
    "\n",
    "    n_take = min(SAMPLES_PER_CLASS, len(class_mask))\n",
    "    selected = np.random.choice(class_mask, n_take, replace=False)\n",
    "\n",
    "    test_indices.append(selected)\n",
    "\n",
    "# stack the selected indices for both classes\n",
    "test_indices = np.concatenate(test_indices)\n",
    "\n",
    "# build explain sets\n",
    "X_explain = X_ptb_test_cnn[test_indices]\n",
    "y_explain = y_test[test_indices]\n",
    "\n",
    "print(\"\\nTest samples to explain:\")\n",
    "print(f\"  count: {len(test_indices)}\")\n",
    "print(f\"  X_explain shape: {X_explain.shape}\")\n",
    "print(f\"  class distribution: {np.bincount(y_explain.astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7159e4e-e8fa-4f0d-9b5c-0e2dd86c6c6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SHAP Explainer -> DeepExplainer for DL model\n",
    "explainer = shap.DeepExplainer(model, background_data)\n",
    "shap_values = explainer.shap_values(X_ptb_test_cnn[:100])\n",
    "\n",
    "print(f\"\\nExpected value (baseline) for each class:\")\n",
    "for i, ev in enumerate(explainer.expected_value):\n",
    "    print(f\"  Class {i}: {ev:.4f}\")\n",
    "\n",
    "baseline_sum = sum(explainer.expected_value)\n",
    "print(f\"\\nBaseline sum: {baseline_sum:.4f}\")\n",
    "\n",
    "#expected output: baseline sum should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb4997-9a25-4cf4-aeda-aa9b41f4a029",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculcation of SHAP values\n",
    "\n",
    "shap_values_raw = explainer.shap_values(X_explain)\n",
    "\n",
    "# Reshape SHAP values to correct format\n",
    "print(f\"\\nRaw SHAP values shape: {shap_values_raw.shape}\")\n",
    "\n",
    "if isinstance(shap_values_raw, np.ndarray) and len(shap_values_raw.shape) == 4:\n",
    "    shap_values = []\n",
    "    for class_idx in range(2):\n",
    "        shap_values.append(shap_values_raw[:, :, :, class_idx])\n",
    "else:\n",
    "    shap_values = shap_values_raw\n",
    "\n",
    "\n",
    "print(f\"\\nFinal SHAP structure:\")\n",
    "print(f\"  Type: {type(shap_values)}\")\n",
    "print(f\"  Length (classes): {len(shap_values)}\")\n",
    "print(f\"  Shape per class: {shap_values[0].shape}\")\n",
    "\n",
    "# Statistics\n",
    "for i in range(2):\n",
    "    print(f\"\\nClass {i} SHAP statistics:\")\n",
    "    print(f\"  Min: {shap_values[i].min():.4f}\")\n",
    "    print(f\"  Max: {shap_values[i].max():.4f}\")\n",
    "    print(f\"  Mean: {shap_values[i].mean():.4f}\")\n",
    "    print(f\"  Std: {shap_values[i].std():.4f}\")\n",
    "\n",
    "\n",
    "#expected output\n",
    "#Raw SHAP values shape: (100, 187, 1, 2)\n",
    "\n",
    "#Final SHAP structure:\n",
    "#Type: <class 'list'>\n",
    "#Length (classes): 2\n",
    "#Shape per class: (100, 187, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a537c7c-ccd5-4079-bc3b-88d0036d80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparations for plotting\n",
    "\n",
    "X_explain_2d = X_explain.reshape(len(X_explain), 187)\n",
    "shap_values_2d = [sv.reshape(len(X_explain), 187) for sv in shap_values]\n",
    "\n",
    "print(f\"X_explain_2d shape: {X_explain_2d.shape}\")\n",
    "print(f\"shap_values_2d[0] shape: {shap_values_2d[0].shape}\")\n",
    "\n",
    "\n",
    "# expected output\n",
    "#X_explain_2d shape: (100, 187)\n",
    "#shap_values_2d[0] shape: (100, 187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b7542-e848-4f64-a9a2-a73c7df5fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Top 20 most important features for every class\n",
    "\n",
    "# Calculate importance for each class\n",
    "class_importance = []\n",
    "for class_idx in range(2):\n",
    "    mean_abs_shap = np.mean(np.abs(shap_values_2d[class_idx]), axis=0)\n",
    "    class_importance.append(mean_abs_shap)\n",
    "\n",
    "# Create separate plot for each class\n",
    "for class_idx in range(2):\n",
    "    \n",
    "    # Create individual figure for class\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    \n",
    "    # Get top 20 features for this class\n",
    "    top_20 = np.argsort(class_importance[class_idx])[-20:][::-1]\n",
    "    \n",
    "    # Plot bars\n",
    "    y_pos = np.arange(len(top_20))\n",
    "    ax.barh(y_pos, class_importance[class_idx][top_20], \n",
    "            color=f'C{class_idx}', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([f'Feature {f}' for f in top_20], fontsize=10)\n",
    "    ax.set_xlabel('Mean |SHAP Value|', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Class {class_idx} - Top 20 Most Important Features', \n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for i, (feat, val) in enumerate(zip(top_20, class_importance[class_idx][top_20])):\n",
    "        ax.text(val, i, f' {val:.4f}', va='center', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'reports/interpretability/SHAP_PTB/feature_importance_class_{class_idx}.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top 10 for this class\n",
    "    print(f\"\\nClass {class_idx} - Top 10 features:\")\n",
    "    for rank, feat in enumerate(top_20[:10], 1):\n",
    "        print(f\"  {rank}. Feature {feat}: {class_importance[class_idx][feat]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12915cf7-e955-4b32-9b91-d13ebeebeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature effects class 0\n",
    "\n",
    "# Choose a class to analyze\n",
    "class_to_analyze = 0\n",
    "print(f\"\\nAnalyzing Class {class_to_analyze}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_2d[class_to_analyze], X_explain_2d, show=False)\n",
    "plt.title(f'SHAP Summary Plot - Class {class_to_analyze}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'reports/interpretability/SHAP_PTB/shap_summary_class_{class_to_analyze}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77292e69-1b74-4bd1-ac80-df6f79bab951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample ECG over SHAP values for 3 examples per class\n",
    "\n",
    "# Find correctly classified samples\n",
    "predicted_classes = np.argmax(model.predict(X_explain, verbose=0), axis=1)\n",
    "\n",
    "for target_class in range(2):\n",
    "    # Find samples of this class that were correctly predicted\n",
    "    correct_idx = np.where((y_explain == target_class) & \n",
    "                          (predicted_classes == target_class))[0]\n",
    "    \n",
    "    if len(correct_idx) > 0:\n",
    "        # Take up to 3 samples\n",
    "        n_samples = min(3, len(correct_idx))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            sample_idx = correct_idx[i]\n",
    "            \n",
    "            print(f\"Analyzing Sample {sample_idx} (True Class: {target_class}, Example {i+1}/3)\")\n",
    "            \n",
    "            # Get prediction\n",
    "            pred = model.predict(X_explain[sample_idx:sample_idx+1], verbose=0)[0]\n",
    "            print(f\"Predicted class: {np.argmax(pred)}\")\n",
    "            print(f\"Confidence: {pred[target_class]:.4f}\")\n",
    "            \n",
    "            # Plot ECG signal with SHAP values\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8), sharex=True)\n",
    "            \n",
    "            # ECG signal\n",
    "            ecg_signal = X_explain_2d[sample_idx]\n",
    "            ax1.plot(ecg_signal, 'b-', linewidth=1)\n",
    "            ax1.set_ylabel('Normalized ECG Signal', fontsize=12)\n",
    "            ax1.set_title(f'Sample {sample_idx} - True Class: {target_class}, Predicted: {np.argmax(pred)}', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # SHAP values for the predicted class\n",
    "            shap_vals = shap_values_2d[target_class][sample_idx]\n",
    "            colors = ['red' if x > 0 else 'blue' for x in shap_vals]\n",
    "            ax2.bar(range(len(shap_vals)), shap_vals, color=colors, alpha=0.6, width=1.0)\n",
    "            ax2.set_xlabel('Time Step (Feature Index)', fontsize=12)\n",
    "            ax2.set_ylabel('SHAP Value', fontsize=12)\n",
    "            ax2.set_title(f'Feature Importance - Class {target_class}', fontsize=12)\n",
    "            ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'reports/interpretability/SHAP_PTB/ecg_shap_sample_{sample_idx}_class_{target_class}_example_{i+1}.png', \n",
    "                       dpi=150, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # Show top important features\n",
    "            top_n = 10\n",
    "            top_features = np.argsort(np.abs(shap_vals))[-top_n:][::-1]\n",
    "            print(f\"\\nTop {top_n} most important time steps:\")\n",
    "            for rank, feat_idx in enumerate(top_features, 1):\n",
    "                print(f\"  {rank}. Feature {feat_idx}: SHAP={shap_vals[feat_idx]:.4f}, \"\n",
    "                      f\"Value={ecg_signal[feat_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912851d-ec2a-4a03-a4b1-47176e57ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4efb97-5c24-4285-acac-c5691fb7f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassification analysis\n",
    "# Identify misclassified samples\n",
    "\n",
    "# Get predictions on full test set\n",
    "y_pred_probs = model.predict(X_ptb_test_cnn, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert y_ptb_test to numpy array and flatten\n",
    "y_test_array = y_ptb_test.values if hasattr(y_ptb_test, 'values') else np.array(y_ptb_test)\n",
    "y_test_array = y_test_array.ravel()\n",
    "\n",
    "# Find misclassified samples\n",
    "misclassified_idx = np.where(y_test_array != y_pred)[0]\n",
    "correct_idx = np.where(y_test_array == y_pred)[0]\n",
    "\n",
    "print(f\"\\nTotal test samples: {len(y_test_array)}\")\n",
    "print(f\"Correctly classified: {len(correct_idx)} ({100*len(correct_idx)/len(y_test_array):.2f}%)\")\n",
    "print(f\"Misclassified: {len(misclassified_idx)} ({100*len(misclassified_idx)/len(y_test_array):.2f}%)\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_array, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Find most common misclassification patterns\n",
    "misclassification_patterns = []\n",
    "for true_class in range(2):\n",
    "    for pred_class in range(2):\n",
    "        if true_class != pred_class:\n",
    "            count = cm[true_class, pred_class]\n",
    "            if count > 0:\n",
    "                misclassification_patterns.append({\n",
    "                    'true': true_class,\n",
    "                    'pred': pred_class,\n",
    "                    'count': count\n",
    "                })\n",
    "\n",
    "# Sort by frequency\n",
    "misclassification_patterns = sorted(misclassification_patterns, \n",
    "                                   key=lambda x: x['count'], \n",
    "                                   reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d772a-ebb0-4268-b8ef-cf903e2a9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Misclassified Cases for SHAP\n",
    "\n",
    "# Select representative misclassified samples\n",
    "samples_to_analyze = []\n",
    "samples_info = []\n",
    "\n",
    "for pattern in misclassification_patterns[:2]:\n",
    "    true_class = pattern['true']\n",
    "    pred_class = pattern['pred']\n",
    "    \n",
    "    # Find samples matching this pattern\n",
    "    pattern_samples = misclassified_idx[\n",
    "        (y_test_array[misclassified_idx] == true_class) & \n",
    "        (y_pred[misclassified_idx] == pred_class)\n",
    "    ]\n",
    "    \n",
    "    # Select up to 3 samples from this pattern\n",
    "    n_samples = min(3, len(pattern_samples))\n",
    "    selected = np.random.choice(pattern_samples, n_samples, replace=False)\n",
    "    \n",
    "    samples_to_analyze.extend(selected)\n",
    "    samples_info.extend([{\n",
    "        'idx': idx,\n",
    "        'true': true_class,\n",
    "        'pred': pred_class,\n",
    "        'prob': y_pred_probs[idx]\n",
    "    } for idx in selected])\n",
    "\n",
    "print(f\"\\nSelected {len(samples_to_analyze)} misclassified samples\")\n",
    "print(f\"Patterns covered: {len(set([(s['true'], s['pred']) for s in samples_info]))}\")\n",
    "\n",
    "# Also select correctly classified samples for comparison\n",
    "correct_samples_per_class = []\n",
    "for class_idx in range(2):\n",
    "    class_correct = correct_idx[y_test_array[correct_idx] == class_idx]\n",
    "    if len(class_correct) > 0:\n",
    "        selected = np.random.choice(class_correct, min(3, len(class_correct)), replace=False)\n",
    "        correct_samples_per_class.extend(selected)\n",
    "\n",
    "print(f\"Selected {len(correct_samples_per_class)} correctly classified samples for comparison\")\n",
    "\n",
    "# Combine for SHAP analysis\n",
    "all_samples = np.array(samples_to_analyze + correct_samples_per_class)\n",
    "X_analyze = X_ptb_test_cnn[all_samples]\n",
    "y_analyze = y_test_array[all_samples]\n",
    "\n",
    "print(f\"\\nTotal samples for SHAP analysis: {len(all_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041d697-03c2-4e58-ad31-19ec672418e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP for Misclassified Cases\n",
    "\n",
    "shap_values_misc_raw = explainer.shap_values(X_analyze)\n",
    "\n",
    "# Reshape SHAP values\n",
    "print(f\"\\nRaw SHAP shape: {shap_values_misc_raw.shape}\")\n",
    "\n",
    "if isinstance(shap_values_misc_raw, np.ndarray) and len(shap_values_misc_raw.shape) == 4:\n",
    "    shap_values_misc = []\n",
    "    for class_idx in range(2):\n",
    "        shap_values_misc.append(shap_values_misc_raw[:, :, :, class_idx])\n",
    "else:\n",
    "    shap_values_misc = shap_values_misc_raw\n",
    "\n",
    "# Reshape to 2D for analysis\n",
    "X_analyze_2d = X_analyze.reshape(len(all_samples), 187)\n",
    "shap_values_misc_2d = [sv.reshape(len(all_samples), 187) for sv in shap_values_misc]\n",
    "\n",
    "print(f\"Final SHAP structure: {len(shap_values_misc_2d)} classes\")\n",
    "print(f\"Shape per class: {shap_values_misc_2d[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391dbcb-e748-4f13-9605-e8a17816579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Misclassified Cases\n",
    "\n",
    "# Analyze each misclassified sample\n",
    "for i, info in enumerate(samples_info[:10]):  # Top 10\n",
    "    sample_idx = info['idx']\n",
    "    true_class = info['true']\n",
    "    pred_class = info['pred']\n",
    "    probs = info['prob']\n",
    "    \n",
    "    # Find this sample in analyzed set\n",
    "    analyze_idx = np.where(all_samples == sample_idx)[0][0]\n",
    "    \n",
    "    print(f\"Misclassified Sample {i+1}: Index {sample_idx}\")\n",
    "    print(f\"  True Class: {true_class}\")\n",
    "    print(f\"  Predicted Class: {pred_class}\")\n",
    "    print(f\"  Prediction confidence: {probs[pred_class]:.4f}\")\n",
    "    print(f\"  True class probability: {probs[true_class]:.4f}\")\n",
    "    \n",
    "    # Create plot\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. ECG Signal\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ecg = X_analyze_2d[analyze_idx]\n",
    "    ax1.plot(ecg, 'b-', linewidth=1.2)\n",
    "    ax1.set_ylabel('ECG Signal', fontsize=11)\n",
    "    ax1.set_title(f'Sample {sample_idx}: True={true_class}, Predicted={pred_class} '\n",
    "                  f'(Confidence={probs[pred_class]:.3f})', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(0, 186)\n",
    "    \n",
    "    # 2. SHAP for PREDICTED class\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    shap_pred = shap_values_misc_2d[pred_class][analyze_idx]\n",
    "    colors_pred = ['red' if x > 0 else 'blue' for x in shap_pred]\n",
    "    ax2.bar(range(187), shap_pred, color=colors_pred, alpha=0.6, width=1.0)\n",
    "    ax2.set_ylabel('SHAP Value', fontsize=11)\n",
    "    ax2.set_title(f'Why Model Predicted Class {pred_class}', fontsize=12, fontweight='bold')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(0, 186)\n",
    "    \n",
    "    # 3. SHAP for TRUE class\n",
    "    ax3 = fig.add_subplot(gs[2, :])\n",
    "    shap_true = shap_values_misc_2d[true_class][analyze_idx]\n",
    "    colors_true = ['red' if x > 0 else 'blue' for x in shap_true]\n",
    "    ax3.bar(range(187), shap_true, color=colors_true, alpha=0.6, width=1.0)\n",
    "    ax3.set_ylabel('SHAP Value', fontsize=11)\n",
    "    ax3.set_title(f'Evidence for True Class {true_class} (Missed)', fontsize=12, fontweight='bold')\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_xlim(0, 186)\n",
    "    ax3.set_xlabel('Time Step (Feature Index)', fontsize=11)\n",
    "    \n",
    "    # 4. Prediction probabilities\n",
    "    ax4 = fig.add_subplot(gs[3, 0])\n",
    "    colors_bar = ['green' if idx == true_class else ('red' if idx == pred_class else 'gray') \n",
    "                  for idx in range(2)]\n",
    "    ax4.bar(range(2), probs, color=colors_bar, alpha=0.7)\n",
    "    ax4.set_xlabel('Class', fontsize=11)\n",
    "    ax4.set_ylabel('Probability', fontsize=11)\n",
    "    ax4.set_title('Prediction Probabilities', fontsize=11, fontweight='bold')\n",
    "    ax4.set_xticks(range(2))\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 5. Key features comparison\n",
    "    ax5 = fig.add_subplot(gs[3, 1])\n",
    "    top_n = 10\n",
    "    top_pred = np.argsort(np.abs(shap_pred))[-top_n:][::-1]\n",
    "    top_true = np.argsort(np.abs(shap_true))[-top_n:][::-1]\n",
    "    \n",
    "    comparison_text = \"Top Features:\\n\\n\"\n",
    "    comparison_text += f\"Pred Class {pred_class}:\\n\"\n",
    "    for rank, feat in enumerate(top_pred[:5], 1):\n",
    "        comparison_text += f\"  {rank}. F{feat}: {shap_pred[feat]:+.3f}\\n\"\n",
    "    comparison_text += f\"\\nTrue Class {true_class}:\\n\"\n",
    "    for rank, feat in enumerate(top_true[:5], 1):\n",
    "        comparison_text += f\"  {rank}. F{feat}: {shap_true[feat]:+.3f}\\n\"\n",
    "    \n",
    "    ax5.text(0.1, 0.5, comparison_text, fontsize=9, family='monospace',\n",
    "             verticalalignment='center', transform=ax5.transAxes)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    plt.savefig(f'reports/interpretability/SHAP_PTB/misclassified_sample_{i+1}_idx_{sample_idx}.png', \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top features\n",
    "    print(\"\\nTop 3 features:\")\n",
    "    print(f\"  Predicted Class {pred_class}:\")\n",
    "    for feat in top_pred[:3]:\n",
    "        print(f\"    Feature {feat}: SHAP={shap_pred[feat]:+.4f}, Value={ecg[feat]:.4f}\")\n",
    "    print(f\"  True Class {true_class}:\")\n",
    "    for feat in top_true[:3]:\n",
    "        print(f\"    Feature {feat}: SHAP={shap_true[feat]:+.4f}, Value={ecg[feat]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
