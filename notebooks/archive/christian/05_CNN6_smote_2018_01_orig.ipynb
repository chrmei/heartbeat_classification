{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92072ab0",
   "metadata": {},
   "source": [
    "# CNN Model - 2018 Paper (Kachuee, Fazeli, Sarrafzadeh): CNN6\n",
    "\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Conv1D, MaxPooling1D, Flatten, Add, ReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from pathlib import Path\n",
    "import re \n",
    "\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "print(tf.config.list_physical_devices('GPU'))  # should show []\n",
    "from contextlib import redirect_stdout\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from src.visualization.visualization import plot_training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d207cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_METHOD = \"SMOTE\"\n",
    "REMOVE_OUTLIERS = False\n",
    "# model_name = \"cnn6\"  # as the paper, no smote! --> very bad...\n",
    "model_name = \"cnn6_sm\" # with smote dataset\n",
    "model_name = \"cnn6_sm_1fcl\"  # with smote but only one fully connected layer!\n",
    "\n",
    "OUTPUT_PATH = \"src/models/CNN/\"\n",
    "results_csv = \"reports/03_model_testing_results/05_CNN_model_comparison.csv\"\n",
    "EPOCHS = 50\n",
    "\n",
    "#import MIT data\n",
    "df_mitbih_test = pd.read_csv('data/original/mitbih_test.csv', header = None)\n",
    "\n",
    "X_train = pd.read_csv('data/processed/mitbih/X_train.csv')\n",
    "y_train = pd.read_csv('data/processed/mitbih/y_train.csv')\n",
    "y_train = y_train['187']\n",
    "\n",
    "X_val = pd.read_csv('data/processed/mitbih/X_val.csv')\n",
    "y_val = pd.read_csv('data/processed/mitbih/y_val.csv')\n",
    "y_val = y_val['187']\n",
    "\n",
    "X_test = df_mitbih_test.drop(187, axis = 1)\n",
    "y_test = df_mitbih_test[187]\n",
    "\n",
    "\n",
    "# Apply SMOTE\n",
    "# --- Before SMOTE ---\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "\n",
    "# Convert to numpy if not already\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "# --- Apply SMOTE ---\n",
    "sm = SMOTE(random_state=42, sampling_strategy='auto', k_neighbors=5)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train_np, y_train_np)\n",
    "\n",
    "print(\"After SMOTE:\", Counter(y_train_sm))\n",
    "print(\"X_train_sm shape:\", X_train_sm.shape)\n",
    "\n",
    "# Reshape the data for 1D CNN\n",
    "#X_train_sm_cnn = np.expand_dims(X_train_sm, axis=2)\n",
    "X_train_sm_cnn = np.expand_dims(X_train_sm, axis=2)\n",
    "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "X_val_cnn = np.expand_dims(X_val, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2) \n",
    "\n",
    "display(X_train_cnn.shape)\n",
    "display(X_val_cnn.shape)\n",
    "display(X_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac73b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = Input(shape=(187, 1))\n",
    "\n",
    "# Initial convolution\n",
    "conv_0 = Conv1D(filters=32, kernel_size=5, padding='same')(input_layer)\n",
    "\n",
    "# ----- Residual Block 1 -----\n",
    "x = Conv1D(32, 5, padding='same', activation='relu')(conv_0)\n",
    "x = Conv1D(32, 5, padding='same')(x)\n",
    "x = Add()([conv_0, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# ----- Residual Block 2 -----\n",
    "shortcut = x\n",
    "x = Conv1D(32, 5, padding='same', activation='relu')(x)\n",
    "x = Conv1D(32, 5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# ----- Residual Block 3 -----\n",
    "shortcut = x\n",
    "x = Conv1D(32, 5, padding='same', activation='relu')(x)\n",
    "x = Conv1D(32, 5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# ----- Residual Block 4 -----\n",
    "shortcut = x\n",
    "x = Conv1D(32, 5, padding='same', activation='relu')(x)\n",
    "x = Conv1D(32, 5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# ----- Residual Block 5 -----\n",
    "shortcut = x\n",
    "x = Conv1D(32, 5, padding='same', activation='relu')(x)\n",
    "x = Conv1D(32, 5, padding='same')(x)\n",
    "x = Add()([shortcut, x])\n",
    "x = ReLU()(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=2, padding='same')(x)\n",
    "\n",
    "# ----- Fully Connected Layers -----\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "# x = Dense(32, activation='relu')(x) \n",
    "output_layer = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Model\n",
    "cnn6 = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe54c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate with exponential decay\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.75,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# Adam optimizer with specified hyperparameters\n",
    "optimizer = Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "cnn6.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    min_delta=1e-4,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=OUTPUT_PATH+model_name+'_bs_epoch_{epoch:02d}_valloss_{val_loss:.4f}.keras',   # file path (can be .keras or .h5)\n",
    "    monitor='val_loss',        # metric to monitor\n",
    "    mode='min',                    # because higher accuracy is better\n",
    "    save_best_only=True,           # only save when val_accuracy improves\n",
    "    verbose=1                      # print message when a model is saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running fit WITH SMOTE\")\n",
    "history = cnn6.fit(\n",
    "    X_train_sm,\n",
    "    y_train_sm,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_val_cnn, y_val),  \n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_epoch_from_name(name, default_epochs=EPOCHS):\n",
    "    # Expect pattern like ..._epoch_12_...; returns int if found else default\n",
    "    m = re.search(r\"epoch_(\\d+)\", name)\n",
    "    return int(m.group(1)) if m else default_epochs\n",
    "\n",
    "def parse_val_loss_from_name(name):\n",
    "    # Expect pattern like ..._valloss_0.1234.keras\n",
    "    m = re.search(r\"valloss_([0-9]+\\.[0-9]+)\", name)\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "# Safer file filtering\n",
    "model_dir = Path(OUTPUT_PATH)\n",
    "model_paths = sorted([p for p in model_dir.glob(\"*.keras\")])\n",
    "model_paths = [p for p in model_paths if model_name in p.name]\n",
    "\n",
    "all_labels = np.unique(y_test)  # ground-truth labels present in test set\n",
    "rows = []\n",
    "\n",
    "for p in model_paths:\n",
    "    print(p)\n",
    "    model_ = load_model(str(p))\n",
    "\n",
    "    y_pred = model_.predict(X_test_cnn)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Force consistent label space for metrics\n",
    "    print(classification_report(y_test, y_pred_class, digits=4))\n",
    "    report = classification_report(\n",
    "        y_test, y_pred_class, labels=all_labels, output_dict=True, zero_division=0\n",
    "    )\n",
    "\n",
    "    print(pd.crosstab(y_test, y_pred_class, colnames=['Predictions']))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    epoch_num = parse_epoch_from_name(p.name)\n",
    "    val_loss = parse_val_loss_from_name(p.name)\n",
    "\n",
    "    row = {\n",
    "        \"sampling_method\": SAMPLING_METHOD,\n",
    "        \"outliers_removed\": REMOVE_OUTLIERS,\n",
    "        \"epochs\": epoch_num,\n",
    "        \"model\": p.name,\n",
    "        \"val_loss\": round(float(val_loss), 4) if not np.isnan(val_loss) else np.nan,\n",
    "        \"test_accuracy\": round(float(accuracy), 4),\n",
    "        \"test_f1_macro\": round(float(report[\"macro avg\"][\"f1-score\"]), 4),\n",
    "        \"test_precision_macro\": round(float(report[\"macro avg\"][\"precision\"]), 4),\n",
    "        \"test_recall_macro\": round(float(report[\"macro avg\"][\"recall\"]), 4),\n",
    "        \"test_f1_weighted\": round(float(report[\"weighted avg\"][\"f1-score\"]), 4),\n",
    "        \"test_precision_weighted\": round(float(report[\"weighted avg\"][\"precision\"]), 4),\n",
    "        \"test_recall_weighted\": round(float(report[\"weighted avg\"][\"recall\"]), 4),\n",
    "    }\n",
    "    for lbl in all_labels:\n",
    "        row[f\"test_f1_cls_{int(lbl)}\"] = round(float(report[str(lbl)][\"f1-score\"]), 4)\n",
    "        row[f\"test_precision_cls_{int(lbl)}\"] = round(float(report[str(lbl)][\"precision\"]), 4)\n",
    "        row[f\"test_recall_cls_{int(lbl)}\"] = round(float(report[str(lbl)][\"recall\"]), 4)\n",
    "        row[f\"test_support_cls_{int(lbl)}\"] = int(report[str(lbl)][\"support\"])\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "os.makedirs(os.path.dirname(results_csv), exist_ok=True)\n",
    "if os.path.exists(results_csv):\n",
    "    df.to_csv(results_csv, mode='a', index=False, header=False)\n",
    "else:\n",
    "    df.to_csv(results_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, \"reports/figures/training_history/\", model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
